"""
æ™ºèƒ½ä½“æ‰§è¡ŒæŠ¥å‘Šç”Ÿæˆå™¨

ç”¨äºç”Ÿæˆå¯è§†åŒ–çš„æ‰§è¡Œè¿‡ç¨‹æŠ¥å‘Šï¼Œæ”¯æŒ Markdown å’Œç»“æ„åŒ–æ•°æ®å¯¼å‡º
æ•´åˆè¿½è¸ªç³»ç»Ÿæ•°æ®ï¼Œæä¾›ç»†ç²’åº¦çš„æ‰§è¡Œåˆ†æ
"""

from datetime import datetime
from typing import Any, Dict, List, Optional

from auto_agent.models import ExecutionPlan, SubTaskResult


class ExecutionReportGenerator:
    """æ™ºèƒ½ä½“æ‰§è¡ŒæŠ¥å‘Šç”Ÿæˆå™¨"""

    @staticmethod
    def generate_report_data(
        agent_name: str,
        query: str,
        plan: ExecutionPlan,
        results: List[SubTaskResult],
        state: Dict[str, Any],
        start_time: Optional[datetime] = None,
        end_time: Optional[datetime] = None,
        trace_data: Optional[Dict[str, Any]] = None,
        checkpoints: Optional[List[Dict[str, Any]]] = None,
        working_memory: Optional[Dict[str, Any]] = None,
        consistency_violations: Optional[List[Dict[str, Any]]] = None,
    ) -> Dict[str, Any]:
        """
        ç”Ÿæˆç»“æ„åŒ–çš„æ‰§è¡ŒæŠ¥å‘Šæ•°æ®

        Args:
            agent_name: æ™ºèƒ½ä½“åç§°
            query: ç”¨æˆ·æŸ¥è¯¢
            plan: æ‰§è¡Œè®¡åˆ’
            results: æ‰§è¡Œç»“æœåˆ—è¡¨
            state: æœ€ç»ˆçŠ¶æ€
            start_time: å¼€å§‹æ—¶é—´
            end_time: ç»“æŸæ—¶é—´
            trace_data: è¿½è¸ªæ•°æ®ï¼ˆæ¥è‡ª Tracerï¼‰
            checkpoints: ä¸€è‡´æ€§æ£€æŸ¥ç‚¹åˆ—è¡¨
            working_memory: å·¥ä½œè®°å¿†æ•°æ®
            consistency_violations: ä¸€è‡´æ€§è¿è§„åˆ—è¡¨

        Returns:
            ç»“æ„åŒ–çš„æŠ¥å‘Šæ•°æ®
        """
        result_map = {r.step_id: r for r in results}

        steps_detail = []
        for step in plan.subtasks:
            result = result_map.get(step.id)

            if result is None:
                status = "pending"
            elif result.success:
                status = "success"
            else:
                status = "failed"

            steps_detail.append(
                {
                    "step": step.id,
                    "name": step.tool or "unknown",
                    "description": step.description,
                    "expectations": step.expectations,
                    "status": status,
                    "output": ExecutionReportGenerator._compress_output(
                        result.output if result else None
                    ),
                    "error": result.error if result and not result.success else None,
                }
            )

        # ç»Ÿè®¡ä¿¡æ¯
        total_steps = len(plan.subtasks)
        executed_steps = len(results)
        successful_steps = sum(1 for r in results if r.success)
        failed_steps = executed_steps - successful_steps

        duration = None
        if start_time and end_time:
            duration = (end_time - start_time).total_seconds()

        # åŸºç¡€æŠ¥å‘Šæ•°æ®
        report = {
            "agent_name": agent_name,
            "query": query[:500] + "..." if len(query) > 500 else query,
            "intent": plan.intent,
            "generated_at": datetime.now().isoformat(),
            "start_time": start_time.isoformat() if start_time else None,
            "end_time": end_time.isoformat() if end_time else None,
            "duration_seconds": duration,
            "statistics": {
                "total_steps": total_steps,
                "executed_steps": executed_steps,
                "successful_steps": successful_steps,
                "failed_steps": failed_steps,
                "success_rate": round(successful_steps / executed_steps * 100, 1)
                if executed_steps > 0
                else 0,
            },
            "steps": steps_detail,
            "final_state": ExecutionReportGenerator._compress_state(state),
            "mermaid_diagram": ExecutionReportGenerator.generate_mermaid(plan, results),
            "errors": plan.errors,
            "warnings": plan.warnings,
        }
        
        # æ•´åˆè¿½è¸ªæ•°æ®
        if trace_data:
            report["trace"] = ExecutionReportGenerator._extract_trace_summary(trace_data)
        
        # æ•´åˆæ£€æŸ¥ç‚¹æ•°æ®
        if checkpoints:
            report["checkpoints"] = checkpoints
        
        # æ•´åˆå·¥ä½œè®°å¿†æ•°æ®
        if working_memory:
            report["working_memory"] = working_memory
        
        # æ•´åˆä¸€è‡´æ€§è¿è§„æ•°æ®
        if consistency_violations:
            report["consistency_violations"] = consistency_violations
        
        return report
    
    @staticmethod
    def _extract_trace_summary(trace_data: Dict[str, Any]) -> Dict[str, Any]:
        """ä»è¿½è¸ªæ•°æ®ä¸­æå–æ‘˜è¦ä¿¡æ¯"""
        summary = trace_data.get("summary", {})
        
        return {
            "trace_id": trace_data.get("trace_id"),
            "duration_ms": trace_data.get("duration_ms"),
            "llm_usage": {
                "total_calls": summary.get("llm_calls", {}).get("count", 0),
                "total_tokens": summary.get("llm_calls", {}).get("total_tokens", 0),
                "prompt_tokens": summary.get("llm_calls", {}).get("prompt_tokens", 0),
                "response_tokens": summary.get("llm_calls", {}).get("response_tokens", 0),
                "by_purpose": summary.get("llm_calls", {}).get("by_purpose", {}),
            },
            "tool_usage": {
                "total_calls": summary.get("tool_calls", {}).get("count", 0),
                "success": summary.get("tool_calls", {}).get("success", 0),
                "failed": summary.get("tool_calls", {}).get("failed", 0),
            },
            "flow_events": {
                "retries": summary.get("flow_events", {}).get("retries", 0),
                "jumps": summary.get("flow_events", {}).get("jumps", 0),
                "aborts": summary.get("flow_events", {}).get("aborts", 0),
                "replans": summary.get("flow_events", {}).get("replans", 0),
            },
            "memory_ops": summary.get("memory_ops", {}),
            "binding_ops": summary.get("binding_ops", {}),
        }

    @staticmethod
    def generate_mermaid(
        plan: ExecutionPlan,
        results: List[SubTaskResult],
    ) -> str:
        """ç”Ÿæˆ Mermaid æµç¨‹å›¾"""
        if not plan.subtasks:
            return "graph TD\n    Start([å¼€å§‹]) --> End([ç»“æŸ])"

        result_map = {r.step_id: r for r in results}
        lines = ["graph TD"]
        lines.append("    Start([å¼€å§‹]) --> Step1")

        for i, step in enumerate(plan.subtasks):
            step_id = f"Step{step.id}"
            result = result_map.get(step.id)

            tool_name = step.tool or "unknown"
            if result is None:
                shape = f"[{tool_name}]"
            elif result.success:
                shape = f"[{tool_name}]"
            else:
                shape = f"[[{tool_name}]]"

            lines.append(f"    {step_id}{shape}")

            if i < len(plan.subtasks) - 1:
                next_id = f"Step{plan.subtasks[i + 1].id}"
                lines.append(f"    {step_id} --> {next_id}")
            else:
                lines.append(f"    {step_id} --> End([ç»“æŸ])")

        # æ·»åŠ æ ·å¼
        lines.append("")
        for step in plan.subtasks:
            result = result_map.get(step.id)
            step_id = f"Step{step.id}"
            if result is None:
                lines.append(f"    style {step_id} fill:#E0E0E0")
            elif result.success:
                lines.append(f"    style {step_id} fill:#90EE90")
            else:
                lines.append(f"    style {step_id} fill:#FFB6C1")

        return "\n".join(lines)

    @staticmethod
    def generate_markdown_report(report_data: Dict[str, Any]) -> str:
        """ç”Ÿæˆ Markdown æ ¼å¼æŠ¥å‘Š"""
        lines = [
            "# æ™ºèƒ½ä½“æ‰§è¡ŒæŠ¥å‘Š",
            "",
            f"**Agent**: {report_data['agent_name']}",
            f"**æ„å›¾**: {report_data.get('intent', 'N/A')}",
            f"**æ‰§è¡Œæ—¶é—´**: {report_data['generated_at']}",
            f"**è€—æ—¶**: {report_data.get('duration_seconds', 'N/A')} ç§’",
        ]
        
        # æ·»åŠ è¿½è¸ª IDï¼ˆå¦‚æœæœ‰ï¼‰
        trace = report_data.get("trace", {})
        if trace.get("trace_id"):
            lines.append(f"**è¿½è¸ªID**: `{trace['trace_id']}`")
        
        lines.extend([
            "",
            "**ç”¨æˆ·è¾“å…¥**:",
            f"> {report_data['query']}",
            "",
            "---",
            "",
            "## æ‰§è¡Œç»Ÿè®¡",
            "",
            "| æŒ‡æ ‡ | å€¼ |",
            "|------|-----|",
            f"| æ€»æ­¥éª¤æ•° | {report_data['statistics']['total_steps']} |",
            f"| å·²æ‰§è¡Œ | {report_data['statistics']['executed_steps']} |",
            f"| æˆåŠŸ | {report_data['statistics']['successful_steps']} |",
            f"| å¤±è´¥ | {report_data['statistics']['failed_steps']} |",
            f"| æˆåŠŸç‡ | {report_data['statistics']['success_rate']}% |",
            "",
        ])
        
        # æ·»åŠ  LLM ä½¿ç”¨ç»Ÿè®¡ï¼ˆå¦‚æœæœ‰è¿½è¸ªæ•°æ®ï¼‰
        if trace.get("llm_usage"):
            llm = trace["llm_usage"]
            lines.extend([
                "## LLM è°ƒç”¨ç»Ÿè®¡",
                "",
                "| æŒ‡æ ‡ | å€¼ |",
                "|------|-----|",
                f"| æ€»è°ƒç”¨æ¬¡æ•° | {llm.get('total_calls', 0)} |",
                f"| æ€» Token æ•° | {llm.get('total_tokens', 0):,} |",
                f"| Prompt Tokens | {llm.get('prompt_tokens', 0):,} |",
                f"| Response Tokens | {llm.get('response_tokens', 0):,} |",
                "",
            ])
            
            # æŒ‰ç›®çš„åˆ†ç±»
            by_purpose = llm.get("by_purpose", {})
            if by_purpose:
                lines.extend([
                    "**æŒ‰è°ƒç”¨ç›®çš„åˆ†ç±»**:",
                    "",
                    "| ç›®çš„ | è°ƒç”¨æ¬¡æ•° | Token æ•° |",
                    "|------|----------|----------|",
                ])
                purpose_names = {
                    "planning": "ä»»åŠ¡è§„åˆ’",
                    "binding_plan": "ç»‘å®šè§„åˆ’",
                    "param_build": "å‚æ•°æ„é€ ",
                    "validation": "æœŸæœ›éªŒè¯",
                    "error_analysis": "é”™è¯¯åˆ†æ",
                    "param_fix": "å‚æ•°ä¿®æ­£",
                    "memory_query": "è®°å¿†æŸ¥è¯¢",
                    "memory_summary": "è®°å¿†æ€»ç»“",
                    "prompt_gen": "Promptç”Ÿæˆ",
                    "replan": "é‡è§„åˆ’",
                    "incremental_replan": "å¢é‡é‡è§„åˆ’",
                    "consistency_check": "ä¸€è‡´æ€§æ£€æŸ¥",
                    "checkpoint_register": "æ£€æŸ¥ç‚¹æ³¨å†Œ",
                    "working_memory": "å·¥ä½œè®°å¿†",
                    "other": "å…¶ä»–",
                }
                for purpose, data in by_purpose.items():
                    name = purpose_names.get(purpose, purpose)
                    lines.append(f"| {name} | {data.get('count', 0)} | {data.get('tokens', 0):,} |")
                lines.append("")
        
        # æ·»åŠ å‚æ•°ç»‘å®šç»Ÿè®¡ï¼ˆå¦‚æœæœ‰ï¼‰
        binding_ops = trace.get("binding_ops", {})
        if binding_ops and binding_ops.get("total_bindings", 0) > 0:
            total = binding_ops.get("total_bindings", 0)
            resolved = binding_ops.get("resolved_bindings", 0)
            fallback = binding_ops.get("fallback_bindings", 0)
            success_rate = (resolved / total * 100) if total > 0 else 0
            
            lines.extend([
                "## å‚æ•°ç»‘å®šç»Ÿè®¡",
                "",
                "| æŒ‡æ ‡ | å€¼ |",
                "|------|-----|",
                f"| ç»‘å®šè§„åˆ’æ¬¡æ•° | {binding_ops.get('plan_creates', 0)} |",
                f"| ç»‘å®šè§£ææ¬¡æ•° | {binding_ops.get('resolves', 0)} |",
                f"| LLM Fallback æ¬¡æ•° | {binding_ops.get('fallbacks', 0)} |",
                f"| æ€»ç»‘å®šæ•° | {total} |",
                f"| æˆåŠŸè§£æ | {resolved} |",
                f"| éœ€è¦ Fallback | {fallback} |",
                f"| ç»‘å®šæˆåŠŸç‡ | {success_rate:.1f}% |",
                "",
            ])
        
        # æ·»åŠ æµç¨‹äº‹ä»¶ç»Ÿè®¡ï¼ˆå¦‚æœæœ‰ï¼‰
        if trace.get("flow_events"):
            flow = trace["flow_events"]
            total_events = sum(flow.values())
            if total_events > 0:
                lines.extend([
                    "## æµç¨‹æ§åˆ¶äº‹ä»¶",
                    "",
                    "| äº‹ä»¶ç±»å‹ | æ¬¡æ•° |",
                    "|----------|------|",
                    f"| é‡è¯• | {flow.get('retries', 0)} |",
                    f"| è·³è½¬ | {flow.get('jumps', 0)} |",
                    f"| ä¸­æ­¢ | {flow.get('aborts', 0)} |",
                    f"| é‡è§„åˆ’ | {flow.get('replans', 0)} |",
                    "",
                ])
        
        # æ·»åŠ ä¸€è‡´æ€§æ£€æŸ¥ç‚¹ï¼ˆå¦‚æœæœ‰ï¼‰
        checkpoints = report_data.get("checkpoints", [])
        if checkpoints:
            lines.extend([
                "## ä¸€è‡´æ€§æ£€æŸ¥ç‚¹",
                "",
                "æ‰§è¡Œè¿‡ç¨‹ä¸­æ³¨å†Œçš„å…³é”®æ£€æŸ¥ç‚¹ï¼Œç”¨äºåç»­ä¸€è‡´æ€§éªŒè¯å’Œé—®é¢˜ä¿®æ­£ã€‚",
                "",
            ])
            for cp in checkpoints:
                cp_id = cp.get("checkpoint_id", "unknown")
                cp_type = cp.get("checkpoint_type", "unknown")
                step_id = cp.get("step_id", "?")
                
                lines.append(f"### ğŸ“ {cp_id} [{cp_type}]")
                lines.append("")
                lines.append(f"- **æ­¥éª¤**: Step {step_id}")
                
                # æ˜¾ç¤ºå…³é”®å…ƒç´ 
                key_elements = cp.get("key_elements", {})
                if key_elements:
                    lines.append("- **å…³é”®å…ƒç´ **:")
                    for elem_type, elements in key_elements.items():
                        if isinstance(elements, list):
                            lines.append(f"  - {elem_type}: {', '.join(str(e) for e in elements[:10])}")
                            if len(elements) > 10:
                                lines.append(f"    ... è¿˜æœ‰ {len(elements) - 10} ä¸ª")
                        else:
                            lines.append(f"  - {elem_type}: {elements}")
                
                # æ˜¾ç¤ºçº¦æŸ
                constraints = cp.get("constraints", [])
                if constraints:
                    lines.append("- **çº¦æŸæ¡ä»¶**:")
                    for c in constraints[:5]:
                        lines.append(f"  - {c}")
                    if len(constraints) > 5:
                        lines.append(f"  - ... è¿˜æœ‰ {len(constraints) - 5} æ¡")
                
                lines.append("")
        
        # æ·»åŠ ä¸€è‡´æ€§è¿è§„ï¼ˆå¦‚æœæœ‰ï¼‰
        violations = report_data.get("consistency_violations", [])
        if violations:
            lines.extend([
                "## âš ï¸ ä¸€è‡´æ€§è¿è§„",
                "",
                "æ‰§è¡Œè¿‡ç¨‹ä¸­æ£€æµ‹åˆ°çš„ä¸€è‡´æ€§é—®é¢˜ï¼Œå¯ç”¨äºåç»­ä¿®æ­£ã€‚",
                "",
                "| ä¸¥é‡ç¨‹åº¦ | æ£€æŸ¥ç‚¹ | é—®é¢˜æè¿° | å»ºè®® |",
                "|----------|--------|----------|------|",
            ])
            for v in violations:
                severity = v.get("severity", "warning")
                severity_icon = "ğŸ”´" if severity == "critical" else "ğŸŸ¡"
                cp_id = v.get("checkpoint_id", "N/A")
                desc = v.get("description", "æœªçŸ¥é—®é¢˜")[:50]
                suggestion = v.get("suggestion", "")[:30]
                lines.append(f"| {severity_icon} {severity} | {cp_id} | {desc} | {suggestion} |")
            lines.append("")
        
        # æ·»åŠ å·¥ä½œè®°å¿†ï¼ˆå¦‚æœæœ‰ï¼‰
        working_memory = report_data.get("working_memory", {})
        if working_memory:
            lines.extend([
                "## ğŸ§  å·¥ä½œè®°å¿†",
                "",
                "æ‰§è¡Œè¿‡ç¨‹ä¸­æå–çš„è®¾è®¡å†³ç­–ã€çº¦æŸå’Œå¾…åŠäº‹é¡¹ã€‚",
                "",
            ])
            
            # è®¾è®¡å†³ç­–
            decisions = working_memory.get("decisions", [])
            if decisions:
                lines.append("### è®¾è®¡å†³ç­–")
                lines.append("")
                for d in decisions[:10]:
                    decision = d.get("decision", "")
                    rationale = d.get("rationale", "")
                    step = d.get("step_id", "?")
                    lines.append(f"- **[Step {step}]** {decision}")
                    if rationale:
                        lines.append(f"  - ç†ç”±: {rationale[:100]}")
                if len(decisions) > 10:
                    lines.append(f"- ... è¿˜æœ‰ {len(decisions) - 10} æ¡å†³ç­–")
                lines.append("")
            
            # çº¦æŸæ¡ä»¶
            constraints = working_memory.get("constraints", [])
            if constraints:
                lines.append("### çº¦æŸæ¡ä»¶")
                lines.append("")
                for c in constraints[:10]:
                    constraint = c.get("constraint", "")
                    source = c.get("source", "")
                    lines.append(f"- {constraint}")
                    if source:
                        lines.append(f"  - æ¥æº: {source}")
                if len(constraints) > 10:
                    lines.append(f"- ... è¿˜æœ‰ {len(constraints) - 10} æ¡çº¦æŸ")
                lines.append("")
            
            # æ¥å£å®šä¹‰
            interfaces = working_memory.get("interfaces", [])
            if interfaces:
                lines.append("### æ¥å£å®šä¹‰")
                lines.append("")
                for iface in interfaces[:10]:
                    name = iface.get("name", "unknown")
                    iface_type = iface.get("type", "")
                    lines.append(f"- **{name}** ({iface_type})")
                    signature = iface.get("signature", "")
                    if signature:
                        lines.append(f"  ```")
                        lines.append(f"  {signature[:200]}")
                        lines.append(f"  ```")
                if len(interfaces) > 10:
                    lines.append(f"- ... è¿˜æœ‰ {len(interfaces) - 10} ä¸ªæ¥å£")
                lines.append("")
            
            # å¾…åŠäº‹é¡¹
            todos = working_memory.get("todos", [])
            if todos:
                lines.append("### å¾…åŠäº‹é¡¹")
                lines.append("")
                for t in todos[:10]:
                    todo = t.get("todo", "")
                    priority = t.get("priority", "medium")
                    status = t.get("status", "pending")
                    status_icon = "âœ…" if status == "done" else "â³"
                    lines.append(f"- {status_icon} [{priority}] {todo}")
                if len(todos) > 10:
                    lines.append(f"- ... è¿˜æœ‰ {len(todos) - 10} æ¡å¾…åŠ")
                lines.append("")
        
        lines.extend([
            "## æ‰§è¡Œæµç¨‹",
            "",
            "```mermaid",
            report_data["mermaid_diagram"],
            "```",
            "",
            "## æ­¥éª¤è¯¦æƒ…",
            "",
        ])

        for step in report_data["steps"]:
            status_icon = {
                "success": "âœ…",
                "failed": "âŒ",
                "pending": "â³",
            }.get(step["status"], "â“")

            lines.append(f"### {status_icon} æ­¥éª¤ {step['step']}: {step['name']}")
            lines.append("")
            lines.append(f"- **æè¿°**: {step['description']}")
            if step.get("expectations"):
                lines.append(f"- **æœŸæœ›**: {step['expectations']}")
            lines.append(f"- **çŠ¶æ€**: {step['status']}")
            if step.get("error"):
                lines.append(f"- **é”™è¯¯**: `{step['error']}`")
            lines.append("")

        if report_data.get("errors"):
            lines.append("## é”™è¯¯ä¿¡æ¯")
            lines.append("")
            for err in report_data["errors"]:
                lines.append(f"- {err}")
            lines.append("")

        return "\n".join(lines)
    
    @staticmethod
    def generate_detailed_markdown_report(
        report_data: Dict[str, Any],
        trace_data: Optional[Dict[str, Any]] = None,
        show_full_content: bool = True,
    ) -> str:
        """
        ç”Ÿæˆè¯¦ç»†çš„ Markdown æŠ¥å‘Šï¼ˆåŒ…å«å®Œæ•´è¿½è¸ªä¿¡æ¯ï¼‰
        
        Args:
            report_data: åŸºç¡€æŠ¥å‘Šæ•°æ®
            trace_data: å®Œæ•´è¿½è¸ªæ•°æ®ï¼ˆåŒ…å«æ‰€æœ‰ spans å’Œ eventsï¼‰
                - å»ºè®®ä½¿ç”¨ trace_fullï¼ˆä¸æˆªæ–­ç‰ˆæœ¬ï¼‰ä»¥è·å–å®Œæ•´å†…å®¹
            show_full_content: æ˜¯å¦æ˜¾ç¤ºå®Œæ•´çš„ prompt/response å†…å®¹
                - True: æ˜¾ç¤ºå®Œæ•´å†…å®¹ï¼ˆé€‚åˆè¯¦ç»†åˆ†æï¼‰
                - False: æ˜¾ç¤ºé¢„è§ˆï¼ˆé€‚åˆå¿«é€Ÿæµè§ˆï¼‰
            
        Returns:
            è¯¦ç»†çš„ Markdown æŠ¥å‘Š
        """
        # å…ˆç”ŸæˆåŸºç¡€æŠ¥å‘Š
        lines = [ExecutionReportGenerator.generate_markdown_report(report_data)]
        
        if not trace_data:
            return lines[0]
        
        # æ·»åŠ è¯¦ç»†è¿½è¸ªä¿¡æ¯
        lines.extend([
            "",
            "---",
            "",
            "## è¯¦ç»†è¿½è¸ªæ—¥å¿—",
            "",
        ])
        
        # éå†æ‰€æœ‰ spans
        root_span = trace_data.get("spans", {})
        if root_span:
            lines.extend(ExecutionReportGenerator._format_span_tree(root_span, 0, show_full_content))
        
        return "\n".join(lines)
    
    @staticmethod
    def _format_span_tree(span: Dict[str, Any], depth: int, show_full: bool = True) -> List[str]:
        """
        é€’å½’æ ¼å¼åŒ– span æ ‘
        
        Args:
            span: span æ•°æ®
            depth: ç¼©è¿›æ·±åº¦
            show_full: æ˜¯å¦æ˜¾ç¤ºå®Œæ•´å†…å®¹
        """
        lines = []
        indent = "  " * depth
        
        name = span.get("name", "unknown")
        span_type = span.get("span_type", "")
        duration = span.get("duration_ms", 0)
        
        if name != "root":
            type_badge = f"[{span_type}]" if span_type else ""
            lines.append(f"{indent}### {type_badge} {name} ({duration:.1f}ms)")
            lines.append("")
        
        # æ ¼å¼åŒ–äº‹ä»¶
        events = span.get("events", [])
        for event in events:
            event_lines = ExecutionReportGenerator._format_event(event, depth + 1, show_full)
            lines.extend(event_lines)
        
        # é€’å½’å¤„ç†å­ spans
        children = span.get("children", [])
        for child in children:
            lines.extend(ExecutionReportGenerator._format_span_tree(child, depth + 1, show_full))
        
        return lines
    
    @staticmethod
    def _format_event(event: Dict[str, Any], depth: int, show_full: bool = True) -> List[str]:
        """
        æ ¼å¼åŒ–å•ä¸ªäº‹ä»¶
        
        Args:
            event: äº‹ä»¶æ•°æ®
            depth: ç¼©è¿›æ·±åº¦
            show_full: æ˜¯å¦æ˜¾ç¤ºå®Œæ•´å†…å®¹ï¼ˆé»˜è®¤ Trueï¼‰
        """
        lines = []
        indent = "  " * depth
        event_type = event.get("event_type", "unknown")
        
        if event_type == "llm_call":
            purpose = event.get("purpose", "unknown")
            model = event.get("model", "unknown")
            tokens = event.get("total_tokens", 0)
            duration = event.get("duration_ms", 0)
            
            lines.append(f"{indent}- ğŸ¤– **LLMè°ƒç”¨** [{purpose}]")
            lines.append(f"{indent}  - æ¨¡å‹: {model}")
            lines.append(f"{indent}  - Tokens: {tokens:,} ({duration:.1f}ms)")
            
            # æ˜¾ç¤º promptï¼ˆå®Œæ•´æˆ–é¢„è§ˆï¼‰
            prompt = event.get("prompt", event.get("prompt_preview", ""))
            if prompt:
                if show_full:
                    # ä½¿ç”¨ä»£ç å—æ˜¾ç¤ºå®Œæ•´ prompt
                    lines.append(f"{indent}  - **Prompt**:")
                    lines.append(f"{indent}    ```")
                    for line in prompt.split("\n"):
                        lines.append(f"{indent}    {line}")
                    lines.append(f"{indent}    ```")
                else:
                    preview = prompt[:200] + "..." if len(prompt) > 200 else prompt
                    lines.append(f"{indent}  - Prompt: `{preview}`")
            
            # æ˜¾ç¤º responseï¼ˆå®Œæ•´æˆ–é¢„è§ˆï¼‰
            response = event.get("response", event.get("response_preview", ""))
            if response and show_full:
                lines.append(f"{indent}  - **Response**:")
                lines.append(f"{indent}    ```")
                for line in response.split("\n"):
                    lines.append(f"{indent}    {line}")
                lines.append(f"{indent}    ```")
            
            lines.append("")
            
        elif event_type == "tool_call":
            tool_name = event.get("tool_name", "unknown")
            success = event.get("success", False)
            duration = event.get("duration_ms", 0)
            status = "âœ…" if success else "âŒ"
            
            lines.append(f"{indent}- ğŸ”§ **å·¥å…·è°ƒç”¨** {status} `{tool_name}` ({duration:.1f}ms)")
            
            if not success and event.get("error"):
                lines.append(f"{indent}  - é”™è¯¯: {event['error']}")
            
            lines.append("")
            
        elif event_type == "flow":
            action = event.get("action", "unknown")
            reason = event.get("reason", "")
            from_step = event.get("from_step", "")
            to_step = event.get("to_step", "")
            
            action_icons = {
                "retry": "ğŸ”„",
                "jump": "â­ï¸",
                "abort": "ğŸ›‘",
                "replan": "ğŸ“‹",
                "fallback": "â†©ï¸",
            }
            icon = action_icons.get(action, "â“")
            
            lines.append(f"{indent}- {icon} **æµç¨‹æ§åˆ¶** [{action}]")
            lines.append(f"{indent}  - åŸå› : {reason}")
            if from_step:
                lines.append(f"{indent}  - ä»æ­¥éª¤: {from_step}")
            if to_step:
                lines.append(f"{indent}  - åˆ°æ­¥éª¤: {to_step}")
            lines.append("")
            
        elif event_type == "memory":
            action = event.get("action", "unknown")
            layer = event.get("memory_layer", "")
            result_count = event.get("result_count", 0)
            
            lines.append(f"{indent}- ğŸ§  **è®°å¿†æ“ä½œ** [{action}] {layer}")
            if result_count:
                lines.append(f"{indent}  - ç»“æœæ•°: {result_count}")
            lines.append("")
        
        return lines

    @staticmethod
    def _compress_output(output: Any) -> Any:
        """å‹ç¼©è¾“å‡ºæ•°æ®"""
        if output is None:
            return None
        if isinstance(output, dict):
            compressed = {}
            for k, v in output.items():
                if k == "documents" and isinstance(v, list):
                    compressed[k] = f"[{len(v)} documents]"
                elif isinstance(v, str) and len(v) > 200:
                    compressed[k] = v[:200] + "..."
                elif isinstance(v, list) and len(v) > 10:
                    compressed[k] = f"[{len(v)} items]"
                else:
                    compressed[k] = v
            return compressed
        return output

    @staticmethod
    def _compress_state(state: Dict[str, Any]) -> Dict[str, Any]:
        """å‹ç¼©çŠ¶æ€æ•°æ®"""
        compressed = {}
        for k, v in state.items():
            if k in ["inputs", "control"]:
                compressed[k] = v
            elif isinstance(v, list) and len(v) > 5:
                compressed[k] = f"[{len(v)} items]"
            elif isinstance(v, dict) and len(str(v)) > 500:
                compressed[k] = f"{{...{len(v)} keys}}"
            elif isinstance(v, str) and len(v) > 200:
                compressed[k] = v[:200] + "..."
            else:
                compressed[k] = v
        return compressed
