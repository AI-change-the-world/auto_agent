# Auto-Agent ä¼˜åŒ–ç­–ç•¥æ–‡æ¡£

<p align="center">
  <img src="https://img.shields.io/badge/Version-v1.0-blue" alt="Version" />
  <img src="https://img.shields.io/badge/Framework-Auto--Agent%20v0.1%2B-brightgreen" alt="Framework" />
  <img src="https://img.shields.io/badge/Last%20Updated-2024-orange" alt="Last Updated" />
</p>

## ğŸ“‹ ç›®å½•

- [1. æ€§èƒ½ä¼˜åŒ–](#1-æ€§èƒ½ä¼˜åŒ–)
- [2. æ¶æ„ä¼˜åŒ–](#2-æ¶æ„ä¼˜åŒ–)
- [3. è®°å¿†ç³»ç»Ÿä¼˜åŒ–](#3-è®°å¿†ç³»ç»Ÿä¼˜åŒ–)
- [4. LLM äº¤äº’ä¼˜åŒ–](#4-llm-äº¤äº’ä¼˜åŒ–)
- [5. å¯é æ€§ä¸å®¹é”™ä¼˜åŒ–](#5-å¯é æ€§ä¸å®¹é”™ä¼˜åŒ–)
- [6. å¯è§‚æµ‹æ€§ä¼˜åŒ–](#6-å¯è§‚æµ‹æ€§ä¼˜åŒ–)
- [7. æˆæœ¬ä¼˜åŒ–](#7-æˆæœ¬ä¼˜åŒ–)
- [8. å¼€å‘ä½“éªŒä¼˜åŒ–](#8-å¼€å‘ä½“éªŒä¼˜åŒ–)
- [9. å®æ–½è·¯çº¿å›¾](#9-å®æ–½è·¯çº¿å›¾)
- [10. é™„å½•](#10-é™„å½•)

---

## ğŸ“– æ¦‚è¿°

æœ¬æ–‡æ¡£è¯¦ç»†é˜è¿°äº† Auto-Agent æ™ºèƒ½ä½“æ¡†æ¶çš„å…¨é¢ä¼˜åŒ–ç­–ç•¥ï¼Œæ—¨åœ¨æå‡ç³»ç»Ÿæ€§èƒ½ã€å¯é æ€§ã€å¯ç»´æŠ¤æ€§å’Œå¼€å‘ä½“éªŒã€‚é€šè¿‡å®æ–½è¿™äº›ä¼˜åŒ–æªæ–½ï¼Œæˆ‘ä»¬æœŸæœ›èƒ½å¤Ÿæ˜¾è‘—æ”¹å–„æ¡†æ¶çš„æ•´ä½“è¡¨ç°å’Œç”¨æˆ·ä½“éªŒã€‚

### ğŸ” ä¼˜åŒ–ç»´åº¦æ¦‚è§ˆ

| ç»´åº¦     | æ ¸å¿ƒç›®æ ‡           | é¢„æœŸæ”¶ç›Š              |
| -------- | ------------------ | --------------------- |
| æ€§èƒ½ä¼˜åŒ– | æå‡æ‰§è¡Œæ•ˆç‡       | å“åº”é€Ÿåº¦æå‡ 40-70%   |
| æ¶æ„ä¼˜åŒ– | å¢å¼ºæ‰©å±•æ€§å’Œçµæ´»æ€§ | æ”¯æŒæ’ä»¶åŒ–å’Œæµå¼å¤„ç†  |
| è®°å¿†ç³»ç»Ÿ | ä¼˜åŒ–å­˜å‚¨å’Œæ£€ç´¢     | æ£€ç´¢æ•ˆç‡æå‡ 10-50 å€ |
| LLM äº¤äº’ | æé«˜äº¤äº’è´¨é‡å’Œæ•ˆç‡ | æˆæœ¬é™ä½ 30-50%       |
| å¯é æ€§   | å¢å¼ºç³»ç»Ÿç¨³å®šæ€§     | å¯ç”¨æ€§æå‡è‡³ 99.9%+   |
| å¯è§‚æµ‹æ€§ | å®Œå–„ç›‘æ§å’Œè¯Šæ–­     | é—®é¢˜å®šä½æ—¶é—´ < 5 åˆ†é’Ÿ |
| æˆæœ¬ä¼˜åŒ– | é™ä½è¿è¥æˆæœ¬       | æ€»ä½“æˆæœ¬é™ä½ 50-70%   |
| å¼€å‘ä½“éªŒ | æå‡å¼€å‘æ•ˆç‡       | è°ƒè¯•æ•ˆç‡æå‡ 3 å€     |

<a name="1-æ€§èƒ½ä¼˜åŒ–"></a>
# ğŸš€ 1. æ€§èƒ½ä¼˜åŒ–

<a name="11-å¹¶è¡Œæ‰§è¡Œä¼˜åŒ–"></a>
## âš¡ 1.1 å¹¶è¡Œæ‰§è¡Œä¼˜åŒ–

### ç°çŠ¶é—®é¢˜

- å½“å‰ ExecutionEngine é¡ºåºæ‰§è¡Œæ‰€æœ‰å­ä»»åŠ¡
- å­˜åœ¨å¤§é‡å¯å¹¶è¡Œçš„ç‹¬ç«‹ä»»åŠ¡æœªè¢«ä¼˜åŒ–

### ä¼˜åŒ–ç­–ç•¥

```python
# ä¼˜åŒ–å‰ (executor.py)
for subtask in plan.subtasks:
    result = await self._execute_subtask(subtask)
    results.append(result)

# ä¼˜åŒ–åï¼šåŸºäºä¾èµ–å…³ç³»çš„å¹¶è¡Œæ‰§è¡Œ
async def execute_plan_parallel(self, plan: ExecutionPlan):
    """æ ¹æ®ä¾èµ–å…³ç³»æ„å»º DAGï¼Œå¹¶è¡Œæ‰§è¡Œç‹¬ç«‹ä»»åŠ¡"""
    dag = self._build_dependency_graph(plan.subtasks)
    
    # åˆ†å±‚æ‰§è¡Œï¼šåŒä¸€å±‚çš„ä»»åŠ¡å¹¶è¡Œ
    for level in dag.levels:
        tasks = [self._execute_subtask(task) for task in level]
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # å¤„ç†å¼‚å¸¸å¹¶å†³å®šæ˜¯å¦ç»§ç»­
        if not self._handle_level_results(results):
            break
    
    return self._aggregate_results(results)
```

### å®ç°è¦ç‚¹

- åœ¨ Subtask æ¨¡å‹ä¸­æ·»åŠ  dependencies: List[str] å­—æ®µï¼ˆå·²æœ‰ï¼‰
- å®ç°æ‹“æ‰‘æ’åºç®—æ³•æ„å»ºæ‰§è¡Œå±‚çº§
- ä½¿ç”¨ asyncio.gather() å¹¶è¡Œæ‰§è¡ŒåŒå±‚ä»»åŠ¡
- æ·»åŠ å±‚çº§å¤±è´¥ç­–ç•¥ï¼ˆfail-fast / continue-on-errorï¼‰

### é¢„æœŸæ”¶ç›Š

- å¤æ‚ä»»åŠ¡æ‰§è¡Œæ—¶é—´å‡å°‘ 40-60%
- æå‡ç”¨æˆ·ä½“éªŒå“åº”é€Ÿåº¦
<a name="12-llm-è¯·æ±‚æ‰¹å¤„ç†ä¸ç¼“å­˜"></a>
## ğŸ—ƒï¸ 1.2 LLM è¯·æ±‚æ‰¹å¤„ç†ä¸ç¼“å­˜

### ç°çŠ¶é—®é¢˜

- é‡å¤çš„ LLM è¯·æ±‚æœªç¼“å­˜
- Planningã€Error Analysis ç­‰ç¯èŠ‚é¢‘ç¹è°ƒç”¨ LLM

### ä¼˜åŒ–ç­–ç•¥

```python
# æ–°å¢ llm/cache.py
from functools import lru_cache
import hashlib
import json

class LLMCache:
    """LLM å“åº”ç¼“å­˜å±‚"""
    
    def __init__(self, backend='redis', ttl=3600):
        self.backend = backend  # æ”¯æŒ redis/memory/disk
        self.ttl = ttl
    
    def get_cache_key(self, prompt: str, model: str, params: dict) -> str:
        """ç”Ÿæˆç¼“å­˜é”®"""
        content = f"{model}:{prompt}:{json.dumps(params, sort_keys=True)}"
        return hashlib.sha256(content.encode()).hexdigest()
    
    async def get_or_call(self, prompt, model, params, call_func):
        """ç¼“å­˜ä¼˜å…ˆç­–ç•¥"""
        cache_key = self.get_cache_key(prompt, model, params)
        
        # å°è¯•ä»ç¼“å­˜è·å–
        cached = await self._get_from_cache(cache_key)
        if cached:
            return cached
        
        # ç¼“å­˜æœªå‘½ä¸­ï¼Œè°ƒç”¨ LLM
        result = await call_func(prompt, model, params)
        await self._set_cache(cache_key, result, self.ttl)
        
        return result
```

### ç¼“å­˜ç­–ç•¥

- **çƒ­ç¼“å­˜**: å¸¸è§æ„å›¾è¯†åˆ«ã€å·¥å…·æè¿°ï¼ˆTTL: 1å°æ—¶ï¼‰
- **ä¼šè¯ç¼“å­˜**: å½“å‰å¯¹è¯ä¸­çš„ä¸­é—´ç»“æœï¼ˆTTL: å¯¹è¯ç»“æŸï¼‰
- **è¯­ä¹‰ç¼“å­˜**: ä½¿ç”¨å‘é‡ç›¸ä¼¼åº¦åŒ¹é…è¿‘ä¼¼æŸ¥è¯¢ï¼ˆç›¸ä¼¼åº¦ > 0.95ï¼‰

### é¢„æœŸæ”¶ç›Š

- LLM è°ƒç”¨å‡å°‘ 30-50%
- å“åº”æ—¶é—´å‡å°‘ 200-500ms
- API æˆæœ¬é™ä½ 30-40%
<a name="13-è®°å¿†ç³»ç»Ÿç´¢å¼•ä¼˜åŒ–"></a>
## ğŸ” 1.3 è®°å¿†ç³»ç»Ÿç´¢å¼•ä¼˜åŒ–

### ç°çŠ¶é—®é¢˜

- LongTermMemory çš„æ–‡æœ¬æœç´¢æ•ˆç‡ä½
- ç¼ºå°‘å‘é‡ç´¢å¼•å’Œå…¨æ–‡æœç´¢å¼•æ“

### ä¼˜åŒ–ç­–ç•¥

```python
# ä¼˜åŒ– memory/long_term.py
class LongTermMemory:
    def __init__(self, vector_db='chromadb'):
        self.vector_store = self._init_vector_db(vector_db)
        self.full_text_index = self._init_fts_engine()  # SQLite FTS5
    
    async def search_context(self, query: str, top_k=5) -> List[str]:
        """æ··åˆæ£€ç´¢ï¼šå‘é‡ + å…³é”®è¯"""
        # 1. å‘é‡æ£€ç´¢ï¼ˆè¯­ä¹‰ç›¸ä¼¼ï¼‰
        vector_results = await self.vector_store.similarity_search(
            query, k=top_k
        )
        
        # 2. å…¨æ–‡æ£€ç´¢ï¼ˆç²¾ç¡®åŒ¹é…ï¼‰
        fts_results = await self.full_text_index.search(
            query, k=top_k
        )
        
        # 3. èåˆæ’åºï¼ˆRRF - Reciprocal Rank Fusionï¼‰
        return self._merge_results(vector_results, fts_results)
```

### æŠ€æœ¯é€‰å‹

- **å‘é‡æ•°æ®åº“**: ChromaDB / Qdrantï¼ˆå°è§„æ¨¡ï¼‰, Milvusï¼ˆå¤§è§„æ¨¡ï¼‰
- **å…¨æ–‡æœç´¢**: SQLite FTS5 / Elasticsearch
- **æ··åˆæ£€ç´¢ç®—æ³•**: RRF / Linear Combination

### é¢„æœŸæ”¶ç›Š

- è®°å¿†æ£€ç´¢é€Ÿåº¦æå‡ 10-50 å€
- ä¸Šä¸‹æ–‡ç›¸å…³æ€§æé«˜ 25%+
<a name="2-æ¶æ„ä¼˜åŒ–"></a>
# ğŸ—ï¸ 2. æ¶æ„ä¼˜åŒ–

<a name="21-æ’ä»¶åŒ–å·¥å…·ç³»ç»Ÿ"></a>
## ğŸ”Œ 2.1 æ’ä»¶åŒ–å·¥å…·ç³»ç»Ÿ

### ç°çŠ¶é—®é¢˜

- æ‰€æœ‰å·¥å…·ç¡¬ç¼–ç åœ¨ tools/ ç›®å½•
- ç¼ºå°‘åŠ¨æ€åŠ è½½å’Œçƒ­æ›´æ–°æœºåˆ¶

### ä¼˜åŒ–ç­–ç•¥

```python
# æ–°å¢ tools/plugin_manager.py
class ToolPluginManager:
    """å·¥å…·æ’ä»¶ç®¡ç†å™¨"""
    
    def __init__(self, plugin_dirs: List[str]):
        self.plugin_dirs = plugin_dirs
        self.registry = ToolRegistry()
    
    def load_plugins(self):
        """åŠ¨æ€åŠ è½½æ’ä»¶"""
        for plugin_dir in self.plugin_dirs:
            for file in Path(plugin_dir).glob("*.py"):
                self._load_plugin_file(file)
    
    def _load_plugin_file(self, file: Path):
        """åŠ è½½å•ä¸ªæ’ä»¶æ–‡ä»¶"""
        spec = importlib.util.spec_from_file_location(file.stem, file)
        module = importlib.util.module_from_spec(spec)
        spec.loader.exec_module(module)
        
        # è‡ªåŠ¨æ³¨å†Œæ‰€æœ‰ BaseTool å­ç±»
        for name, obj in inspect.getmembers(module):
            if inspect.isclass(obj) and issubclass(obj, BaseTool):
                self.registry.register_tool(obj())
```

### æ’ä»¶è§„èŒƒ

```yaml
# plugin.yaml
name: custom_calculator
version: 1.0.0
author: team@example.com
dependencies:
  - numpy>=1.20
  - sympy>=1.9
entry_point: calculator.py:AdvancedCalculator
```

### é¢„æœŸæ”¶ç›Š

- æ”¯æŒç¬¬ä¸‰æ–¹å·¥å…·æ‰©å±•
- æ— éœ€é‡å¯å³å¯æ›´æ–°å·¥å…·
- éš”ç¦»æ•…éšœå·¥å…·å½±å“èŒƒå›´
<a name="22-æµå¼å“åº”æ¶æ„"></a>
## ğŸŒŠ 2.2 æµå¼å“åº”æ¶æ„

### ç°çŠ¶é—®é¢˜

- å½“å‰å¿…é¡»ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆæ‰è¿”å›ç»“æœ
- é•¿ä»»åŠ¡ç¼ºå°‘ä¸­é—´è¿›åº¦åé¦ˆ

### ä¼˜åŒ–ç­–ç•¥

```python
# æ”¹é€  orchestrator.py
class AgentOrchestrator:
    async def run_streaming(self, user_input: str):
        """æµå¼è¿”å›ä»»åŠ¡æ‰§è¡Œè¿›åº¦"""
        async for event in self._execute_with_streaming(user_input):
            yield event  # SSE / WebSocket
    
    async def _execute_with_streaming(self, user_input):
        """ç”Ÿæˆå™¨æ¨¡å¼æ‰§è¡Œ"""
        # 1. Planning é˜¶æ®µ
        yield StreamEvent(type='planning', data={'status': 'started'})
        plan = await self.planner.plan(...)
        yield StreamEvent(type='planning', data={'plan': plan.dict()})
        
        # 2. Execution é˜¶æ®µ
        for i, subtask in enumerate(plan.subtasks):
            yield StreamEvent(
                type='subtask_started',
                data={'index': i, 'description': subtask.description}
            )
            
            result = await self.executor.execute_subtask(subtask)
            
            yield StreamEvent(
                type='subtask_completed',
                data={'index': i, 'result': result}
            )
        
        # 3. æœ€ç»ˆç»“æœ
        yield StreamEvent(type='completed', data={'final_result': ...})
```

### å‰ç«¯é›†æˆ

```javascript
// ä½¿ç”¨ SSE æ¥æ”¶æµå¼å“åº”
const eventSource = new EventSource('/api/agent/stream');
eventSource.onmessage = (event) => {
  const data = JSON.parse(event.data);
  updateUI(data);  // å®æ—¶æ›´æ–° UI
};
```

### é¢„æœŸæ”¶ç›Š

- ç”¨æˆ·æ„ŸçŸ¥å»¶è¿Ÿé™ä½ 70%+
- æä¾›å®æ—¶è¿›åº¦å±•ç¤º
- æ”¯æŒé•¿æ—¶é—´ä»»åŠ¡çš„é€æ˜åº¦
<a name="3-è®°å¿†ç³»ç»Ÿä¼˜åŒ–"></a>
# ğŸ§  3. è®°å¿†ç³»ç»Ÿä¼˜åŒ–

<a name="31-åˆ†å±‚è®°å¿†æ¶æ„"></a>
## ğŸ“š 3.1 åˆ†å±‚è®°å¿†æ¶æ„

### ç°çŠ¶é—®é¢˜

- LTM å’Œ STM è¾¹ç•Œæ¨¡ç³Š
- ç¼ºå°‘ä¸­æœŸè®°å¿†ï¼ˆå·¥ä½œè®°å¿†ï¼‰

### ä¼˜åŒ–ç­–ç•¥

è®°å¿†åˆ†å±‚æ¶æ„ï¼š
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Sensory Memory (æ„ŸçŸ¥è®°å¿†)           â”‚ â† åŸå§‹è¾“å…¥ (1-2ç§’)
â”‚  - ç”¨æˆ·åŸå§‹è¾“å…¥                      â”‚
â”‚  - å·¥å…·åŸå§‹è¾“å‡º                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚ ç­›é€‰
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Working Memory (å·¥ä½œè®°å¿†)           â”‚ â† å½“å‰ä»»åŠ¡ (ä¼šè¯çº§)
â”‚  - å½“å‰æ‰§è¡Œè®¡åˆ’                      â”‚
â”‚  - ä¸­é—´ç»“æœ                          â”‚
â”‚  - é”™è¯¯ä¸Šä¸‹æ–‡                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚ é‡è¦ä¿¡æ¯æå–
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Short-Term Memory (çŸ­æœŸè®°å¿†)        â”‚ â† å¯¹è¯å†å² (1å¤©)
â”‚  - å®Œæ•´å¯¹è¯å†å²                      â”‚
â”‚  - ç”¨æˆ·åå¥½                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚ çŸ¥è¯†è’¸é¦
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Long-Term Memory (é•¿æœŸè®°å¿†)         â”‚ â† çŸ¥è¯†åº“ (æ°¸ä¹…)
â”‚  - å…³é”®äº‹å®                          â”‚
â”‚  - ç»éªŒæ€»ç»“                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### å®ç°

```python
# æ–°å¢ memory/working_memory.py
class WorkingMemory:
    """å·¥ä½œè®°å¿† - ä»»åŠ¡æ‰§è¡ŒæœŸé—´çš„ä¸´æ—¶çŠ¶æ€"""
    
    def __init__(self, max_slots=7):  # ç±³å‹’å®šå¾‹ï¼š7Â±2
        self.slots = []
        self.max_slots = max_slots
        self.attention_focus = None  # å½“å‰å…³æ³¨ç‚¹
    
    def add_item(self, item, priority='medium'):
        """æ·»åŠ é¡¹ç›®åˆ°å·¥ä½œè®°å¿†ï¼Œè‡ªåŠ¨æ·˜æ±°ä½ä¼˜å…ˆçº§"""
        if len(self.slots) >= self.max_slots:
            self._evict_lowest_priority()
        
        self.slots.append({
            'item': item,
            'priority': priority,
            'timestamp': time.time()
        })
    
    def get_context(self) -> str:
        """è·å–å½“å‰å·¥ä½œä¸Šä¸‹æ–‡"""
        # æŒ‰ä¼˜å…ˆçº§å’Œæ—¶é—´æ’åº
        sorted_items = sorted(
            self.slots,
            key=lambda x: (PRIORITY_MAP[x['priority']], -x['timestamp'])
        )
        return "\n".join([item['item'] for item in sorted_items])
```

### é¢„æœŸæ”¶ç›Š

- å‡å°‘ LLM ä¸Šä¸‹æ–‡çª—å£æµªè´¹
- æé«˜ä»»åŠ¡æ‰§è¡Œè¿è´¯æ€§
- é™ä½è®°å¿†ç³»ç»Ÿå­˜å‚¨æˆæœ¬
<a name="32-è‡ªé€‚åº”é—å¿˜æœºåˆ¶"></a>
## â™»ï¸ 3.2 è‡ªé€‚åº”é—å¿˜æœºåˆ¶

### ç°çŠ¶é—®é¢˜

- è®°å¿†æ— é™å¢é•¿å¯¼è‡´æ£€ç´¢æ•ˆç‡ä¸‹é™
- è¿‡æœŸä¿¡æ¯å¹²æ‰°å†³ç­–

### ä¼˜åŒ–ç­–ç•¥

```python
class AdaptiveForgetfulness:
    """è‡ªé€‚åº”é—å¿˜ç®—æ³•"""
    
    def calculate_retention_score(self, memory_item) -> float:
        """è®¡ç®—è®°å¿†ä¿ç•™åˆ†æ•° (0-1)"""
        # è‰¾å®¾æµ©æ–¯é—å¿˜æ›²çº¿ + é‡è¦æ€§æƒé‡
        time_decay = self._ebbinghaus_decay(memory_item.age)
        importance = memory_item.importance  # 0-1
        access_freq = memory_item.access_count / memory_item.age
        
        score = (
            0.4 * time_decay +
            0.4 * importance +
            0.2 * access_freq
        )
        
        return score
    
    def _ebbinghaus_decay(self, days: float) -> float:
        """è‰¾å®¾æµ©æ–¯é—å¿˜æ›²çº¿"""
        return math.exp(-days / 7)  # 7å¤©åŠè¡°æœŸ
    
    async def prune_memories(self, threshold=0.3):
        """å®šæœŸæ¸…ç†ä½åˆ†è®°å¿†"""
        for memory in self.memory_store:
            if self.calculate_retention_score(memory) < threshold:
                await self._archive_or_delete(memory)
```

### é—å¿˜ç­–ç•¥

- **è½¯åˆ é™¤**: ä½åˆ†è®°å¿†å½’æ¡£åˆ°å†·å­˜å‚¨
- **ä¸»åŠ¨é—å¿˜**: ç”¨æˆ·æ˜ç¡®è¯·æ±‚åˆ é™¤
- **æ™ºèƒ½å‹ç¼©**: å¤šæ¡ç›¸ä¼¼è®°å¿†åˆå¹¶ä¸ºæ‘˜è¦

### é¢„æœŸæ”¶ç›Š

- è®°å¿†æ•°æ®åº“å¤§å°å‡å°‘ 60%+
- æ£€ç´¢ç²¾åº¦æå‡ 15%
<a name="4-llm-äº¤äº’ä¼˜åŒ–"></a>
# ğŸ¤– 4. LLM äº¤äº’ä¼˜åŒ–

<a name="41-æç¤ºè¯å·¥ç¨‹ä¼˜åŒ–"></a>
## ğŸ’¬ 4.1 æç¤ºè¯å·¥ç¨‹ä¼˜åŒ–

### ç°çŠ¶é—®é¢˜

- æç¤ºè¯æ¨¡æ¿ç¼ºå°‘ç‰ˆæœ¬ç®¡ç†
- æ²¡æœ‰ A/B æµ‹è¯•æœºåˆ¶

### ä¼˜åŒ–ç­–ç•¥

```python
# æ–°å¢ llm/prompt_manager.py
class PromptManager:
    """æç¤ºè¯ç®¡ç†ä¸ä¼˜åŒ–"""
    
    def __init__(self):
        self.templates = {}
        self.versions = {}
        self.performance_metrics = {}
    
    def register_template(self, name: str, template: str, version: str):
        """æ³¨å†Œæç¤ºè¯æ¨¡æ¿"""
        key = f"{name}:{version}"
        self.templates[key] = template
        self.versions[name] = version
    
    async def get_optimized_prompt(self, name: str, context: dict):
        """è·å–ä¼˜åŒ–åçš„æç¤ºè¯"""
        # 1. é€‰æ‹©æœ€ä½³ç‰ˆæœ¬ï¼ˆåŸºäºå†å²æ€§èƒ½ï¼‰
        version = self._select_best_version(name)
        template = self.templates[f"{name}:{version}"]
        
        # 2. åŠ¨æ€å‹ç¼©ä¸Šä¸‹æ–‡
        compressed_context = await self._compress_context(context)
        
        # 3. å¡«å……æ¨¡æ¿
        prompt = template.format(**compressed_context)
        
        # 4. éªŒè¯ token æ•°
        if self._count_tokens(prompt) > MAX_TOKENS:
            prompt = await self._truncate_intelligently(prompt)
        
        return prompt
    
    def _select_best_version(self, name: str) -> str:
        """åŸºäº UCB ç®—æ³•é€‰æ‹©ç‰ˆæœ¬ï¼ˆæ¢ç´¢-åˆ©ç”¨å¹³è¡¡ï¼‰"""
        versions = [v for v in self.templates.keys() if v.startswith(name)]
        
        best_version = max(versions, key=lambda v: self._ucb_score(v))
        return best_version.split(':')[1]
    
    def _ucb_score(self, version: str) -> float:
        """Upper Confidence Bound åˆ†æ•°"""
        metrics = self.performance_metrics.get(version, {})
        avg_success = metrics.get('success_rate', 0.5)
        tries = metrics.get('tries', 1)
        total_tries = sum(m.get('tries', 0) for m in self.performance_metrics.values())
        
        exploration_bonus = math.sqrt(2 * math.log(total_tries) / tries)
        return avg_success + exploration_bonus
```

### æ¨¡æ¿ç‰ˆæœ¬ç®¡ç†

```yaml
# prompts/planning_v2.yaml
name: planning
version: v2.1
description: "ä¼˜åŒ–ï¼šå‡å°‘å†—ä½™æŒ‡ä»¤ï¼Œæé«˜ JSON è§£ææˆåŠŸç‡"
template: |
  ä½ æ˜¯ä»»åŠ¡è§„åˆ’å™¨ã€‚æ ¹æ®ç”¨æˆ·è¾“å…¥ç”Ÿæˆæ‰§è¡Œè®¡åˆ’ã€‚
  
  å¯ç”¨å·¥å…·ï¼š{tools}
  å†å²ä¸Šä¸‹æ–‡ï¼š{context}
  
  è¾“å‡º JSON æ ¼å¼ï¼š
  {
    "intent": "ç”¨æˆ·æ„å›¾",
    "subtasks": [...]
  }

metrics:
  success_rate: 0.94
  avg_tokens: 850
  avg_latency_ms: 1200
```

### é¢„æœŸæ”¶ç›Š

- æç¤ºè¯è´¨é‡æŒç»­æ”¹è¿›
- é™ä½ Token æ¶ˆè€— 20-30%
- æé«˜ JSON è§£ææˆåŠŸç‡è‡³ 95%+
<a name="42-å¤šæ¨¡å‹è·¯ç”±ç­–ç•¥"></a>
## ğŸ”„ 4.2 å¤šæ¨¡å‹è·¯ç”±ç­–ç•¥

### ç°çŠ¶é—®é¢˜

- æ‰€æœ‰ä»»åŠ¡ä½¿ç”¨åŒä¸€ä¸ª LLM æ¨¡å‹
- æœªæ ¹æ®ä»»åŠ¡å¤æ‚åº¦é€‰æ‹©æ¨¡å‹

### ä¼˜åŒ–ç­–ç•¥

```python
# æ–°å¢ llm/router.py
class ModelRouter:
    """æ™ºèƒ½æ¨¡å‹è·¯ç”±"""
    
    MODELS = {
        'simple': 'gpt-3.5-turbo',      # å¿«é€Ÿä¾¿å®œ
        'standard': 'gpt-4o-mini',      # å¹³è¡¡
        'complex': 'gpt-4o',            # å¤æ‚æ¨ç†
        'coding': 'claude-3-opus',      # ä»£ç ç”Ÿæˆ
    }
    
    async def route_request(self, task_type: str, context: dict) -> str:
        """æ ¹æ®ä»»åŠ¡ç±»å‹å’Œå¤æ‚åº¦è·¯ç”±åˆ°æœ€ä½³æ¨¡å‹"""
        complexity = self._estimate_complexity(context)
        
        if task_type == 'code_generation':
            return self.MODELS['coding']
        elif complexity < 0.3:
            return self.MODELS['simple']
        elif complexity < 0.7:
            return self.MODELS['standard']
        else:
            return self.MODELS['complex']
    
    def _estimate_complexity(self, context: dict) -> float:
        """ä¼°ç®—ä»»åŠ¡å¤æ‚åº¦ (0-1)"""
        factors = {
            'subtask_count': len(context.get('subtasks', [])) / 10,
            'dependency_depth': self._calc_dependency_depth(context) / 5,
            'context_length': len(str(context)) / 10000,
            'error_count': context.get('retry_count', 0) / 3,
        }
        
        # åŠ æƒå¹³å‡
        return min(1.0, sum(factors.values()) / len(factors))
```

### è·¯ç”±è§„åˆ™ç¤ºä¾‹

| ä»»åŠ¡ç±»å‹ | å¤æ‚åº¦ | é€‰æ‹©æ¨¡å‹      | åŸå›        |
| -------- | ------ | ------------- | ---------- |
| æ„å›¾è¯†åˆ« | ä½     | GPT-3.5       | é€Ÿåº¦ä¼˜å…ˆ   |
| ä»»åŠ¡è§„åˆ’ | ä¸­     | GPT-4o-mini   | å¹³è¡¡æ€§èƒ½   |
| ä»£ç ç”Ÿæˆ | é«˜     | Claude-3-Opus | ä»£ç èƒ½åŠ›å¼º |
| é”™è¯¯åˆ†æ | é«˜     | GPT-4o        | æ¨ç†èƒ½åŠ›å¼º |

### é¢„æœŸæ”¶ç›Š

- æˆæœ¬é™ä½ 40-50%
- å¹³å‡å“åº”é€Ÿåº¦æå‡ 30%
- å„ç±»ä»»åŠ¡å‡†ç¡®ç‡æå‡ 10-15%
<a name="5-å¯é æ€§ä¸å®¹é”™ä¼˜åŒ–"></a>
# ğŸ›¡ï¸ 5. å¯é æ€§ä¸å®¹é”™ä¼˜åŒ–

<a name="51-æ™ºèƒ½é‡è¯•ç­–ç•¥å‡çº§"></a>
## ğŸ” 5.1 æ™ºèƒ½é‡è¯•ç­–ç•¥å‡çº§

### ç°çŠ¶é—®é¢˜

- å½“å‰åªæœ‰ç®€å•çš„æŒ‡æ•°é€€é¿
- ç¼ºå°‘å¯¹ä¸åŒé”™è¯¯ç±»å‹çš„é’ˆå¯¹æ€§å¤„ç†

### ä¼˜åŒ–ç­–ç•¥

```python
# å‡çº§ retry/controller.py
class AdvancedRetryController:
    """å¢å¼ºå‹é‡è¯•æ§åˆ¶å™¨"""
    
    ERROR_STRATEGIES = {
        'rate_limit': {
            'strategy': 'exponential_backoff',
            'base_delay': 60,
            'max_retries': 5,
        },
        'timeout': {
            'strategy': 'linear_backoff',
            'base_delay': 5,
            'max_retries': 3,
        },
        'api_error': {
            'strategy': 'immediate_retry',
            'max_retries': 2,
        },
        'validation_error': {
            'strategy': 'replan',  # ä¸é‡è¯•ï¼Œç›´æ¥é‡æ–°è§„åˆ’
            'max_retries': 0,
        },
    }
    
    async def execute_with_smart_retry(self, func, *args, **kwargs):
        """æ ¹æ®é”™è¯¯ç±»å‹æ™ºèƒ½é‡è¯•"""
        attempt = 0
        last_error = None
        
        while attempt < self.max_retries:
            try:
                return await func(*args, **kwargs)
            
            except Exception as e:
                error_type = self._classify_error(e)
                strategy = self.ERROR_STRATEGIES.get(error_type)
                
                if not strategy or attempt >= strategy['max_retries']:
                    raise
                
                # æ‰§è¡Œå¯¹åº”ç­–ç•¥
                if strategy['strategy'] == 'replan':
                    return await self._trigger_replan(e, *args, **kwargs)
                
                delay = self._calculate_delay(strategy, attempt)
                await asyncio.sleep(delay)
                
                attempt += 1
                last_error = e
        
        raise last_error
    
    def _classify_error(self, error: Exception) -> str:
        """é”™è¯¯åˆ†ç±»"""
        error_msg = str(error).lower()
        
        if 'rate limit' in error_msg or '429' in error_msg:
            return 'rate_limit'
        elif 'timeout' in error_msg:
            return 'timeout'
        elif 'validation' in error_msg or 'schema' in error_msg:
            return 'validation_error'
        else:
            return 'api_error'
```

### æ–­è·¯å™¨æ¨¡å¼

```python
class CircuitBreaker:
    """é˜²æ­¢çº§è”æ•…éšœ"""
    
    def __init__(self, failure_threshold=5, timeout=60):
        self.failure_count = 0
        self.failure_threshold = failure_threshold
        self.timeout = timeout
        self.state = 'CLOSED'  # CLOSED/OPEN/HALF_OPEN
        self.last_failure_time = None
    
    async def call(self, func, *args, **kwargs):
        """é€šè¿‡æ–­è·¯å™¨è°ƒç”¨å‡½æ•°"""
        if self.state == 'OPEN':
            if time.time() - self.last_failure_time > self.timeout:
                self.state = 'HALF_OPEN'
            else:
                raise CircuitBreakerOpenError("Circuit breaker is OPEN")
        
        try:
            result = await func(*args, **kwargs)
            self._on_success()
            return result
        except Exception as e:
            self._on_failure()
            raise
    
    def _on_failure(self):
        self.failure_count += 1
        self.last_failure_time = time.time()
        
        if self.failure_count >= self.failure_threshold:
            self.state = 'OPEN'
    
    def _on_success(self):
        self.failure_count = 0
        self.state = 'CLOSED'
```

### é¢„æœŸæ”¶ç›Š

- ç³»ç»Ÿå¯ç”¨æ€§æå‡è‡³ 99.9%+
- å‡å°‘æ— æ•ˆé‡è¯• 70%
- é˜²æ­¢æœåŠ¡é›ªå´©
<a name="52-ä¼˜é›…é™çº§æœºåˆ¶"></a>
##  fallback"> 5.2 ä¼˜é›…é™çº§æœºåˆ¶

### ç°çŠ¶é—®é¢˜

- LLM ä¸å¯ç”¨æ—¶æ•´ä¸ªç³»ç»Ÿç˜«ç—ª
- ç¼ºå°‘é™çº§æ–¹æ¡ˆ

### ä¼˜åŒ–ç­–ç•¥

```python
class GracefulDegradation:
    """ä¼˜é›…é™çº§ç®¡ç†å™¨"""
    
    FALLBACK_CHAIN = [
        'primary_llm',      # GPT-4
        'backup_llm',       # Claude
        'local_llm',        # Llama æœ¬åœ°éƒ¨ç½²
        'rule_based',       # è§„åˆ™å¼•æ“
    ]
    
    async def execute_with_fallback(self, task, context):
        """é™çº§é“¾æ‰§è¡Œ"""
        for i, method in enumerate(self.FALLBACK_CHAIN):
            try:
                logger.info(f"å°è¯•æ–¹æ³•: {method} (Level {i})")
                
                if method.endswith('_llm'):
                    result = await self._call_llm(method, task, context)
                elif method == 'rule_based':
                    result = await self._rule_based_fallback(task, context)
                
                logger.info(f"æ–¹æ³• {method} æˆåŠŸ")
                return result, i  # è¿”å›ç»“æœå’Œé™çº§çº§åˆ«
            
            except Exception as e:
                logger.warning(f"æ–¹æ³• {method} å¤±è´¥: {e}")
                if i == len(self.FALLBACK_CHAIN) - 1:
                    raise
                continue
    
    async def _rule_based_fallback(self, task, context):
        """åŸºäºè§„åˆ™çš„å…œåº•é€»è¾‘"""
        # ç®€å•çš„æ¨¡å¼åŒ¹é…å’Œè§„åˆ™å¼•æ“
        if self._match_pattern(task, "è®¡ç®—"):
            return self._execute_calculator(task)
        elif self._match_pattern(task, "æœç´¢"):
            return self._execute_search(task)
        else:
            return {
                'success': False,
                'message': 'æŠ±æ­‰ï¼Œå½“å‰æœåŠ¡ä¸å¯ç”¨ï¼Œè¯·ç¨åé‡è¯•'
            }
```

### é™çº§ç­–ç•¥è¡¨

| åœºæ™¯     | ä¸»ç­–ç•¥         | é™çº§ç­–ç•¥ 1       | é™çº§ç­–ç•¥ 2   | æœ€ç»ˆå…œåº•     |
| -------- | -------------- | ---------------- | ------------ | ------------ |
| ä»»åŠ¡è§„åˆ’ | GPT-4 Planning | GPT-3.5 Planning | æ¨¡æ¿åŒ–è§„åˆ’   | è¿”å›é”™è¯¯ä¿¡æ¯ |
| å·¥å…·è°ƒç”¨ | æ­£å¸¸æ‰§è¡Œ       | ä½¿ç”¨ç¼“å­˜ç»“æœ     | Mock æ•°æ®    | è·³è¿‡è¯¥æ­¥éª¤   |
| ç»“æœèšåˆ | LLM æ€»ç»“       | ç®€å•æ‹¼æ¥         | è¿”å›åŸå§‹ç»“æœ | -            |

### é¢„æœŸæ”¶ç›Š

- 99.5% çš„è¯·æ±‚èƒ½å¾—åˆ°å“åº”ï¼ˆå³ä½¿é™çº§ï¼‰
- ç”¨æˆ·æ„ŸçŸ¥æ•…éšœç‡é™ä½ 80%
<a name="6-å¯è§‚æµ‹æ€§ä¼˜åŒ–"></a>
# ğŸ‘ï¸ 6. å¯è§‚æµ‹æ€§ä¼˜åŒ–

<a name="61-åˆ†å¸ƒå¼è¿½è¸ª"></a>
## ğŸ“ 6.1 åˆ†å¸ƒå¼è¿½è¸ª

### ç°çŠ¶é—®é¢˜

- ç¼ºå°‘ç«¯åˆ°ç«¯çš„è¯·æ±‚è¿½è¸ª
- éš¾ä»¥å®šä½æ€§èƒ½ç“¶é¢ˆ

### ä¼˜åŒ–ç­–ç•¥

```python
# æ–°å¢ observability/tracing.py
from opentelemetry import trace
from opentelemetry.exporter.jaeger import JaegerExporter
from opentelemetry.sdk.trace import TracerProvider
from opentelemetry.sdk.trace.export import BatchSpanProcessor

class DistributedTracing:
    """åˆ†å¸ƒå¼è¿½è¸ªå®ç°"""
    
    def __init__(self):
        # åˆå§‹åŒ– OpenTelemetry
        trace.set_tracer_provider(TracerProvider())
        jaeger_exporter = JaegerExporter(
            agent_host_name="localhost",
            agent_port=6831,
        )
        trace.get_tracer_provider().add_span_processor(
            BatchSpanProcessor(jaeger_exporter)
        )
        self.tracer = trace.get_tracer(__name__)
    
    def trace_operation(self, operation_name: str):
        """è£…é¥°å™¨ï¼šè¿½è¸ªæ“ä½œ"""
        def decorator(func):
            @functools.wraps(func)
            async def wrapper(*args, **kwargs):
                with self.tracer.start_as_current_span(operation_name) as span:
                    # æ·»åŠ å±æ€§
                    span.set_attribute("function", func.__name__)
                    span.set_attribute("args", str(args))
                    
                    try:
                        result = await func(*args, **kwargs)
                        span.set_attribute("result_type", type(result).__name__)
                        return result
                    except Exception as e:
                        span.set_attribute("error", True)
                        span.set_attribute("error_message", str(e))
                        raise
            return wrapper
        return decorator

# ä½¿ç”¨ç¤ºä¾‹
tracing = DistributedTracing()

class TaskPlanner:
    @tracing.trace_operation("task_planning")
    async def plan(self, user_input, context):
        # ... åŸæœ‰é€»è¾‘
        pass
```

### Trace ç»“æ„ç¤ºä¾‹

```
Trace ID: abc123
â”œâ”€ [100ms] orchestrator.run
â”‚  â”œâ”€ [20ms] load_memories
â”‚  â”œâ”€ [50ms] task_planner.plan
â”‚  â”‚  â”œâ”€ [10ms] prompt_construction
â”‚  â”‚  â””â”€ [35ms] llm_call (GPT-4)
â”‚  â”œâ”€ [25ms] executor.execute_plan
â”‚  â”‚  â”œâ”€ [10ms] tool_search.execute
â”‚  â”‚  â””â”€ [12ms] tool_calculator.execute
â”‚  â””â”€ [5ms] save_memories
```

### é¢„æœŸæ”¶ç›Š

- å¯è§†åŒ–å®Œæ•´è¯·æ±‚é“¾è·¯
- å¿«é€Ÿå®šä½æ€§èƒ½ç“¶é¢ˆï¼ˆ95 ç™¾åˆ†ä½å»¶è¿Ÿå®šä½ï¼‰
- è·¨æœåŠ¡è°ƒç”¨è¿½è¸ª
<a name="62-ç»“æ„åŒ–æ—¥å¿—ä¸æŒ‡æ ‡"></a>
## ğŸ“Š 6.2 ç»“æ„åŒ–æ—¥å¿—ä¸æŒ‡æ ‡

### ç°çŠ¶é—®é¢˜

- æ—¥å¿—æ ¼å¼ä¸ç»Ÿä¸€
- ç¼ºå°‘å…³é”®ä¸šåŠ¡æŒ‡æ ‡

### ä¼˜åŒ–ç­–ç•¥

```python
# æ–°å¢ observability/logging.py
import structlog

class StructuredLogger:
    """ç»“æ„åŒ–æ—¥å¿—"""
    
    def __init__(self):
        structlog.configure(
            processors=[
                structlog.stdlib.filter_by_level,
                structlog.stdlib.add_logger_name,
                structlog.stdlib.add_log_level,
                structlog.stdlib.PositionalArgumentsFormatter(),
                structlog.processors.TimeStamper(fmt="iso"),
                structlog.processors.StackInfoRenderer(),
                structlog.processors.format_exc_info,
                structlog.processors.JSONRenderer()
            ],
            logger_factory=structlog.stdlib.LoggerFactory(),
        )
        self.logger = structlog.get_logger()
    
    def log_task_execution(self, task_id, subtask, result, duration_ms):
        """è®°å½•ä»»åŠ¡æ‰§è¡Œ"""
        self.logger.info(
            "task_execution",
            task_id=task_id,
            subtask_id=subtask.id,
            tool=subtask.tool,
            success=result.success,
            duration_ms=duration_ms,
            token_count=result.get('token_count'),
        )
```

```python
# æ–°å¢ observability/metrics.py
from prometheus_client import Counter, Histogram, Gauge

class Metrics:
    """Prometheus æŒ‡æ ‡"""
    
    # è®¡æ•°å™¨
    task_total = Counter(
        'auto_agent_tasks_total',
        'Total number of tasks',
        ['status', 'intent']
    )
    
    # ç›´æ–¹å›¾ï¼ˆå»¶è¿Ÿåˆ†å¸ƒï¼‰
    task_duration = Histogram(
        'auto_agent_task_duration_seconds',
        'Task execution duration',
        ['tool'],
        buckets=[0.1, 0.5, 1, 2, 5, 10, 30]
    )
    
    # ä»ªè¡¨ç›˜ï¼ˆå½“å‰å€¼ï¼‰
    active_tasks = Gauge(
        'auto_agent_active_tasks',
        'Number of currently executing tasks'
    )
    
    # LLM è°ƒç”¨æˆæœ¬
    llm_cost_total = Counter(
        'auto_agent_llm_cost_usd',
        'Total LLM API cost in USD',
        ['model']
    )
```

### å…³é”®æŒ‡æ ‡çœ‹æ¿

**æ ¸å¿ƒæŒ‡æ ‡:**

- ä»»åŠ¡æˆåŠŸç‡ (Success Rate)
- P50/P95/P99 å»¶è¿Ÿ (Latency Percentiles)
- æ¯ç§’è¯·æ±‚æ•° (RPS)
- é”™è¯¯ç‡ (Error Rate)

**ä¸šåŠ¡æŒ‡æ ‡:**

- å¹³å‡å­ä»»åŠ¡æ•° (Avg Subtasks per Task)
- å·¥å…·è°ƒç”¨åˆ†å¸ƒ (Tool Usage Distribution)
- LLM Token æ¶ˆè€— (Token Usage)
- é‡è¯•ç‡ (Retry Rate)

**æˆæœ¬æŒ‡æ ‡:**

- æ¯ä»»åŠ¡æˆæœ¬ (Cost per Task)
- LLM API è´¹ç”¨ (LLM API Cost)
- å­˜å‚¨æˆæœ¬ (Storage Cost)

### é¢„æœŸæ”¶ç›Š

- å®æ—¶ç›‘æ§ç³»ç»Ÿå¥åº·çŠ¶å†µ
- å¿«é€Ÿå®šä½é—®é¢˜ï¼ˆMTTD < 5 åˆ†é’Ÿï¼‰
- æ•°æ®é©±åŠ¨ä¼˜åŒ–å†³ç­–
<a name="7-æˆæœ¬ä¼˜åŒ–"></a>
# ğŸ’° 7. æˆæœ¬ä¼˜åŒ–

<a name="71-token-ä½¿ç”¨ä¼˜åŒ–"></a>
## ğŸª™ 7.1 Token ä½¿ç”¨ä¼˜åŒ–

### ä¼˜åŒ–ç­–ç•¥

```python
class TokenOptimizer:
    """Token ä½¿ç”¨ä¼˜åŒ–å™¨"""
    
    async def optimize_context(self, context: str, max_tokens: int):
        """æ™ºèƒ½å‹ç¼©ä¸Šä¸‹æ–‡"""
        if self._count_tokens(context) <= max_tokens:
            return context
        
        # 1. ç§»é™¤å†—ä½™ä¿¡æ¯
        context = self._remove_redundancy(context)
        
        # 2. æå–å…³é”®ä¿¡æ¯
        if self._count_tokens(context) > max_tokens:
            context = await self._extract_key_info(context, max_tokens)
        
        # 3. ä½¿ç”¨æ‘˜è¦æ¨¡å‹å‹ç¼©
        if self._count_tokens(context) > max_tokens:
            context = await self._summarize(context, max_tokens)
        
        return context
    
    async def _extract_key_info(self, text: str, max_tokens: int):
        """åŸºäº TF-IDF æå–å…³é”®å¥å­"""
        sentences = self._split_sentences(text)
        scores = self._calculate_tfidf_scores(sentences)
        
        # é€‰æ‹©é«˜åˆ†å¥å­ç›´åˆ°è¾¾åˆ° token é™åˆ¶
        selected = []
        token_count = 0
        
        for sent, score in sorted(zip(sentences, scores), key=lambda x: -x[1]):
            sent_tokens = self._count_tokens(sent)
            if token_count + sent_tokens > max_tokens:
                break
            selected.append(sent)
            token_count += sent_tokens
        
        return " ".join(selected)
```

### Token èŠ‚çœç­–ç•¥

- **ä¸Šä¸‹æ–‡çª—å£ç®¡ç†**: æ»‘åŠ¨çª—å£ä¿ç•™æœ€è¿‘ N è½®å¯¹è¯
- **å·¥å…·æè¿°ç¼“å­˜**: åªåœ¨é¦–æ¬¡è§„åˆ’æ—¶å‘é€å®Œæ•´å·¥å…·åˆ—è¡¨
- **å¢é‡å¼æ›´æ–°**: åªå‘é€å˜æ›´éƒ¨åˆ†ï¼Œä¸é‡å¤å‘é€å…¨é‡ä¸Šä¸‹æ–‡
- **å‹ç¼©ç®—æ³•**: ä½¿ç”¨ zlib å‹ç¼©é•¿æ–‡æœ¬ï¼ˆAPI æ”¯æŒæ—¶ï¼‰

### é¢„æœŸæ”¶ç›Š

- Token ä½¿ç”¨é‡å‡å°‘ 40-50%
- API æˆæœ¬é™ä½ $200-500/æœˆï¼ˆæ¯ä¸‡æ¬¡è°ƒç”¨ï¼‰
<a name="72-æ¨¡å‹é€‰æ‹©æˆæœ¬ä¼˜åŒ–"></a>
## ğŸ“ˆ 7.2 æ¨¡å‹é€‰æ‹©æˆæœ¬ä¼˜åŒ–

### ç­–ç•¥çŸ©é˜µ

| åœºæ™¯     | æ¨èæ¨¡å‹      | æˆæœ¬/1M Tokens | æ›¿ä»£æ–¹æ¡ˆ            |
| -------- | ------------- | -------------- | ------------------- |
| æ„å›¾è¯†åˆ« | GPT-3.5-turbo | $0.50          | Llama-3-8B (æœ¬åœ°)   |
| ç®€å•è§„åˆ’ | GPT-4o-mini   | $0.15          | -                   |
| å¤æ‚æ¨ç† | GPT-4o        | $5.00          | Claude-3.5-Sonnet   |
| ä»£ç ç”Ÿæˆ | Claude-3-Opus | $15.00         | GPT-4o + æç¤ºè¯ä¼˜åŒ– |
| æ‘˜è¦å‹ç¼© | GPT-3.5-turbo | $0.50          | æœ¬åœ° T5-base        |

### æ··åˆéƒ¨ç½²ç­–ç•¥

```python
class HybridDeployment:
    """æ··åˆéƒ¨ç½²ï¼šäº‘ç«¯ + æœ¬åœ°æ¨¡å‹"""
    
    async def route_to_best_endpoint(self, task_type, complexity):
        """è·¯ç”±åˆ°æˆæœ¬æœ€ä¼˜çš„ç«¯ç‚¹"""
        if complexity < 0.3:
            # ä½¿ç”¨æœ¬åœ°éƒ¨ç½²çš„å°æ¨¡å‹
            return await self.local_llm.generate(...)
        elif task_type in ['summarization', 'classification']:
            # ä½¿ç”¨ç‰¹åŒ–å¾®è°ƒæ¨¡å‹
            return await self.fine_tuned_model.generate(...)
        else:
            # ä½¿ç”¨äº‘ç«¯å¤§æ¨¡å‹
            return await self.cloud_llm.generate(...)
```

### é¢„æœŸæ”¶ç›Š

- æ€»ä½“ LLM æˆæœ¬é™ä½ 50-70%
- å“åº”é€Ÿåº¦æå‡ï¼ˆæœ¬åœ°æ¨¡å‹å»¶è¿Ÿ < 100msï¼‰
<a name="8-å¼€å‘ä½“éªŒä¼˜åŒ–"></a>
# ğŸ‘¨â€ğŸ’» 8. å¼€å‘ä½“éªŒä¼˜åŒ–

<a name="81-å¼€å‘å·¥å…·é“¾"></a>
## ğŸ”§ 8.1 å¼€å‘å·¥å…·é“¾

### ç­–ç•¥

```python
# æ–°å¢ devtools/debugger.py
class AgentDebugger:
    """Agent æ‰§è¡Œè°ƒè¯•å™¨"""
    
    def __init__(self):
        self.breakpoints = []
        self.step_mode = False
    
    async def debug_run(self, user_input: str):
        """è°ƒè¯•æ¨¡å¼è¿è¡Œ"""
        print("ğŸ› è°ƒè¯•æ¨¡å¼å¯åŠ¨")
        
        # 1. æ˜¾ç¤ºåŠ è½½çš„è®°å¿†
        memories = await self.load_memories()
        self._print_memories(memories)
        self._wait_for_continue()
        
        # 2. æ˜¾ç¤ºç”Ÿæˆçš„è®¡åˆ’
        plan = await self.planner.plan(user_input, memories)
        self._print_plan(plan)
        self._wait_for_continue()
        
        # 3. é€æ­¥æ‰§è¡Œå­ä»»åŠ¡
        for i, subtask in enumerate(plan.subtasks):
            print(f"\nâ–¶ æ‰§è¡Œå­ä»»åŠ¡ {i+1}/{len(plan.subtasks)}")
            self._print_subtask(subtask)
            
            if self._should_break(subtask):
                self._interactive_debug(subtask)
            
            result = await self.executor.execute_subtask(subtask)
            self._print_result(result)
            self._wait_for_continue()
    
    def _interactive_debug(self, subtask):
        """äº¤äº’å¼è°ƒè¯•"""
        while True:
            cmd = input("è°ƒè¯•å‘½ä»¤ (c=ç»§ç»­, s=è·³è¿‡, m=ä¿®æ”¹å‚æ•°, q=é€€å‡º): ")
            if cmd == 'c':
                break
            elif cmd == 's':
                subtask.skip = True
                break
            elif cmd == 'm':
                # å…è®¸ä¿®æ”¹å‚æ•°
                new_params = input("è¾“å…¥æ–°å‚æ•° (JSON): ")
                subtask.parameters = json.loads(new_params)
            elif cmd == 'q':
                raise KeyboardInterrupt()
```

```python
# æ–°å¢ devtools/playground.py
class AgentPlayground:
    """Web UI æµ‹è¯•æ²™ç›’"""
    
    def start_server(self, port=8080):
        """å¯åŠ¨ Web è°ƒè¯•ç•Œé¢"""
        app = FastAPI()
        
        @app.get("/")
        async def index():
            return FileResponse("playground/index.html")
        
        @app.post("/api/execute")
        async def execute(request: ExecuteRequest):
            """æ‰§è¡Œä»»åŠ¡å¹¶è¿”å›è¯¦ç»†ä¿¡æ¯"""
            trace = []
            
            async def traced_execute():
                async for event in self.agent.run_streaming(request.input):
                    trace.append(event)
                    await websocket.send_json(event)
            
            await traced_execute()
            return {"trace": trace}
        
        uvicorn.run(app, host="0.0.0.0", port=port)
```

### Playground UI åŠŸèƒ½

- ğŸ“ å®æ—¶ç¼–è¾‘æç¤ºè¯æ¨¡æ¿
- ğŸ¯ å¯è§†åŒ–æ‰§è¡Œè®¡åˆ’ DAG
- ğŸ“Š Token ä½¿ç”¨é‡åˆ†æ
- ğŸ”„ å†å²æ‰§è¡Œè®°å½•å›æ”¾
- âš™ï¸ å‚æ•°è°ƒä¼˜ç•Œé¢
<a name="82-æµ‹è¯•æ¡†æ¶å¢å¼º"></a>
## ğŸ§ª 8.2 æµ‹è¯•æ¡†æ¶å¢å¼º

### ä¼˜åŒ–ç­–ç•¥

```python
# æ–°å¢ tests/fixtures.py
import pytest

@pytest.fixture
def mock_llm():
    """Mock LLM å®¢æˆ·ç«¯"""
    class MockLLMClient:
        def __init__(self):
            self.responses = {}
        
        def set_response(self, prompt_pattern, response):
            """é¢„è®¾å“åº”"""
            self.responses[prompt_pattern] = response
        
        async def generate(self, prompt, **kwargs):
            for pattern, response in self.responses.items():
                if pattern in prompt:
                    return response
            return {"error": "No mock response configured"}
    
    return MockLLMClient()

@pytest.fixture
def sample_execution_plan():
    """ç¤ºä¾‹æ‰§è¡Œè®¡åˆ’"""
    return ExecutionPlan(
        intent="æœç´¢å¹¶æ€»ç»“",
        subtasks=[
            Subtask(
                description="æœç´¢ä¿¡æ¯",
                tool="search",
                parameters={"query": "test"}
            ),
            Subtask(
                description="æ€»ç»“ç»“æœ",
                tool="summarize",
                parameters={},
                dependencies=["subtask_0"]
            )
        ]
    )
```

```python
# æ–°å¢ tests/integration_test.py
class TestEndToEnd:
    """ç«¯åˆ°ç«¯æµ‹è¯•"""
    
    @pytest.mark.asyncio
    async def test_complete_workflow(self, mock_llm, tmp_path):
        """æµ‹è¯•å®Œæ•´å·¥ä½œæµ"""
        # 1. åˆå§‹åŒ– Agent
        agent = AutoAgent(
            llm_client=mock_llm,
            memory_dir=tmp_path
        )
        
        # 2. è®¾ç½® Mock å“åº”
        mock_llm.set_response(
            "ç”Ÿæˆæ‰§è¡Œè®¡åˆ’",
            '{"intent": "test", "subtasks": [...]}'
        )
        
        # 3. æ‰§è¡Œä»»åŠ¡
        result = await agent.run("å¸®æˆ‘æœç´¢ Python æœ€æ–°ç‰ˆæœ¬")
        
        # 4. éªŒè¯ç»“æœ
        assert result.success
        assert "Python" in result.response
        assert len(result.subtasks_executed) > 0
```

```python
# æ–°å¢ tests/performance_test.py
class TestPerformance:
    """æ€§èƒ½æµ‹è¯•"""
    
    @pytest.mark.benchmark
    def test_planning_performance(self, benchmark):
        """æµ‹è¯•è§„åˆ’æ€§èƒ½"""
        planner = TaskPlanner()
        
        result = benchmark(
            planner.plan,
            user_input="å¤æ‚æŸ¥è¯¢",
            context={}
        )
        
        # æ–­è¨€ï¼šè§„åˆ’åº”åœ¨ 500ms å†…å®Œæˆ
        assert benchmark.stats['mean'] < 0.5
    
    @pytest.mark.load
    async def test_concurrent_requests(self):
        """è´Ÿè½½æµ‹è¯•ï¼š100 å¹¶å‘è¯·æ±‚"""
        tasks = [
            agent.run(f"è¯·æ±‚ {i}")
            for i in range(100)
        ]
        
        start = time.time()
        results = await asyncio.gather(*tasks)
        duration = time.time() - start
        
        # æ–­è¨€ï¼š100 ä¸ªè¯·æ±‚åº”åœ¨ 30 ç§’å†…å®Œæˆ
        assert duration < 30
        assert all(r.success for r in results)
```

### CI/CD é›†æˆ

```yaml
# .github/workflows/test.yml
name: Test & Benchmark

on: [push, pull_request]

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - name: Run unit tests
        run: pytest tests/ -v --cov=auto_agent
      
      - name: Run performance tests
        run: pytest tests/performance_test.py --benchmark-only
      
      - name: Upload coverage
        uses: codecov/codecov-action@v3
```

### é¢„æœŸæ”¶ç›Š

- å¼€å‘è°ƒè¯•æ•ˆç‡æå‡ 3 å€
- Bug ä¿®å¤æ—¶é—´å‡å°‘ 60%
- ä»£ç è¦†ç›–ç‡æå‡è‡³ 85%+
<a name="9-å®æ–½è·¯çº¿å›¾"></a>
# ğŸ—ºï¸ 9. å®æ–½è·¯çº¿å›¾

## ğŸ¯ ä¼˜å…ˆçº§çŸ©é˜µ

| ä¼˜åŒ–é¡¹         | æ”¶ç›Š | å®æ–½éš¾åº¦ | ä¼˜å…ˆçº§ |
| -------------- | ---- | -------- | ------ |
| LLM è¯·æ±‚ç¼“å­˜   | é«˜   | ä½       | P0 ğŸ”¥   |
| å¹¶è¡Œæ‰§è¡Œä¼˜åŒ–   | é«˜   | ä¸­       | P0 ğŸ”¥   |
| æµå¼å“åº”æ¶æ„   | é«˜   | ä¸­       | P0 ğŸ”¥   |
| æ™ºèƒ½é‡è¯•ç­–ç•¥   | é«˜   | ä½       | P0 ğŸ”¥   |
| Token ä½¿ç”¨ä¼˜åŒ– | é«˜   | ä¸­       | P1     |
| å¤šæ¨¡å‹è·¯ç”±     | é«˜   | ä¸­       | P1     |
| åˆ†å¸ƒå¼è¿½è¸ª     | ä¸­   | ä¸­       | P1     |
| è®°å¿†ç³»ç»Ÿç´¢å¼•   | ä¸­   | é«˜       | P2     |
| æ’ä»¶åŒ–å·¥å…·ç³»ç»Ÿ | ä¸­   | é«˜       | P2     |
| æ··åˆéƒ¨ç½²       | é«˜   | é«˜       | P2     |

## ğŸš€ å®æ–½é˜¶æ®µ
### Phase 1 (1-2 å‘¨) - å¿«é€Ÿè§æ•ˆ âš¡
- å®ç° LLM å“åº”ç¼“å­˜
- ä¼˜åŒ–æ™ºèƒ½é‡è¯•ç­–ç•¥
- æ·»åŠ åŸºç¡€ Prometheus æŒ‡æ ‡
- å®ç°æµå¼å“åº” API

### Phase 2 (3-4 å‘¨) - æ€§èƒ½æå‡ ğŸš€
- å®ç°å­ä»»åŠ¡å¹¶è¡Œæ‰§è¡Œ
- éƒ¨ç½²å¤šæ¨¡å‹è·¯ç”±
- Token ä½¿ç”¨ä¼˜åŒ–
- æ·»åŠ åˆ†å¸ƒå¼è¿½è¸ª

### Phase 3 (5-8 å‘¨) - æ¶æ„å‡çº§ ğŸ—ï¸
- é‡æ„è®°å¿†ç³»ç»Ÿï¼ˆå‘é‡ç´¢å¼•ï¼‰
- å®ç°æ’ä»¶åŒ–å·¥å…·ç³»ç»Ÿ
- ä¼˜é›…é™çº§æœºåˆ¶
- å¼€å‘è€…å·¥å…·é“¾

### Phase 4 (9-12 å‘¨) - è¿›é˜¶ä¼˜åŒ– ğŸŒŸ
- æ··åˆéƒ¨ç½²æ¶æ„
- è‡ªé€‚åº”é—å¿˜æœºåˆ¶
- æç¤ºè¯ A/B æµ‹è¯•å¹³å°
- å®Œæ•´çš„ç«¯åˆ°ç«¯æµ‹è¯•å¥—ä»¶
<a name="10-é™„å½•"></a>
# ğŸ“ 10. é™„å½•

## ğŸ“Š A. æ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æŒ‡æ ‡ (KPIs)

```python
PERFORMANCE_KPIS = {
    'latency': {
        'p50': 500,    # ms, ä¸­ä½æ•°å»¶è¿Ÿ
        'p95': 2000,   # ms, 95åˆ†ä½
        'p99': 5000,   # ms, 99åˆ†ä½
    },
    'throughput': {
        'target_rps': 100,  # ç›®æ ‡ RPS
    },
    'availability': {
        'target_uptime': 0.999,  # 99.9% å¯ç”¨æ€§
    }
}
```

## ğŸ’° B. æˆæœ¬æŒ‡æ ‡

### æˆæœ¬è¿½è¸ª

```python
COST_METRICS = {
    'llm_api_cost_per_task': 0.05,  # USD
    'storage_cost_per_gb_month': 0.10,  # USD
    'compute_cost_per_hour': 0.50,  # USD
}
```

---

## ğŸ“ è”ç³»æˆ‘ä»¬

- **æ–‡æ¡£ç»´æŠ¤è€…**: Auto-Agent Team
- **æœ€åæ›´æ–°**: 2024
- **åé¦ˆæ¸ é“**: [GitHub Issues](https://github.com/your-org/auto-agent/issues) / team@example.com

---

<div align="center">
  <h3>ğŸ‰ ä¼˜åŒ–ç­–ç•¥æ–‡æ¡£å®Œæˆ!</h3>
  <p>è¿™ä»½æ–‡æ¡£æä¾›äº†å…¨é¢çš„ä¼˜åŒ–ç­–ç•¥ï¼Œå¸®åŠ©æå‡ Auto-Agent æ¡†æ¶çš„æ€§èƒ½ã€å¯é æ€§å’Œå¼€å‘ä½“éªŒã€‚</p>
</div>