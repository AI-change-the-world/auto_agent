"""
æ–‡æ¡£å†™ä½œæ™ºèƒ½ä½“ç¤ºä¾‹

æ¼”ç¤ºå¦‚ä½•:
1. ä½¿ç”¨ Markdown å®šä¹‰æ™ºèƒ½ä½“
2. è‡ªå®šä¹‰å·¥å…·
3. è‡ªåŠ¨ç¼–æŽ’æ‰§è¡Œæµç¨‹
4. ç”Ÿæˆæ‰§è¡ŒæŠ¥å‘Š
"""

import asyncio
import os
from typing import Any, Dict, List, Optional

from auto_agent import (
    AgentDefinition,
    AgentMarkdownParser,
    AutoAgent,
    BaseTool,
    ExecutionReportGenerator,
    LongTermMemory,
    OpenAIClient,
    ShortTermMemory,
    ToolDefinition,
    ToolParameter,
    ToolRegistry,
    tool,
)


# ==================== è‡ªå®šä¹‰å·¥å…· ====================


@tool(
    name="analyze_input",
    description="åˆ†æžç”¨æˆ·è¾“å…¥ï¼Œè¯†åˆ«æ„å›¾å’Œå…³é”®ä¿¡æ¯",
    category="analysis",
    parameters=[
        {"name": "query", "type": "string", "description": "ç”¨æˆ·è¾“å…¥", "required": True},
    ],
    output_schema={
        "intent": {"type": "string", "description": "ç”¨æˆ·æ„å›¾"},
        "topic": {"type": "string", "description": "ä¸»é¢˜"},
        "keywords": {"type": "array", "description": "å…³é”®è¯åˆ—è¡¨"},
    },
)
class AnalyzeInputTool(BaseTool):
    """åˆ†æžç”¨æˆ·è¾“å…¥å·¥å…·"""

    async def execute(self, query: str, **kwargs) -> Dict[str, Any]:
        # æ¨¡æ‹Ÿåˆ†æžç»“æžœ
        return {
            "success": True,
            "intent": "å†™ä½œ",
            "topic": query[:50],
            "keywords": ["å­¦ä¹ ", "ç¬”è®°", "æ€»ç»“"],
            "case_type": ["è°ƒç ”æŠ¥å‘Š"],
        }


@tool(
    name="es_fulltext_search",
    description="å…¨æ–‡æ£€ç´¢ï¼Œæœç´¢ç›¸å…³æ–‡æ¡£",
    category="retrieval",
    parameters=[
        {"name": "query", "type": "string", "description": "æœç´¢æŸ¥è¯¢", "required": True},
        {"name": "size", "type": "integer", "description": "è¿”å›žæ•°é‡", "default": 10},
    ],
    output_schema={
        "document_ids": {"type": "array", "description": "æ–‡æ¡£IDåˆ—è¡¨"},
        "documents": {"type": "array", "description": "æ–‡æ¡£åˆ—è¡¨"},
    },
)
class ESFulltextSearchTool(BaseTool):
    """å…¨æ–‡æ£€ç´¢å·¥å…·"""

    async def execute(
        self, query: str, size: int = 10, **kwargs
    ) -> Dict[str, Any]:
        # æ¨¡æ‹Ÿæ£€ç´¢ç»“æžœ
        mock_docs = [
            {
                "id": f"doc_{i}",
                "title": f"ç›¸å…³æ–‡æ¡£ {i}: {query[:20]}",
                "content": f"è¿™æ˜¯å…³äºŽ {query[:30]} çš„è¯¦ç»†å†…å®¹...",
                "score": 0.9 - i * 0.1,
            }
            for i in range(min(size, 5))
        ]
        return {
            "success": True,
            "document_ids": [d["id"] for d in mock_docs],
            "documents": mock_docs,
            "count": len(mock_docs),
        }


@tool(
    name="generate_outline",
    description="æ ¹æ®ä¸»é¢˜å’Œæ£€ç´¢ç»“æžœç”Ÿæˆæ–‡æ¡£å¤§çº²",
    category="document",
    parameters=[
        {"name": "topic", "type": "string", "description": "æ–‡æ¡£ä¸»é¢˜", "required": True},
        {"name": "document_ids", "type": "array", "description": "å‚è€ƒæ–‡æ¡£IDåˆ—è¡¨"},
    ],
    output_schema={
        "outline": {"type": "object", "description": "å¤§çº²ç»“æž„"},
    },
)
class GenerateOutlineTool(BaseTool):
    """å¤§çº²ç”Ÿæˆå·¥å…·"""

    async def execute(
        self, topic: str, document_ids: List[str] = None, **kwargs
    ) -> Dict[str, Any]:
        # æ¨¡æ‹Ÿå¤§çº²ç”Ÿæˆ
        outline = {
            "title": f"å…³äºŽ{topic}çš„ç ”ç©¶æŠ¥å‘Š",
            "sections": [
                {"title": "ä¸€ã€èƒŒæ™¯ä»‹ç»", "subsections": ["1.1 ç ”ç©¶èƒŒæ™¯", "1.2 ç ”ç©¶æ„ä¹‰"]},
                {"title": "äºŒã€çŽ°çŠ¶åˆ†æž", "subsections": ["2.1 å›½å†…çŽ°çŠ¶", "2.2 å›½å¤–çŽ°çŠ¶"]},
                {"title": "ä¸‰ã€ä¸»è¦å†…å®¹", "subsections": ["3.1 æ ¸å¿ƒæ¦‚å¿µ", "3.2 å…³é”®æŠ€æœ¯"]},
                {"title": "å››ã€æ€»ç»“ä¸Žå±•æœ›", "subsections": ["4.1 ä¸»è¦ç»“è®º", "4.2 æœªæ¥æ–¹å‘"]},
            ],
        }
        return {
            "success": True,
            "outline": outline,
        }


@tool(
    name="document_compose",
    description="æ ¹æ®å¤§çº²å’Œå‚è€ƒèµ„æ–™æ’°å†™æ–‡æ¡£",
    category="document",
    parameters=[
        {"name": "outline", "type": "object", "description": "æ–‡æ¡£å¤§çº²", "required": True},
        {"name": "documents", "type": "array", "description": "å‚è€ƒæ–‡æ¡£åˆ—è¡¨"},
        {"name": "style", "type": "string", "description": "å†™ä½œé£Žæ ¼", "default": "formal"},
    ],
    output_schema={
        "document": {"type": "object", "description": "ç”Ÿæˆçš„æ–‡æ¡£"},
    },
)
class DocumentComposeTool(BaseTool):
    """æ–‡æ¡£æ’°å†™å·¥å…·"""

    async def execute(
        self,
        outline: Dict[str, Any],
        documents: List[Dict] = None,
        style: str = "formal",
        **kwargs,
    ) -> Dict[str, Any]:
        # æ¨¡æ‹Ÿæ–‡æ¡£ç”Ÿæˆ
        title = outline.get("title", "æœªå‘½åæ–‡æ¡£")
        sections = outline.get("sections", [])
        
        content_parts = [f"# {title}\n"]
        for section in sections:
            content_parts.append(f"\n## {section['title']}\n")
            for sub in section.get("subsections", []):
                content_parts.append(f"\n### {sub}\n")
                content_parts.append("è¿™é‡Œæ˜¯è¯¦ç»†å†…å®¹...\n")
        
        content = "".join(content_parts)
        
        return {
            "success": True,
            "document": {
                "title": title,
                "content": content,
                "word_count": len(content),
                "style": style,
            },
        }


# ==================== Agent å®šä¹‰ (Markdown) ====================

WRITER_AGENT_MD = """
## ä½ æ˜¯ä¸€ä¸ªæ–‡æ¡£å†™ä½œæ™ºèƒ½ä½“

ä½ éœ€è¦æŒ‰ä»¥ä¸‹æ­¥éª¤å®Œæˆç”¨æˆ·çš„éœ€æ±‚ï¼š

1. è°ƒç”¨ [analyze_input] å·¥å…·ï¼Œå¯¹ç”¨æˆ·çš„æ„å›¾è¿›è¡Œåˆ†æž
2. è°ƒç”¨ [es_fulltext_search] å·¥å…·ï¼Œæ£€ç´¢ç›¸å…³æ–‡æ¡£
3. è°ƒç”¨ [generate_outline] å·¥å…·ï¼Œç”Ÿæˆæ–‡æ¡£å¤§çº²
4. è°ƒç”¨ [document_compose] å·¥å…·ï¼Œæ’°å†™å®Œæ•´æ–‡æ¡£
5. è¿”å›žç»“æžœ

### ç›®æ ‡
- ç†è§£ç”¨æˆ·çš„å†™ä½œéœ€æ±‚
- æ£€ç´¢ç›¸å…³å‚è€ƒèµ„æ–™
- ç”Ÿæˆç»“æž„æ¸…æ™°çš„æ–‡æ¡£

### çº¦æŸ
- æ–‡æ¡£é•¿åº¦é€‚ä¸­ï¼Œä¸è¶…è¿‡5000å­—
- å¼•ç”¨çš„å‚è€ƒèµ„æ–™ä¸è¶…è¿‡10ç¯‡
"""


# ==================== ä¸»å‡½æ•° ====================


async def main():
    """è¿è¡Œæ–‡æ¡£å†™ä½œæ™ºèƒ½ä½“ç¤ºä¾‹"""
    
    print("=" * 60)
    print("ðŸ“ æ–‡æ¡£å†™ä½œæ™ºèƒ½ä½“ç¤ºä¾‹")
    print("=" * 60)
    
    # 1. åˆå§‹åŒ– LLM å®¢æˆ·ç«¯
    api_key = os.getenv("OPENAI_API_KEY") or os.getenv("DEEPSEEK_API_KEY")
    base_url = os.getenv("OPENAI_BASE_URL", "https://api.openai.com/v1")
    model = os.getenv("OPENAI_MODEL", "gpt-4o-mini")
    
    if not api_key:
        print("âš ï¸  æœªè®¾ç½® API Keyï¼Œå°†ä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼")
        llm_client = None
    else:
        print(f"âœ… ä½¿ç”¨ LLM: {model}")
        llm_client = OpenAIClient(
            api_key=api_key,
            base_url=base_url,
            model=model,
        )
    
    # 2. åˆå§‹åŒ–å·¥å…·æ³¨å†Œè¡¨
    tool_registry = ToolRegistry()
    tool_registry.register(AnalyzeInputTool())
    tool_registry.register(ESFulltextSearchTool())
    tool_registry.register(GenerateOutlineTool())
    tool_registry.register(DocumentComposeTool())
    
    print(f"âœ… å·²æ³¨å†Œ {len(tool_registry.get_all_tools())} ä¸ªå·¥å…·")
    
    # 3. è§£æž Agent å®šä¹‰
    parser = AgentMarkdownParser(llm_client=llm_client)
    parse_result = await parser.parse(
        content=WRITER_AGENT_MD,
        tools_catalog=tool_registry.get_tools_catalog(),
    )
    
    if not parse_result["success"]:
        print(f"âŒ Agent è§£æžå¤±è´¥: {parse_result['errors']}")
        return
    
    agent_def: AgentDefinition = parse_result["agent"]
    print(f"âœ… Agent è§£æžæˆåŠŸ: {agent_def.name}")
    print(f"   ç›®æ ‡: {agent_def.goals}")
    print(f"   çº¦æŸ: {agent_def.constraints}")
    print(f"   æ­¥éª¤æ•°: {len(agent_def.initial_plan)}")
    
    # 4. åˆå§‹åŒ–è®°å¿†ç³»ç»Ÿ
    ltm = LongTermMemory(storage_path="./data/memories")
    stm = ShortTermMemory(backend="memory")
    
    # 5. åˆ›å»º Agent
    agent_config = parser.to_agent_config(agent_def)
    
    agent = AutoAgent(
        llm_client=llm_client,
        tool_registry=tool_registry,
        long_term_memory=ltm,
        short_term_memory=stm,
        agent_goals=agent_config.get("agent_goals"),
        agent_constraints=agent_config.get("agent_constraints"),
    )
    
    print("âœ… Agent åˆå§‹åŒ–å®Œæˆ")
    
    # 6. æ‰§è¡Œä»»åŠ¡
    query = "å¸®æˆ‘å†™ä¸€ç¯‡å…³äºŽäººå·¥æ™ºèƒ½åœ¨åŒ»ç–—é¢†åŸŸåº”ç”¨çš„è°ƒç ”æŠ¥å‘Š"
    print(f"\nðŸ“‹ ç”¨æˆ·æŸ¥è¯¢: {query}")
    print("-" * 60)
    
    from datetime import datetime
    start_time = datetime.now()
    
    try:
        response = await agent.run(
            query=query,
            user_id="demo_user",
            initial_plan=agent_config.get("initial_plan"),
        )
        
        end_time = datetime.now()
        
        print(f"\nâœ… æ‰§è¡Œå®Œæˆ!")
        print(f"   ä¼šè¯ID: {response.conversation_id}")
        print(f"   è€—æ—¶: {(end_time - start_time).total_seconds():.2f} ç§’")
        
        # 7. ç”Ÿæˆæ‰§è¡ŒæŠ¥å‘Š
        if response.plan and response.execution_results:
            report_data = ExecutionReportGenerator.generate_report_data(
                agent_name=agent_def.name,
                query=query,
                plan=response.plan,
                results=response.execution_results,
                state={},
                start_time=start_time,
                end_time=end_time,
            )
            
            # è¾“å‡º Markdown æŠ¥å‘Š
            markdown_report = ExecutionReportGenerator.generate_markdown_report(report_data)
            
            print("\n" + "=" * 60)
            print("ðŸ“Š æ‰§è¡ŒæŠ¥å‘Š")
            print("=" * 60)
            print(markdown_report)
            
            # ä¿å­˜æŠ¥å‘Š
            report_path = "./data/reports/writer_agent_report.md"
            os.makedirs(os.path.dirname(report_path), exist_ok=True)
            with open(report_path, "w", encoding="utf-8") as f:
                f.write(markdown_report)
            print(f"\nðŸ“ æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_path}")
        
        # 8. è¾“å‡ºç»“æžœ
        print("\n" + "=" * 60)
        print("ðŸ“„ ç”Ÿæˆçš„æ–‡æ¡£")
        print("=" * 60)
        print(response.content[:1000] if response.content else "æ— å†…å®¹")
        
    except Exception as e:
        print(f"âŒ æ‰§è¡Œå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
    
    finally:
        if llm_client:
            await llm_client.close()


# ==================== ç®€åŒ–ç‰ˆæœ¬ (æ—  LLM) ====================


async def demo_without_llm():
    """æ—  LLM çš„ç®€åŒ–æ¼”ç¤º"""
    
    print("=" * 60)
    print("ðŸ“ ç®€åŒ–æ¼”ç¤º (æ—  LLM)")
    print("=" * 60)
    
    # 1. åˆå§‹åŒ–å·¥å…·
    tool_registry = ToolRegistry()
    tool_registry.register(AnalyzeInputTool())
    tool_registry.register(ESFulltextSearchTool())
    tool_registry.register(GenerateOutlineTool())
    tool_registry.register(DocumentComposeTool())
    
    # 2. è§£æž Agent (ä½¿ç”¨è§„åˆ™è§£æž)
    parser = AgentMarkdownParser(llm_client=None)
    parse_result = await parser.parse(WRITER_AGENT_MD)
    
    agent_def = parse_result["agent"]
    print(f"âœ… Agent: {agent_def.name}")
    print(f"   æ­¥éª¤: {[s.tool for s in agent_def.initial_plan]}")
    
    # 3. æ‰‹åŠ¨æ‰§è¡Œå·¥å…·é“¾
    print("\nðŸ”§ æ‰‹åŠ¨æ‰§è¡Œå·¥å…·é“¾:")
    
    # Step 1: åˆ†æžè¾“å…¥
    analyze_tool = tool_registry.get_tool("analyze_input")
    result1 = await analyze_tool.execute(query="å†™ä¸€ç¯‡AIåŒ»ç–—æŠ¥å‘Š")
    print(f"   1. analyze_input: {result1['intent']}, {result1['topic']}")
    
    # Step 2: æ£€ç´¢
    search_tool = tool_registry.get_tool("es_fulltext_search")
    result2 = await search_tool.execute(query=result1["topic"], size=5)
    print(f"   2. es_fulltext_search: æ‰¾åˆ° {result2['count']} ç¯‡æ–‡æ¡£")
    
    # Step 3: ç”Ÿæˆå¤§çº²
    outline_tool = tool_registry.get_tool("generate_outline")
    result3 = await outline_tool.execute(
        topic=result1["topic"],
        document_ids=result2["document_ids"],
    )
    print(f"   3. generate_outline: {result3['outline']['title']}")
    
    # Step 4: æ’°å†™æ–‡æ¡£
    compose_tool = tool_registry.get_tool("document_compose")
    result4 = await compose_tool.execute(
        outline=result3["outline"],
        documents=result2["documents"],
    )
    print(f"   4. document_compose: {result4['document']['word_count']} å­—")
    
    print("\nâœ… æ‰§è¡Œå®Œæˆ!")
    print("\nðŸ“„ ç”Ÿæˆçš„æ–‡æ¡£é¢„è§ˆ:")
    print("-" * 40)
    print(result4["document"]["content"][:500])


if __name__ == "__main__":
    import sys
    
    if len(sys.argv) > 1 and sys.argv[1] == "--simple":
        asyncio.run(demo_without_llm())
    else:
        asyncio.run(main())
