"""
å¯¹æ¯”åŸºå‡†æµ‹è¯•

åŒæ—¶è¿è¡Œ auto_agent å’Œ LangChain ç‰ˆæœ¬ï¼Œæ¯”è¾ƒæ‰§è¡Œæ•ˆæœ

ä½¿ç”¨æ–¹æ³•:
    cd auto_agent
    python examples/langchain_compare/benchmark.py
"""

import asyncio
import os
import sys
import time
from dataclasses import dataclass, field
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° path
script_dir = Path(__file__).parent
project_root = script_dir.parent.parent
if str(project_root) not in sys.path:
    sys.path.insert(0, str(project_root))


@dataclass
class TokenTracker:
    """Token è¿½è¸ªå™¨"""

    steps: List[Dict[str, Any]] = field(default_factory=list)
    cumulative_tokens: int = 0

    def add_step(self, step_name: str, tokens: int):
        self.cumulative_tokens += tokens
        self.steps.append(
            {
                "step": step_name,
                "tokens": tokens,
                "cumulative": self.cumulative_tokens,
            }
        )
        print(f"   ğŸ“Š Token: +{tokens:,} | ç´¯è®¡: {self.cumulative_tokens:,}")


# ==================== auto_agent ç‰ˆæœ¬ ====================


async def run_auto_agent_version(user_query: str, materials_dir: str) -> Dict[str, Any]:
    """è¿è¡Œ auto_agent ç‰ˆæœ¬"""
    from auto_agent import AutoAgent, OpenAIClient, ToolRegistry

    # å¯¼å…¥å·¥å…·ï¼ˆä» deep_research_demoï¼‰
    from examples.deep_research_demo import (
        AnalyzeContentTool,
        GenerateReportTool,
        PolishTextTool,
        ReadMaterialsTool,
        ReflectTool,
    )

    print("\n" + "=" * 70)
    print("ğŸ”¬ [auto_agent] Deep Research Agent")
    print("=" * 70)

    start_time = time.time()
    tracker = TokenTracker()

    # åˆå§‹åŒ– LLM
    api_key = os.getenv("OPENAI_API_KEY") or os.getenv("DEEPSEEK_API_KEY")
    base_url = os.getenv("OPENAI_BASE_URL", "https://api.deepseek.com/v1")
    model = os.getenv("OPENAI_MODEL", "deepseek-chat")

    llm_client = OpenAIClient(
        api_key=api_key,
        base_url=base_url,
        model=model,
        timeout=120.0,
    )

    # æ³¨å†Œå·¥å…·
    registry = ToolRegistry()
    registry.register(ReadMaterialsTool(llm_client, materials_dir))
    registry.register(AnalyzeContentTool(llm_client))
    registry.register(ReflectTool(llm_client))
    registry.register(PolishTextTool(llm_client))
    registry.register(GenerateReportTool(llm_client))

    # åˆ›å»º Agent
    agent = AutoAgent(
        llm_client=llm_client,
        tool_registry=registry,
        agent_name="Deep Research Agent",
        agent_description="æ·±åº¦ç ”ç©¶æ™ºèƒ½ä½“",
    )

    # æ‰§è¡Œ
    final_report = ""
    trace_data = None
    iterations = 0
    last_cumulative = 0

    try:
        async for event in agent.run_stream(
            query=user_query,
            user_id="benchmark",
        ):
            event_type = event.get("event")
            data = event.get("data", {})

            if event_type == "stage_start":
                print(f"   â–¶ï¸ Step {data.get('step')}: {data.get('name')}")

            elif event_type == "stage_complete":
                status = "âœ…" if data.get("success") else "âŒ"
                # ä» trace ä¸­è·å–å½“å‰ç´¯è®¡ token
                step_trace = data.get("trace", {})
                step_tokens = step_trace.get("total_tokens", 0)
                if step_tokens > 0:
                    tracker.add_step(data.get("name", "unknown"), step_tokens)
                print(f"   {status} å®Œæˆ")

            elif event_type == "answer":
                final_report = data.get("answer", "")

            elif event_type == "done":
                iterations = data.get("iterations", 0)
                trace_data = data.get("trace")

        end_time = time.time()

        # æå–ç»Ÿè®¡
        llm_calls = 0
        total_tokens = 0
        token_steps = []
        if trace_data:
            summary = trace_data.get("summary", {})
            llm_calls = summary.get("llm_calls", {}).get("count", 0)
            total_tokens = summary.get("llm_calls", {}).get("total_tokens", 0)

            # ä» spans æå–æ¯æ­¥ token
            spans = trace_data.get("spans", [])
            cumulative = 0
            for span in spans:
                span_tokens = span.get("total_tokens", 0)
                if span_tokens > 0:
                    cumulative += span_tokens
                    token_steps.append(
                        {
                            "step": span.get("name", "unknown"),
                            "tokens": span_tokens,
                            "cumulative": cumulative,
                        }
                    )

        # æ‰“å° token ç»Ÿè®¡
        print(f"\n   ğŸ“Š Token æ¶ˆè€—æ˜ç»†:")
        for step in token_steps:
            print(
                f"      {step['step']}: +{step['tokens']:,} (ç´¯è®¡: {step['cumulative']:,})"
            )
        print(f"   ğŸ“Š æ€»è®¡: {total_tokens:,} tokens")

        return {
            "success": True,
            "framework": "auto_agent",
            "output": final_report,
            "duration_ms": (end_time - start_time) * 1000,
            "iterations": iterations,
            "llm_calls": llm_calls,
            "total_tokens": total_tokens,
            "token_steps": token_steps,
        }

    except Exception as e:
        end_time = time.time()
        import traceback

        traceback.print_exc()
        return {
            "success": False,
            "framework": "auto_agent",
            "error": str(e),
            "duration_ms": (end_time - start_time) * 1000,
        }
    finally:
        await llm_client.close()


# ==================== LangChain ç‰ˆæœ¬ ====================


class LangChainTokenCallback:
    """LangChain Token å›è°ƒè¿½è¸ªå™¨"""

    def __init__(self):
        self.steps: List[Dict[str, Any]] = []
        self.cumulative_tokens = 0
        self.current_step = "init"

    def on_llm_end(self, tokens: int, step_name: str = None):
        step = step_name or self.current_step
        self.cumulative_tokens += tokens
        self.steps.append(
            {
                "step": step,
                "tokens": tokens,
                "cumulative": self.cumulative_tokens,
            }
        )
        print(f"   ğŸ“Š Token: +{tokens:,} | ç´¯è®¡: {self.cumulative_tokens:,}")


async def run_langchain_version(user_query: str, materials_dir: str) -> Dict[str, Any]:
    """è¿è¡Œ LangChain ç‰ˆæœ¬"""
    from langchain.agents import AgentExecutor, create_tool_calling_agent
    from langchain_core.callbacks import BaseCallbackHandler
    from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
    from langchain_openai import ChatOpenAI

    from examples.langchain_compare.tools import (
        analyze_content,
        init_tools,
        read_materials,
    )
    from examples.langchain_compare.tools_part2 import (
        generate_report,
        polish_text,
        reflect,
    )

    print("\n" + "=" * 70)
    print("ğŸ”¬ [LangChain] Deep Research Agent")
    print("=" * 70)

    start_time = time.time()
    token_tracker = LangChainTokenCallback()

    # è‡ªå®šä¹‰å›è°ƒå¤„ç†å™¨
    class TokenTrackingHandler(BaseCallbackHandler):
        def __init__(self, tracker: LangChainTokenCallback):
            self.tracker = tracker
            self.step_count = 0

        def on_llm_end(self, response, **kwargs):
            # å°è¯•ä» response è·å– token ä½¿ç”¨é‡
            token_usage = getattr(response, "llm_output", {})
            if token_usage and isinstance(token_usage, dict):
                usage = token_usage.get("token_usage", {})
                total = usage.get("total_tokens", 0)
                if total > 0:
                    self.tracker.on_llm_end(total, f"llm_call_{self.step_count}")
                    self.step_count += 1

            # å¤‡ç”¨ï¼šä» generations è·å–
            if hasattr(response, "generations") and response.generations:
                for gen_list in response.generations:
                    for gen in gen_list:
                        if hasattr(gen, "generation_info") and gen.generation_info:
                            usage = gen.generation_info.get("token_usage", {})
                            total = usage.get("total_tokens", 0)
                            if total > 0:
                                self.tracker.on_llm_end(
                                    total, f"llm_call_{self.step_count}"
                                )
                                self.step_count += 1

        def on_tool_start(self, serialized, input_str, **kwargs):
            tool_name = serialized.get("name", "unknown")
            print(f"   â–¶ï¸ è°ƒç”¨å·¥å…·: {tool_name}")

        def on_tool_end(self, output, **kwargs):
            print(f"   âœ… å·¥å…·å®Œæˆ")

    callback_handler = TokenTrackingHandler(token_tracker)

    # åˆå§‹åŒ– LLM
    api_key = os.getenv("OPENAI_API_KEY") or os.getenv("DEEPSEEK_API_KEY")
    base_url = os.getenv("OPENAI_BASE_URL", "https://api.deepseek.com/v1")
    model = os.getenv("OPENAI_MODEL", "deepseek-chat")

    llm = ChatOpenAI(
        api_key=api_key,
        base_url=base_url,
        model=model,
        temperature=0.7,
        timeout=120,
        callbacks=[callback_handler],
    )

    # åˆå§‹åŒ–å·¥å…·
    init_tools(llm, materials_dir)
    tools = [read_materials, analyze_content, reflect, polish_text, generate_report]

    # åˆ›å»º Agent
    system_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ·±åº¦ç ”ç©¶æ™ºèƒ½ä½“ã€‚

ä½ å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å·¥å…·ï¼š
1. read_materials - è¯»å–ç ”ç©¶ç´ æ
2. analyze_content - åˆ†æå†…å®¹
3. reflect - æ‰¹åˆ¤æ€§åæ€
4. generate_report - ç”ŸæˆæŠ¥å‘Š
5. polish_text - è¯­è¨€æ¶¦è‰²

è¯·æŒ‰é¡ºåºæ‰§è¡Œç ”ç©¶ä»»åŠ¡ï¼Œç¡®ä¿æ¯ä¸€æ­¥çš„è¾“å‡ºä¼ é€’ç»™ä¸‹ä¸€æ­¥ã€‚"""

    prompt = ChatPromptTemplate.from_messages(
        [
            ("system", system_prompt),
            ("human", "{input}"),
            MessagesPlaceholder(variable_name="agent_scratchpad"),
        ]
    )

    agent = create_tool_calling_agent(llm, tools, prompt)
    agent_executor = AgentExecutor(
        agent=agent,
        tools=tools,
        verbose=False,
        max_iterations=15,
        return_intermediate_steps=True,
        callbacks=[callback_handler],
    )

    try:
        result = await agent_executor.ainvoke(
            {"input": user_query},
            config={"callbacks": [callback_handler]},
        )

        end_time = time.time()

        intermediate_steps = result.get("intermediate_steps", [])

        # æ‰“å° token ç»Ÿè®¡
        print(f"\n   ğŸ“Š Token æ¶ˆè€—æ˜ç»†:")
        for step in token_tracker.steps:
            print(
                f"      {step['step']}: +{step['tokens']:,} (ç´¯è®¡: {step['cumulative']:,})"
            )
        print(f"   ğŸ“Š æ€»è®¡: {token_tracker.cumulative_tokens:,} tokens")

        return {
            "success": True,
            "framework": "langchain",
            "output": result.get("output", ""),
            "duration_ms": (end_time - start_time) * 1000,
            "iterations": len(intermediate_steps),
            "llm_calls": len(intermediate_steps) + 1,
            "total_tokens": token_tracker.cumulative_tokens,
            "token_steps": token_tracker.steps,
        }

    except Exception as e:
        end_time = time.time()
        import traceback

        traceback.print_exc()
        return {
            "success": False,
            "framework": "langchain",
            "error": str(e),
            "duration_ms": (end_time - start_time) * 1000,
            "total_tokens": token_tracker.cumulative_tokens,
        }


# ==================== å¯¹æ¯”æŠ¥å‘Š ====================


def generate_comparison_report(
    auto_agent_result: Dict[str, Any],
    langchain_result: Dict[str, Any],
    output_dir: Path,
):
    """ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š"""

    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

    # ç”Ÿæˆ token æ˜ç»†è¡¨æ ¼
    def format_token_steps(steps: List[Dict]) -> str:
        if not steps:
            return "æ— æ•°æ®"
        lines = ["| æ­¥éª¤ | Token | ç´¯è®¡ |", "|------|-------|------|"]
        for s in steps:
            lines.append(f"| {s['step']} | {s['tokens']:,} | {s['cumulative']:,} |")
        return "\n".join(lines)

    auto_token_table = format_token_steps(auto_agent_result.get("token_steps", []))
    lc_token_table = format_token_steps(langchain_result.get("token_steps", []))

    report = f"""# æ¡†æ¶å¯¹æ¯”æŠ¥å‘Š

> ç”Ÿæˆæ—¶é—´: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}

## æ‰§è¡Œç»Ÿè®¡å¯¹æ¯”

| æŒ‡æ ‡ | auto_agent | LangChain |
|------|------------|-----------|
| æ‰§è¡ŒçŠ¶æ€ | {"âœ… æˆåŠŸ" if auto_agent_result.get("success") else "âŒ å¤±è´¥"} | {"âœ… æˆåŠŸ" if langchain_result.get("success") else "âŒ å¤±è´¥"} |
| æ€»è€—æ—¶ | {auto_agent_result.get("duration_ms", 0):.1f}ms | {langchain_result.get("duration_ms", 0):.1f}ms |
| æ‰§è¡Œæ­¥éª¤ | {auto_agent_result.get("iterations", 0)} | {langchain_result.get("iterations", 0)} |
| LLM è°ƒç”¨æ¬¡æ•° | {auto_agent_result.get("llm_calls", 0)} | {langchain_result.get("llm_calls", 0)} |
| Token æ¶ˆè€— | {auto_agent_result.get("total_tokens", 0):,} | {langchain_result.get("total_tokens", 0):,} |

## Token æ¶ˆè€—æ˜ç»†

### auto_agent Token æ˜ç»†

{auto_token_table}

### LangChain Token æ˜ç»†

{lc_token_table}

## åˆ†æ

### è€—æ—¶å¯¹æ¯”
- auto_agent: {auto_agent_result.get("duration_ms", 0):.1f}ms
- LangChain: {langchain_result.get("duration_ms", 0):.1f}ms
- å·®å¼‚: {abs(auto_agent_result.get("duration_ms", 0) - langchain_result.get("duration_ms", 0)):.1f}ms

### Token å¯¹æ¯”
- auto_agent: {auto_agent_result.get("total_tokens", 0):,} tokens
- LangChain: {langchain_result.get("total_tokens", 0):,} tokens
- å·®å¼‚: {abs(auto_agent_result.get("total_tokens", 0) - langchain_result.get("total_tokens", 0)):,} tokens

### ç‰¹ç‚¹å¯¹æ¯”

| ç‰¹æ€§ | auto_agent | LangChain |
|------|------------|-----------|
| è§„åˆ’æ–¹å¼ | LLM åŠ¨æ€è§„åˆ’ | Agent è‡ªä¸»å†³ç­– |
| å‚æ•°ä¼ é€’ | è¯­ä¹‰é©±åŠ¨ + state ç®¡ç† | å·¥å…·è¿”å›å€¼ä¼ é€’ |
| è¿½è¸ªèƒ½åŠ› | å†…ç½®ç»†ç²’åº¦è¿½è¸ª | éœ€é¢å¤–é…ç½® |
| Token ç»Ÿè®¡ | è‡ªåŠ¨ç»Ÿè®¡ | éœ€æ‰‹åŠ¨é…ç½® |
| é‡è¯•æœºåˆ¶ | å†…ç½®æ™ºèƒ½é‡è¯• | éœ€è‡ªå®šä¹‰ |

---

## auto_agent è¾“å‡º

```
{auto_agent_result.get("output", auto_agent_result.get("error", "æ— è¾“å‡º"))[:2000]}
```

---

## LangChain è¾“å‡º

```
{langchain_result.get("output", langchain_result.get("error", "æ— è¾“å‡º"))[:2000]}
```
"""

    output_file = output_dir / f"comparison_report_{timestamp}.md"
    output_file.write_text(report, encoding="utf-8")

    print(f"\nğŸ“„ å¯¹æ¯”æŠ¥å‘Šå·²ä¿å­˜: {output_file}")
    return output_file


# ==================== ä¸»å‡½æ•° ====================


async def main():
    """è¿è¡Œå¯¹æ¯”åŸºå‡†æµ‹è¯•"""

    print("=" * 70)
    print("ğŸ æ¡†æ¶å¯¹æ¯”åŸºå‡†æµ‹è¯•")
    print("=" * 70)

    # æ£€æŸ¥ç¯å¢ƒ
    api_key = os.getenv("OPENAI_API_KEY") or os.getenv("DEEPSEEK_API_KEY")
    if not api_key:
        print("\nâŒ æœªè®¾ç½® API Key")
        return

    # ç´ æç›®å½•
    script_dir = Path(__file__).parent.parent
    materials_dir = str(script_dir / "research_materials")

    if not Path(materials_dir).exists():
        print(f"\nâŒ ç´ æç›®å½•ä¸å­˜åœ¨: {materials_dir}")
        print("è¯·å…ˆè¿è¡Œ deep_research_demo.py åˆ›å»ºç¤ºä¾‹ç´ æ")
        return

    # ç”¨æˆ·æŸ¥è¯¢
    user_query = """
    è¯·å¸®æˆ‘åšä¸€ä¸ªå…³äº"äººå·¥æ™ºèƒ½åœ¨åŒ»ç–—é¢†åŸŸçš„åº”ç”¨ä¸ä¼¦ç†æŒ‘æˆ˜"çš„æ·±åº¦ç ”ç©¶ã€‚
    
    è¦æ±‚ï¼š
    1. è¯»å–ç ”ç©¶ç´ æ
    2. åˆ†æå†…å®¹ï¼Œæå–å…³é”®ä¿¡æ¯
    3. è¿›è¡Œæ‰¹åˆ¤æ€§åæ€
    4. ç”Ÿæˆç ”ç©¶æŠ¥å‘Š
    5. å¯¹æŠ¥å‘Šè¿›è¡Œæ¶¦è‰²
    """

    # è¿è¡Œ auto_agent ç‰ˆæœ¬
    print("\n" + "=" * 70)
    print("ğŸ“Œ ç¬¬ä¸€è½®: è¿è¡Œ auto_agent ç‰ˆæœ¬")
    print("=" * 70)
    auto_agent_result = await run_auto_agent_version(user_query, materials_dir)

    # è¿è¡Œ LangChain ç‰ˆæœ¬
    print("\n" + "=" * 70)
    print("ğŸ“Œ ç¬¬äºŒè½®: è¿è¡Œ LangChain ç‰ˆæœ¬")
    print("=" * 70)
    langchain_result = await run_langchain_version(user_query, materials_dir)

    # ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š
    output_dir = script_dir / "output"
    output_dir.mkdir(exist_ok=True)

    generate_comparison_report(auto_agent_result, langchain_result, output_dir)

    # æ‰“å°æ‘˜è¦
    print("\n" + "=" * 70)
    print("ğŸ“Š å¯¹æ¯”æ‘˜è¦")
    print("=" * 70)
    print(f"\n{'æŒ‡æ ‡':<20} {'auto_agent':<20} {'LangChain':<20}")
    print("-" * 60)
    print(
        f"{'æ‰§è¡ŒçŠ¶æ€':<20} {'âœ… æˆåŠŸ' if auto_agent_result.get('success') else 'âŒ å¤±è´¥':<20} {'âœ… æˆåŠŸ' if langchain_result.get('success') else 'âŒ å¤±è´¥':<20}"
    )
    print(
        f"{'è€—æ—¶(ms)':<20} {auto_agent_result.get('duration_ms', 0):<20.1f} {langchain_result.get('duration_ms', 0):<20.1f}"
    )
    print(
        f"{'æ‰§è¡Œæ­¥éª¤':<20} {auto_agent_result.get('iterations', 0):<20} {langchain_result.get('iterations', 0):<20}"
    )
    print(
        f"{'LLMè°ƒç”¨':<20} {auto_agent_result.get('llm_calls', 0):<20} {langchain_result.get('llm_calls', 0):<20}"
    )
    print(
        f"{'Tokenæ¶ˆè€—':<20} {auto_agent_result.get('total_tokens', 0):<20,} {langchain_result.get('total_tokens', 0):<20,}"
    )


if __name__ == "__main__":
    asyncio.run(main())
