"""
OpenAI åŸç”Ÿå®¢æˆ·ç«¯ç‰ˆæœ¬ Deep Research Demo

ä¸ auto_agent ç‰ˆæœ¬å¯¹æ¯”ï¼Œä½¿ç”¨ OpenAI åŸç”Ÿ function calling å®ç°

ä½¿ç”¨æ–¹æ³•:
    cd auto_agent
    python examples/langchain_compare/main.py
"""

import asyncio
import json
import os
import sys
import time
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° path
script_dir = Path(__file__).parent
project_root = script_dir.parent.parent
sys.path.insert(0, str(project_root))

from openai import AsyncOpenAI

# ==================== Token è¿½è¸ª ====================


class TokenTracker:
    """Token è¿½è¸ªå™¨"""

    def __init__(self):
        self.steps: List[Dict[str, Any]] = []
        self.cumulative_tokens = 0
        self.llm_call_count = 0

    def add(self, tokens: int, step_name: str):
        self.llm_call_count += 1
        self.cumulative_tokens += tokens
        self.steps.append(
            {
                "step": step_name,
                "tokens": tokens,
                "cumulative": self.cumulative_tokens,
            }
        )
        print(f"   ğŸ“Š Token: +{tokens:,} | ç´¯è®¡: {self.cumulative_tokens:,}")


# ==================== å·¥å…·å®šä¹‰ ====================

TOOLS_SCHEMA = [
    {
        "type": "function",
        "function": {
            "name": "read_materials",
            "description": "è¯»å–ç ”ç©¶ç´ æç›®å½•ä¸‹çš„æ‰€æœ‰æ–‡ä»¶ï¼Œè¿”å›æ–‡ä»¶å†…å®¹ã€‚è¿™æ˜¯ç ”ç©¶çš„ç¬¬ä¸€æ­¥ã€‚",
            "parameters": {
                "type": "object",
                "properties": {
                    "file_types": {
                        "type": "string",
                        "description": "è¦è¯»å–çš„æ–‡ä»¶ç±»å‹ï¼Œç”¨é€—å·åˆ†éš”ï¼ˆå¦‚ .txt,.mdï¼‰",
                        "default": ".txt,.md",
                    }
                },
                "required": [],
            },
        },
    },
    {
        "type": "function",
        "function": {
            "name": "analyze_content",
            "description": "åˆ†æç ”ç©¶ç´ æå†…å®¹ï¼Œæå–ä¸»é¢˜ã€è®ºç‚¹ã€å…³é”®æ•°æ®ã€‚è¿™æ˜¯æ·±åº¦ç ”ç©¶çš„æ ¸å¿ƒåˆ†ææ­¥éª¤ã€‚",
            "parameters": {
                "type": "object",
                "properties": {
                    "focus": {
                        "type": "string",
                        "description": "ç ”ç©¶é‡ç‚¹/å…³æ³¨æ–¹å‘ï¼ˆå¯é€‰ï¼‰",
                    }
                },
                "required": [],
            },
        },
    },
    {
        "type": "function",
        "function": {
            "name": "reflect",
            "description": "å¯¹åˆ†æç»“æœè¿›è¡Œæ‰¹åˆ¤æ€§åæ€ï¼Œå‘ç°é€»è¾‘é—®é¢˜ã€æ½œåœ¨åè§å’Œç¼ºå¤±è§†è§’ã€‚",
            "parameters": {
                "type": "object",
                "properties": {
                    "depth": {
                        "type": "string",
                        "enum": ["shallow", "medium", "deep"],
                        "description": "åæ€æ·±åº¦",
                        "default": "medium",
                    }
                },
                "required": [],
            },
        },
    },
    {
        "type": "function",
        "function": {
            "name": "generate_report",
            "description": "åŸºäºåˆ†æç»“æœå’Œåæ€æ„è§ï¼Œç”Ÿæˆç»“æ„åŒ–çš„ç ”ç©¶æŠ¥å‘Šã€‚",
            "parameters": {
                "type": "object",
                "properties": {
                    "topic": {"type": "string", "description": "ç ”ç©¶ä¸»é¢˜"},
                    "format": {
                        "type": "string",
                        "enum": ["brief", "standard", "detailed"],
                        "description": "æŠ¥å‘Šæ ¼å¼",
                        "default": "standard",
                    },
                },
                "required": ["topic"],
            },
        },
    },
    {
        "type": "function",
        "function": {
            "name": "polish_text",
            "description": "å¯¹æ–‡æœ¬è¿›è¡Œè¯­è¨€æ¶¦è‰²ï¼Œæå‡è¡¨è¾¾çš„ä¸“ä¸šæ€§å’Œå¯è¯»æ€§ã€‚",
            "parameters": {
                "type": "object",
                "properties": {
                    "text": {"type": "string", "description": "å¾…æ¶¦è‰²çš„æ–‡æœ¬"},
                    "style": {
                        "type": "string",
                        "enum": ["academic", "professional", "casual"],
                        "description": "ç›®æ ‡é£æ ¼",
                        "default": "professional",
                    },
                },
                "required": ["text"],
            },
        },
    },
]


# ==================== å·¥å…·å®ç° ====================


class ToolExecutor:
    """å·¥å…·æ‰§è¡Œå™¨"""

    def __init__(self, client: AsyncOpenAI, materials_dir: str):
        self.client = client
        self.materials_dir = materials_dir
        self.state: Dict[str, Any] = {}  # å­˜å‚¨ä¸­é—´ç»“æœ

    async def execute(self, tool_name: str, args: Dict[str, Any]) -> str:
        """æ‰§è¡Œå·¥å…·"""
        print(f"   â–¶ï¸ æ‰§è¡Œå·¥å…·: {tool_name}")

        if tool_name == "read_materials":
            return await self._read_materials(args.get("file_types", ".txt,.md"))
        elif tool_name == "analyze_content":
            return await self._analyze_content(args.get("focus", ""))
        elif tool_name == "reflect":
            return await self._reflect(args.get("depth", "medium"))
        elif tool_name == "generate_report":
            return await self._generate_report(
                args.get("topic", ""), args.get("format", "standard")
            )
        elif tool_name == "polish_text":
            return await self._polish_text(
                args.get("text", ""), args.get("style", "professional")
            )
        else:
            return json.dumps({"error": f"æœªçŸ¥å·¥å…·: {tool_name}"})

    async def _read_materials(self, file_types: str) -> str:
        """è¯»å–ç´ æ"""
        dir_path = Path(self.materials_dir)
        extensions = [ext.strip() for ext in file_types.split(",")]
        materials = []

        for file_path in dir_path.iterdir():
            if file_path.is_file() and file_path.suffix in extensions:
                try:
                    content = file_path.read_text(encoding="utf-8")
                    materials.append(
                        {
                            "filename": file_path.name,
                            "content": content[:3000],
                            "word_count": len(content),
                        }
                    )
                except Exception as e:
                    materials.append({"filename": file_path.name, "error": str(e)})

        self.state["materials"] = materials
        result = {
            "success": True,
            "total_files": len(materials),
            "materials": materials,
        }
        print(f"   âœ… è¯»å–äº† {len(materials)} ä¸ªæ–‡ä»¶")
        return json.dumps(result, ensure_ascii=False)

    async def _analyze_content(self, focus: str) -> str:
        """åˆ†æå†…å®¹"""
        materials = self.state.get("materials", [])
        if not materials:
            return json.dumps({"error": "æ²¡æœ‰å¯åˆ†æçš„ç´ æï¼Œè¯·å…ˆè°ƒç”¨ read_materials"})

        # æ„å»ºç´ ææ–‡æœ¬
        materials_text = ""
        for m in materials:
            if "content" in m:
                materials_text += f"\n=== {m['filename']} ===\n{m['content'][:2000]}\n"

        prompt = f"""è¯·åˆ†æä»¥ä¸‹ç ”ç©¶ç´ æï¼Œæå–å…³é”®ä¿¡æ¯ã€‚{f"ç‰¹åˆ«å…³æ³¨: {focus}" if focus else ""}

{materials_text}

è¯·è¿”å› JSON æ ¼å¼çš„åˆ†æç»“æœï¼ŒåŒ…å«: main_themes, key_arguments, knowledge_gaps, overall_insight"""

        response = await self.client.chat.completions.create(
            model=os.getenv("OPENAI_MODEL", "deepseek-chat"),
            messages=[{"role": "user", "content": prompt}],
            temperature=0.7,
        )

        analysis_text = response.choices[0].message.content
        self.state["analysis"] = analysis_text
        print(f"   âœ… åˆ†æå®Œæˆ")
        return analysis_text

    async def _reflect(self, depth: str) -> str:
        """æ‰¹åˆ¤æ€§åæ€"""
        analysis = self.state.get("analysis", "")
        if not analysis:
            return json.dumps({"error": "æ²¡æœ‰åˆ†æç»“æœï¼Œè¯·å…ˆè°ƒç”¨ analyze_content"})

        depth_map = {
            "shallow": "å¿«é€Ÿæ£€æŸ¥",
            "medium": "ä¸­ç­‰æ·±åº¦æ‰¹åˆ¤æ€§åˆ†æ",
            "deep": "æ·±å…¥å“²å­¦å±‚é¢åæ€",
        }

        prompt = f"""è¯·å¯¹ä»¥ä¸‹åˆ†æç»“æœè¿›è¡Œ{depth_map.get(depth, "ä¸­ç­‰æ·±åº¦")}åæ€ã€‚

{analysis[:3000]}

è¯·æŒ‡å‡º: é€»è¾‘é—®é¢˜ã€æ½œåœ¨åè§ã€ç¼ºå¤±è§†è§’ã€æ”¹è¿›å»ºè®®ã€‚è¿”å› JSON æ ¼å¼ã€‚"""

        response = await self.client.chat.completions.create(
            model=os.getenv("OPENAI_MODEL", "deepseek-chat"),
            messages=[{"role": "user", "content": prompt}],
            temperature=0.7,
        )

        reflection = response.choices[0].message.content
        self.state["reflection"] = reflection
        print(f"   âœ… åæ€å®Œæˆ")
        return reflection

    async def _generate_report(self, topic: str, format: str) -> str:
        """ç”ŸæˆæŠ¥å‘Š"""
        analysis = self.state.get("analysis", "")
        reflection = self.state.get("reflection", "")

        format_map = {
            "brief": "500-800å­—ç®€æŠ¥",
            "standard": "1000-1500å­—æ ‡å‡†æŠ¥å‘Š",
            "detailed": "2000å­—ä»¥ä¸Šè¯¦ç»†æŠ¥å‘Š",
        }

        prompt = f"""è¯·åŸºäºä»¥ä¸‹å†…å®¹ç”Ÿæˆä¸€ä»½{format_map.get(format, "æ ‡å‡†")}ã€‚

ä¸»é¢˜: {topic}

åˆ†æç»“æœ:
{analysis[:2500]}

åæ€æ„è§:
{reflection[:1500]}

è¯·ç”Ÿæˆ Markdown æ ¼å¼çš„ç ”ç©¶æŠ¥å‘Šï¼ŒåŒ…å«: æ‘˜è¦ã€èƒŒæ™¯ã€æ ¸å¿ƒå‘ç°ã€è®¨è®ºã€ç»“è®ºã€‚"""

        response = await self.client.chat.completions.create(
            model=os.getenv("OPENAI_MODEL", "deepseek-chat"),
            messages=[{"role": "user", "content": prompt}],
            temperature=0.7,
        )

        report = response.choices[0].message.content
        self.state["report"] = report
        print(f"   âœ… æŠ¥å‘Šç”Ÿæˆå®Œæˆ")
        return report

    async def _polish_text(self, text: str, style: str) -> str:
        """æ¶¦è‰²æ–‡æœ¬"""
        # å¦‚æœæ²¡ä¼  textï¼Œç”¨ state ä¸­çš„ report
        if not text:
            text = self.state.get("report", "")
        if not text:
            return json.dumps({"error": "æ²¡æœ‰å¾…æ¶¦è‰²çš„æ–‡æœ¬"})

        style_map = {
            "academic": "å­¦æœ¯è®ºæ–‡é£æ ¼",
            "professional": "ä¸“ä¸šæŠ¥å‘Šé£æ ¼",
            "casual": "é€šä¿—æ˜“æ‡‚é£æ ¼",
        }

        prompt = f"""è¯·å¯¹ä»¥ä¸‹æ–‡æœ¬è¿›è¡Œè¯­è¨€æ¶¦è‰²ï¼Œä½¿ç”¨{style_map.get(style, "ä¸“ä¸š")}ã€‚

{text}

è¯·ç›´æ¥è¾“å‡ºæ¶¦è‰²åçš„å®Œæ•´æ–‡æœ¬ã€‚"""

        response = await self.client.chat.completions.create(
            model=os.getenv("OPENAI_MODEL", "deepseek-chat"),
            messages=[{"role": "user", "content": prompt}],
            temperature=0.7,
        )

        polished = response.choices[0].message.content
        self.state["polished_report"] = polished
        print(f"   âœ… æ¶¦è‰²å®Œæˆ")
        return polished


# ==================== Agent ä¸»å¾ªç¯ ====================


async def run_openai_agent(user_query: str, materials_dir: str) -> Dict[str, Any]:
    """è¿è¡Œ OpenAI Function Calling Agent"""

    print("=" * 70)
    print("ğŸ”¬ OpenAI Function Calling Agent")
    print("=" * 70)

    # åˆå§‹åŒ–
    api_key = os.getenv("OPENAI_API_KEY") or os.getenv("DEEPSEEK_API_KEY")
    base_url = os.getenv("OPENAI_BASE_URL", "https://api.deepseek.com/v1")
    model = os.getenv("OPENAI_MODEL", "deepseek-chat")

    client = AsyncOpenAI(api_key=api_key, base_url=base_url)
    tool_executor = ToolExecutor(client, materials_dir)
    tracker = TokenTracker()

    print(f"\nâœ… å®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ (model: {model})")

    # ç³»ç»Ÿæç¤º
    system_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ·±åº¦ç ”ç©¶æ™ºèƒ½ä½“ã€‚

ä½ å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å·¥å…·å®Œæˆç ”ç©¶ä»»åŠ¡ï¼š
1. read_materials - è¯»å–ç ”ç©¶ç´ æ
2. analyze_content - åˆ†æå†…å®¹
3. reflect - æ‰¹åˆ¤æ€§åæ€
4. generate_report - ç”ŸæˆæŠ¥å‘Š
5. polish_text - è¯­è¨€æ¶¦è‰²

è¯·æŒ‰é¡ºåºæ‰§è¡Œä»»åŠ¡ï¼Œç¡®ä¿æ¯ä¸€æ­¥å®Œæˆåå†è¿›è¡Œä¸‹ä¸€æ­¥ã€‚"""

    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": user_query},
    ]

    print(f"\nğŸ“‹ ç”¨æˆ·éœ€æ±‚:\n{user_query.strip()}")
    print("\n" + "=" * 70)
    print("ğŸš€ å¼€å§‹æ‰§è¡Œ...")
    print("=" * 70)

    start_time = time.time()
    max_iterations = 15
    iteration = 0
    final_output = ""

    try:
        while iteration < max_iterations:
            iteration += 1
            print(f"\n--- è¿­ä»£ {iteration} ---")

            # è°ƒç”¨ LLM
            response = await client.chat.completions.create(
                model=model,
                messages=messages,
                tools=TOOLS_SCHEMA,
                tool_choice="auto",
                temperature=0.7,
            )

            # è®°å½• token
            if response.usage:
                tracker.add(response.usage.total_tokens, f"iteration_{iteration}")

            message = response.choices[0].message

            # æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨
            if message.tool_calls:
                messages.append(message)

                # æ‰§è¡Œæ‰€æœ‰å·¥å…·è°ƒç”¨
                for tool_call in message.tool_calls:
                    func_name = tool_call.function.name
                    func_args = json.loads(tool_call.function.arguments)

                    # æ‰§è¡Œå·¥å…·
                    result = await tool_executor.execute(func_name, func_args)

                    # æ·»åŠ å·¥å…·ç»“æœåˆ°æ¶ˆæ¯
                    messages.append(
                        {
                            "role": "tool",
                            "tool_call_id": tool_call.id,
                            "content": result[:5000],  # é™åˆ¶é•¿åº¦
                        }
                    )
            else:
                # æ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œè¯´æ˜å®Œæˆäº†
                final_output = message.content or ""
                print(f"\nâœ… Agent å®Œæˆæ¨ç†")
                break

        end_time = time.time()
        duration_ms = (end_time - start_time) * 1000

        print("\n" + "=" * 70)
        print("âœ… æ‰§è¡Œå®Œæˆ!")
        print("=" * 70)

        # ç»Ÿè®¡
        print(f"\nğŸ“Š æ‰§è¡Œç»Ÿè®¡:")
        print(f"   - è¿­ä»£æ¬¡æ•°: {iteration}")
        print(f"   - LLM è°ƒç”¨: {tracker.llm_call_count}")
        print(f"   - Token æ¶ˆè€—: {tracker.cumulative_tokens:,}")
        print(f"   - è€—æ—¶: {duration_ms:.1f}ms")

        print(f"\nğŸ“Š Token æ¶ˆè€—æ˜ç»†:")
        for step in tracker.steps:
            print(
                f"      {step['step']}: +{step['tokens']:,} (ç´¯è®¡: {step['cumulative']:,})"
            )

        return {
            "success": True,
            "output": final_output or tool_executor.state.get("polished_report", ""),
            "iterations": iteration,
            "llm_calls": tracker.llm_call_count,
            "total_tokens": tracker.cumulative_tokens,
            "token_steps": tracker.steps,
            "duration_ms": duration_ms,
        }

    except Exception as e:
        end_time = time.time()
        print(f"\nâŒ æ‰§è¡Œå¤±è´¥: {e}")
        import traceback

        traceback.print_exc()

        return {
            "success": False,
            "error": str(e),
            "duration_ms": (end_time - start_time) * 1000,
            "total_tokens": tracker.cumulative_tokens,
        }


async def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¯åŠ¨ OpenAI Function Calling Demo...")

    # æ£€æŸ¥ API Key
    api_key = os.getenv("OPENAI_API_KEY") or os.getenv("DEEPSEEK_API_KEY")
    if not api_key:
        print("âŒ æœªè®¾ç½® API Key")
        return

    # ç´ æç›®å½•
    script_dir = Path(__file__).parent.parent
    materials_dir = script_dir / "research_materials"

    if not materials_dir.exists():
        print(f"âŒ ç´ æç›®å½•ä¸å­˜åœ¨: {materials_dir}")
        return

    user_query = """
    è¯·å¸®æˆ‘åšä¸€ä¸ªå…³äº"äººå·¥æ™ºèƒ½åœ¨åŒ»ç–—é¢†åŸŸçš„åº”ç”¨ä¸ä¼¦ç†æŒ‘æˆ˜"çš„æ·±åº¦ç ”ç©¶ã€‚

    è¦æ±‚ï¼š
    1. é¦–å…ˆè¯»å–ç ”ç©¶ç´ æ
    2. åˆ†æç´ æå†…å®¹ï¼Œæå–å…³é”®ä¿¡æ¯
    3. å¯¹åˆ†æç»“æœè¿›è¡Œæ‰¹åˆ¤æ€§åæ€
    4. ç”Ÿæˆä¸€ä»½ç ”ç©¶æŠ¥å‘Š
    5. æœ€åå¯¹æŠ¥å‘Šè¿›è¡Œè¯­è¨€æ¶¦è‰²
    """

    result = await run_openai_agent(user_query, str(materials_dir))

    # ä¿å­˜ç»“æœ
    if result.get("success"):
        output_dir = script_dir / "output"
        output_dir.mkdir(exist_ok=True)

        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_file = output_dir / f"openai_fc_report_{timestamp}.md"

        # Token æ˜ç»†
        token_detail = (
            "\n### Token æ¶ˆè€—æ˜ç»†\n\n| æ­¥éª¤ | Token | ç´¯è®¡ |\n|------|-------|------|\n"
        )
        for step in result.get("token_steps", []):
            token_detail += (
                f"| {step['step']} | {step['tokens']:,} | {step['cumulative']:,} |\n"
            )

        output_file.write_text(
            f"""# OpenAI Function Calling ç ”ç©¶æŠ¥å‘Š

> ç”Ÿæˆæ—¶é—´: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}
> æ¡†æ¶: OpenAI Native Function Calling

---

{result["output"]}

---

## æ‰§è¡Œç»Ÿè®¡

- è¿­ä»£æ¬¡æ•°: {result["iterations"]}
- LLM è°ƒç”¨æ¬¡æ•°: {result["llm_calls"]}
- Token æ¶ˆè€—: {result["total_tokens"]:,}
- è€—æ—¶: {result["duration_ms"]:.1f}ms
{token_detail}
""",
            encoding="utf-8",
        )

        print(f"\nğŸ“„ æŠ¥å‘Šå·²ä¿å­˜: {output_file}")


if __name__ == "__main__":
    print("=" * 70)
    print("OpenAI Function Calling Demo")
    print("=" * 70)
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\nâš ï¸ ç”¨æˆ·ä¸­æ–­")
