"""
å…¨æ ˆé¡¹ç›®ç”Ÿæˆå™¨ - LangChain é£æ ¼ (OpenAI åŸç”Ÿå®¢æˆ·ç«¯)

ä½¿ç”¨ OpenAI åŸç”Ÿå®¢æˆ·ç«¯ + æ‰‹åŠ¨å®ç° Agent å¾ªç¯ï¼Œæ¨¡æ‹Ÿ LangChain tool calling æ¨¡å¼
è¿™æ ·å¯ä»¥å‡†ç¡®ç»Ÿè®¡ token æ¶ˆè€—ï¼ŒåŒæ—¶ä¿æŒ LangChain çš„ ReAct é£æ ¼

ä½¿ç”¨æ–¹æ³•:
    cd auto_agent
    python examples/langchain_compare/fullstack_langchain.py
"""

import asyncio
import json
import os
import re
import sys
import time
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° path
script_dir = Path(__file__).parent
project_root = script_dir.parent.parent
sys.path.insert(0, str(project_root))

from openai import AsyncOpenAI

# ==================== Token è¿½è¸ª ====================


class TokenTracker:
    """Token è¿½è¸ªå™¨"""

    def __init__(self):
        self.steps: List[Dict[str, Any]] = []
        self.cumulative_tokens = 0
        self.llm_call_count = 0

    def add(self, tokens: int, step_name: str):
        self.llm_call_count += 1
        self.cumulative_tokens += tokens
        self.steps.append(
            {
                "step": step_name,
                "tokens": tokens,
                "cumulative": self.cumulative_tokens,
            }
        )
        print(f"   ğŸ“Š Token: +{tokens:,} | ç´¯è®¡: {self.cumulative_tokens:,}")


# ==================== å…¨å±€çŠ¶æ€ ====================


class GlobalState:
    """å…¨å±€çŠ¶æ€ç®¡ç†"""

    def __init__(self):
        self.client: Optional[AsyncOpenAI] = None
        self.model: str = ""
        self.output_dir: Optional[Path] = None
        self.project_dir: Optional[Path] = None
        self.tracker: Optional[TokenTracker] = None

        # ä¸šåŠ¡çŠ¶æ€
        self.data: Dict[str, Any] = {}
        self.generated_code: Dict[str, str] = {}

    def reset(self):
        self.data = {}
        self.generated_code = {}
        self.project_dir = None


_g = GlobalState()


# ==================== å·¥å…·å®šä¹‰ (OpenAI Function Schema) ====================

TOOLS_SCHEMA = [
    {
        "type": "function",
        "function": {
            "name": "init_project",
            "description": "åˆå§‹åŒ–é¡¹ç›®ç›®å½•ç»“æ„ã€‚è¿™æ˜¯é¡¹ç›®ç”Ÿæˆçš„ç¬¬ä¸€æ­¥ã€‚",
            "parameters": {
                "type": "object",
                "properties": {
                    "project_name": {
                        "type": "string",
                        "description": "é¡¹ç›®åç§°ï¼ˆè‹±æ–‡ï¼Œsnake_caseï¼‰",
                    }
                },
                "required": ["project_name"],
            },
        },
    },
    {
        "type": "function",
        "function": {
            "name": "analyze_requirements",
            "description": "åˆ†æç”¨æˆ·éœ€æ±‚ï¼Œæå–å®ä½“ã€å…³ç³»å’Œä¸šåŠ¡è§„åˆ™ã€‚è¾“å‡ºä¼šå½±å“åç»­æ‰€æœ‰æ­¥éª¤ã€‚",
            "parameters": {
                "type": "object",
                "properties": {
                    "requirements": {"type": "string", "description": "ç”¨æˆ·çš„éœ€æ±‚æè¿°"},
                    "project_type": {
                        "type": "string",
                        "description": "é¡¹ç›®ç±»å‹: api/web/cli",
                        "default": "api",
                    },
                },
                "required": ["requirements"],
            },
        },
    },
    {
        "type": "function",
        "function": {
            "name": "design_api",
            "description": "åŸºäºéœ€æ±‚åˆ†æç»“æœè®¾è®¡ REST API ç«¯ç‚¹ã€‚éœ€è¦å…ˆè°ƒç”¨ analyze_requirementsã€‚",
            "parameters": {
                "type": "object",
                "properties": {
                    "project_name": {"type": "string", "description": "é¡¹ç›®åç§°"}
                },
                "required": ["project_name"],
            },
        },
    },
    {
        "type": "function",
        "function": {
            "name": "generate_models",
            "description": "åŸºäºå®ä½“å®šä¹‰ç”Ÿæˆ Pydantic æ¨¡å‹ä»£ç ã€‚éœ€è¦å…ˆè°ƒç”¨ analyze_requirementsã€‚",
            "parameters": {"type": "object", "properties": {}, "required": []},
        },
    },
    {
        "type": "function",
        "function": {
            "name": "generate_service",
            "description": "åŸºäºæ¨¡å‹å’Œ API è®¾è®¡ç”ŸæˆæœåŠ¡å±‚ä»£ç ã€‚éœ€è¦å…ˆè°ƒç”¨ generate_modelsã€‚",
            "parameters": {"type": "object", "properties": {}, "required": []},
        },
    },
    {
        "type": "function",
        "function": {
            "name": "generate_router",
            "description": "åŸºäº API è®¾è®¡å’ŒæœåŠ¡å±‚ç”Ÿæˆ FastAPI è·¯ç”±ä»£ç ã€‚éœ€è¦å…ˆè°ƒç”¨ generate_serviceã€‚",
            "parameters": {"type": "object", "properties": {}, "required": []},
        },
    },
    {
        "type": "function",
        "function": {
            "name": "generate_tests",
            "description": "åŸºäº API ç«¯ç‚¹ç”Ÿæˆ pytest æµ‹è¯•ç”¨ä¾‹ã€‚",
            "parameters": {"type": "object", "properties": {}, "required": []},
        },
    },
    {
        "type": "function",
        "function": {
            "name": "write_code",
            "description": "å°†ç”Ÿæˆçš„ä»£ç å†™å…¥æ–‡ä»¶ã€‚æ¯æ¬¡ç”Ÿæˆä»£ç åå¿…é¡»è°ƒç”¨æ­¤å·¥å…·ã€‚",
            "parameters": {
                "type": "object",
                "properties": {
                    "filename": {
                        "type": "string",
                        "description": "æ–‡ä»¶å (å¦‚ models.py)",
                    },
                    "code_type": {
                        "type": "string",
                        "enum": ["models", "service", "router", "tests"],
                        "description": "ä»£ç ç±»å‹",
                    },
                },
                "required": ["filename", "code_type"],
            },
        },
    },
    {
        "type": "function",
        "function": {
            "name": "validate_project",
            "description": "éªŒè¯ç”Ÿæˆçš„é¡¹ç›®ä»£ç æ˜¯å¦ä¸€è‡´ã€å®Œæ•´ã€‚è¿™æ˜¯æœ€åä¸€æ­¥ã€‚",
            "parameters": {"type": "object", "properties": {}, "required": []},
        },
    },
]


# ==================== å·¥å…·å®ç° ====================


async def _llm_call(prompt: str, step_name: str) -> str:
    """è°ƒç”¨ LLM å¹¶è®°å½• tokenï¼ˆä½¿ç”¨ stream é¿å…è¶…æ—¶ï¼‰"""
    chunks = []
    total_tokens = 0

    stream = await _g.client.chat.completions.create(
        model=_g.model,
        messages=[{"role": "user", "content": prompt}],
        temperature=0.3,
        stream=True,
        stream_options={"include_usage": True},
    )

    async for chunk in stream:
        # æ”¶é›†å†…å®¹å—
        if chunk.choices and chunk.choices[0].delta.content:
            chunks.append(chunk.choices[0].delta.content)
        # æœ€åä¸€ä¸ª chunk åŒ…å« usage ä¿¡æ¯
        if chunk.usage:
            total_tokens = chunk.usage.total_tokens

    # è®°å½• token æ¶ˆè€—
    if total_tokens > 0 and _g.tracker:
        _g.tracker.add(total_tokens, f"tool:{step_name}")

    # è¿”å›æ‹¼æ¥å¥½çš„å®Œæ•´å­—ç¬¦ä¸²
    return "".join(chunks)


async def tool_init_project(args: Dict[str, Any]) -> Dict[str, Any]:
    """åˆå§‹åŒ–é¡¹ç›® è¿™é‡Œå’Œauto_agentç‰ˆæœ¬ç¨å¾®æœ‰äº›å·®å¼‚ï¼Œå¯èƒ½ä¼šå¯¼è‡´ä¸€äº›ä¸ä¸€è‡´çš„åœ°æ–¹"""
    project_name = args.get("project_name", "my_project")
    _g.project_dir = _g.output_dir / project_name
    _g.project_dir.mkdir(parents=True, exist_ok=True)
    _g.data["project_name"] = project_name

    print(f"   âœ… é¡¹ç›®ç›®å½•: {_g.project_dir}")
    return {"success": True, "project_dir": str(_g.project_dir)}


async def tool_analyze_requirements(args: Dict[str, Any]) -> Dict[str, Any]:
    """åˆ†æéœ€æ±‚"""
    requirements = args.get("requirements", "")
    project_type = args.get("project_type", "api")

    prompt = f"""è¯·åˆ†æä»¥ä¸‹é¡¹ç›®éœ€æ±‚ï¼Œæå–å…³é”®ä¿¡æ¯ã€‚

é¡¹ç›®ç±»å‹: {project_type}
éœ€æ±‚æè¿°:
{requirements}

è¯·ä»¥ JSON æ ¼å¼è¿”å›:
è¯·ä»¥ JSON æ ¼å¼è¿”å›åˆ†æç»“æœ:
{{
    "project_name": "é¡¹ç›®åç§°ï¼ˆè‹±æ–‡ï¼Œsnake_caseï¼‰",
    "description": "é¡¹ç›®æè¿°",
    "entities": [
        {{
            "name": "å®ä½“åç§°ï¼ˆè‹±æ–‡ï¼ŒPascalCaseï¼‰",
            "description": "å®ä½“æè¿°",
            "fields": [
                {{"name": "å­—æ®µå", "type": "ç±»å‹", "required": true/false, "description": "æè¿°"}}
            ]
        }}
    ],
    "relationships": [
        {{"from": "å®ä½“A", "to": "å®ä½“B", "type": "one-to-many/many-to-many/one-to-one", "description": "å…³ç³»æè¿°"}}
    ],
    "business_rules": [
        {{"rule": "è§„åˆ™æè¿°", "affects": ["ç›¸å…³å®ä½“"]}}
    ],
    "constraints": [
        {{"constraint": "çº¦æŸæè¿°", "type": "validation/security/performance"}}
    ],
    "api_style": "REST/GraphQL",
    "auth_required": true/false
}}"""

    text = await _llm_call(prompt, "analyze_requirements")

    json_match = re.search(r"\{.*\}", text, re.DOTALL)
    if json_match:
        result = json.loads(json_match.group())
        _g.data["entities"] = result.get("entities", [])
        _g.data["relationships"] = result.get("relationships", [])
        _g.data["business_rules"] = result.get("business_rules", [])

        print(f"   âœ… å®ä½“: {len(_g.data['entities'])} ä¸ª")
        return {"success": True, **result}

    return {"success": False, "error": "è§£æå¤±è´¥"}


async def tool_design_api(args: Dict[str, Any]) -> Dict[str, Any]:
    """è®¾è®¡ API"""
    entities = _g.data.get("entities", [])
    relationships = _g.data.get("relationships", [])

    if not entities:
        return {"success": False, "error": "è¯·å…ˆè°ƒç”¨ analyze_requirements"}

    prompt = f"""è¯·åŸºäºä»¥ä¸‹å®ä½“è®¾è®¡ REST APIã€‚

å®ä½“: {json.dumps(entities, ensure_ascii=False, indent=2)}
å…³ç³»: {json.dumps(relationships, ensure_ascii=False, indent=2)}

è¯·ä»¥ JSON æ ¼å¼è¿”å› API è®¾è®¡:
{{
    "base_path": "/api/v1",
    "endpoints": [
        {{
            "path": "/users",
            "method": "GET",
            "description": "è·å–ç”¨æˆ·åˆ—è¡¨",
            "request_params": {{"page": "int", "size": "int"}},
            "response_schema": "UserListResponse",
            "auth_required": true
        }},
        {{
            "path": "/users/{{id}}",
            "method": "GET",
            "description": "è·å–å•ä¸ªç”¨æˆ·",
            "path_params": {{"id": "int"}},
            "response_schema": "UserResponse",
            "auth_required": true
        }}
    ],
    "schemas": {{
        "UserResponse": {{
            "type": "object",
            "properties": {{
                "id": {{"type": "integer"}},
                "name": {{"type": "string"}}
            }}
        }}
    }},
    "error_responses": {{
        "400": "Bad Request",
        "401": "Unauthorized",
        "404": "Not Found",
        "500": "Internal Server Error"
    }}
}}

è¦æ±‚:
1. ä¸ºæ¯ä¸ªå®ä½“ç”Ÿæˆ CRUD ç«¯ç‚¹
2. è€ƒè™‘å®ä½“é—´çš„å…³ç³»ï¼Œç”ŸæˆåµŒå¥—èµ„æºç«¯ç‚¹
3. ä½¿ç”¨ RESTful é£æ ¼
4. æ‰€æœ‰ ID å‚æ•°ä½¿ç”¨æ•´æ•°ç±»å‹"""

    text = await _llm_call(prompt, "design_api")

    json_match = re.search(r"\{.*\}", text, re.DOTALL)
    if json_match:
        result = json.loads(json_match.group())
        _g.data["endpoints"] = result.get("endpoints", [])
        _g.data["schemas"] = result.get("schemas", {})

        print(f"   âœ… ç«¯ç‚¹: {len(_g.data['endpoints'])} ä¸ª")
        return {"success": True, **result}

    return {"success": False, "error": "è§£æå¤±è´¥"}


async def tool_generate_models(args: Dict[str, Any]) -> Dict[str, Any]:
    """ç”Ÿæˆæ¨¡å‹ä»£ç """
    entities = _g.data.get("entities", [])
    schemas = _g.data.get("schemas", {})

    if not entities:
        return {"success": False, "error": "è¯·å…ˆè°ƒç”¨ analyze_requirements"}

    prompt = f"""è¯·ç”Ÿæˆ Pydantic æ¨¡å‹ä»£ç ã€‚

å®ä½“: {json.dumps(entities, ensure_ascii=False, indent=2)}
Schema: {json.dumps(schemas, ensure_ascii=False, indent=2)}

è¯·ç”Ÿæˆå®Œæ•´çš„ Python ä»£ç ï¼ŒåŒ…å«:
1. å¿…è¦çš„ import è¯­å¥
2. åŸºç¡€æ¨¡å‹ç±»ï¼ˆBaseModel é…ç½®ï¼‰
3. æ¯ä¸ªå®ä½“çš„æ¨¡å‹ç±»ï¼ˆåŒ…å« Createã€Updateã€Response å˜ä½“ï¼‰
4. ç±»å‹æ³¨è§£å’Œå­—æ®µéªŒè¯
5. æ–‡æ¡£å­—ç¬¦ä¸²

ä»£ç é£æ ¼è¦æ±‚:
- ä½¿ç”¨ Pydantic v2 è¯­æ³•
- æ‰€æœ‰å­—æ®µéƒ½è¦æœ‰ç±»å‹æ³¨è§£
- å¯é€‰å­—æ®µä½¿ç”¨ Optional
- ID å­—æ®µä½¿ç”¨ int ç±»å‹

è¯·ç›´æ¥è¾“å‡º Python ä»£ç ï¼Œç”¨ ```python å’Œ ``` åŒ…è£¹ã€‚"""

    text = await _llm_call(prompt, "generate_models")

    code_match = re.search(r"```python\n(.*?)```", text, re.DOTALL)
    code = code_match.group(1).strip() if code_match else text.strip()

    _g.generated_code["models"] = code
    model_names = re.findall(r"class (\w+)\(", code)
    _g.data["model_names"] = model_names

    print(f"   âœ… æ¨¡å‹: {len(model_names)} ä¸ª, {len(code.split(chr(10)))} è¡Œ")
    return {
        "success": True,
        "model_names": model_names,
        "line_count": len(code.split("\n")),
    }


async def tool_generate_service(args: Dict[str, Any]) -> Dict[str, Any]:
    """ç”ŸæˆæœåŠ¡å±‚ä»£ç """
    model_names = _g.data.get("model_names", [])
    endpoints = _g.data.get("endpoints", [])
    entities = _g.data.get("entities", [])

    if not model_names:
        return {"success": False, "error": "è¯·å…ˆè°ƒç”¨ generate_models"}

    prompt = f"""è¯·ç”ŸæˆæœåŠ¡å±‚ä»£ç ã€‚

æ¨¡å‹ç±»: {json.dumps(model_names)}
ç«¯ç‚¹: {json.dumps(endpoints, ensure_ascii=False, indent=2)}
å®ä½“: {json.dumps(entities, ensure_ascii=False, indent=2)}

è¯·ç”Ÿæˆå®Œæ•´çš„æœåŠ¡å±‚ Python ä»£ç ï¼ŒåŒ…å«:
1. å¿…è¦çš„ import è¯­å¥ï¼ˆä» models æ¨¡å—å¯¼å…¥æ¨¡å‹ç±»ï¼‰
2. æœåŠ¡ç±»ï¼ˆæ¯ä¸ªå®ä½“ä¸€ä¸ªæœåŠ¡ç±»ï¼‰
3. CRUD æ–¹æ³•å®ç°ï¼ˆä½¿ç”¨ async/awaitï¼‰
4. ç±»å‹æ³¨è§£
5. é”™è¯¯å¤„ç†

ä»£ç é£æ ¼è¦æ±‚:
- ä½¿ç”¨ä¾èµ–æ³¨å…¥æ¨¡å¼
- æ–¹æ³•å‚æ•°å’Œè¿”å›å€¼éƒ½è¦æœ‰ç±»å‹æ³¨è§£
- ä½¿ç”¨å·²å®šä¹‰çš„æ¨¡å‹ç±»åï¼ˆä¸è¦è‡ªå·±åˆ›é€ æ–°çš„ç±»åï¼‰
- ID å‚æ•°ä½¿ç”¨ int ç±»å‹

è¯·ç›´æ¥è¾“å‡º Python ä»£ç ï¼Œç”¨ ```python å’Œ ``` åŒ…è£¹ã€‚"""

    text = await _llm_call(prompt, "generate_service")

    code_match = re.search(r"```python\n(.*?)```", text, re.DOTALL)
    code = code_match.group(1).strip() if code_match else text.strip()

    _g.generated_code["service"] = code
    methods = re.findall(r"async def (\w+)\(", code)
    _g.data["service_methods"] = methods

    print(f"   âœ… æ–¹æ³•: {len(methods)} ä¸ª, {len(code.split(chr(10)))} è¡Œ")
    return {
        "success": True,
        "service_methods": methods,
        "line_count": len(code.split("\n")),
    }


async def tool_generate_router(args: Dict[str, Any]) -> Dict[str, Any]:
    """ç”Ÿæˆè·¯ç”±ä»£ç """
    endpoints = _g.data.get("endpoints", [])
    service_methods = _g.data.get("service_methods", [])
    model_names = _g.data.get("model_names", [])

    if not service_methods:
        return {"success": False, "error": "è¯·å…ˆè°ƒç”¨ generate_service"}

    prompt = f"""è¯·ç”Ÿæˆ FastAPI è·¯ç”±ä»£ç ã€‚

ç«¯ç‚¹: {json.dumps(endpoints, ensure_ascii=False, indent=2)}
æœåŠ¡æ–¹æ³•: {json.dumps(service_methods)}
æ¨¡å‹ç±»: {json.dumps(model_names)}

è¯·ç”Ÿæˆå®Œæ•´çš„ FastAPI è·¯ç”± Python ä»£ç ï¼ŒåŒ…å«:
1. å¿…è¦çš„ import è¯­å¥
2. APIRouter å®ä¾‹
3. æ¯ä¸ªç«¯ç‚¹çš„è·¯ç”±å‡½æ•°
4. ä¾èµ–æ³¨å…¥ï¼ˆæœåŠ¡ç±»ï¼‰
5. è¯·æ±‚/å“åº”æ¨¡å‹
6. é”™è¯¯å¤„ç†

ä»£ç é£æ ¼è¦æ±‚:
- ä½¿ç”¨ FastAPI çš„ä¾èµ–æ³¨å…¥
- è·¯ç”±å‡½æ•°ä½¿ç”¨ async/await
- æ­£ç¡®ä½¿ç”¨å·²å®šä¹‰çš„æ¨¡å‹ç±»å’ŒæœåŠ¡æ–¹æ³•
- æ·»åŠ  OpenAPI æ–‡æ¡£æ³¨è§£
- ID å‚æ•°ä½¿ç”¨ int ç±»å‹

è¯·ç›´æ¥è¾“å‡º Python ä»£ç ï¼Œç”¨ ```python å’Œ ``` åŒ…è£¹ã€‚"""

    text = await _llm_call(prompt, "generate_router")

    code_match = re.search(r"```python\n(.*?)```", text, re.DOTALL)
    code = code_match.group(1).strip() if code_match else text.strip()

    _g.generated_code["router"] = code
    route_count = len(re.findall(r"@router\.(get|post|put|delete|patch)", code))

    print(f"   âœ… è·¯ç”±: {route_count} ä¸ª, {len(code.split(chr(10)))} è¡Œ")
    return {
        "success": True,
        "route_count": route_count,
        "line_count": len(code.split("\n")),
    }


async def tool_generate_tests(args: Dict[str, Any]) -> Dict[str, Any]:
    """ç”Ÿæˆæµ‹è¯•ä»£ç """
    endpoints = _g.data.get("endpoints", [])
    model_names = _g.data.get("model_names", [])

    if not endpoints:
        return {"success": False, "error": "è¯·å…ˆè°ƒç”¨ design_api"}

    prompt = f"""è¯·ç”Ÿæˆ pytest æµ‹è¯•ä»£ç ã€‚

ç«¯ç‚¹: {json.dumps(endpoints, ensure_ascii=False, indent=2)}
æ¨¡å‹ç±»: {json.dumps(model_names)}

è¯·ç”Ÿæˆå®Œæ•´çš„ pytest æµ‹è¯•ä»£ç ï¼ŒåŒ…å«:
1. å¿…è¦çš„ import è¯­å¥
2. pytest fixturesï¼ˆTestClientã€æµ‹è¯•æ•°æ®ï¼‰
3. æ¯ä¸ªç«¯ç‚¹çš„æµ‹è¯•å‡½æ•°
4. æ­£å‘æµ‹è¯•å’Œå¼‚å¸¸æµ‹è¯•
5. æ–­è¨€éªŒè¯

ä»£ç é£æ ¼è¦æ±‚:
- ä½¿ç”¨ pytest å’Œ httpx
- æµ‹è¯•å‡½æ•°å‘½å: test_<method>_<resource>_<scenario>
- ä½¿ç”¨ fixtures ç®¡ç†æµ‹è¯•æ•°æ®
- åŒ…å«è¾¹ç•Œæ¡ä»¶æµ‹è¯•

è¯·ç›´æ¥è¾“å‡º Python ä»£ç ï¼Œç”¨ ```python å’Œ ``` åŒ…è£¹ã€‚"""

    text = await _llm_call(prompt, "generate_tests")

    code_match = re.search(r"```python\n(.*?)```", text, re.DOTALL)
    code = code_match.group(1).strip() if code_match else text.strip()

    _g.generated_code["tests"] = code
    test_count = len(re.findall(r"def test_\w+\(", code))

    print(f"   âœ… æµ‹è¯•: {test_count} ä¸ª, {len(code.split(chr(10)))} è¡Œ")
    return {
        "success": True,
        "test_count": test_count,
        "line_count": len(code.split("\n")),
    }


async def tool_write_code(args: Dict[str, Any]) -> Dict[str, Any]:
    """å†™å…¥ä»£ç æ–‡ä»¶"""
    filename = args.get("filename", "")
    code_type = args.get("code_type", "")

    code = _g.generated_code.get(code_type, "")
    if not code:
        return {"success": False, "error": f"æ²¡æœ‰ {code_type} ä»£ç "}

    if not _g.project_dir:
        return {"success": False, "error": "é¡¹ç›®æœªåˆå§‹åŒ–"}

    file_path = _g.project_dir / filename
    file_path.write_text(code, encoding="utf-8")

    print(f"   âœ… å†™å…¥: {filename}")
    return {"success": True, "filename": filename, "file_path": str(file_path)}


async def tool_validate_project(args: Dict[str, Any]) -> Dict[str, Any]:
    """éªŒè¯é¡¹ç›®"""
    models_code = _g.generated_code.get("models", "")[:1500]
    service_code = _g.generated_code.get("service", "")[:1500]
    router_code = _g.generated_code.get("router", "")[:1500]

    if not all([models_code, service_code, router_code]):
        return {"success": False, "error": "ä»£ç ä¸å®Œæ•´"}

    prompt = f"""è¯·éªŒè¯ä»¥ä¸‹ä»£ç çš„ä¸€è‡´æ€§ã€‚

æ¨¡å‹ä»£ç :
{models_code}

æœåŠ¡ä»£ç :
{service_code}

è·¯ç”±ä»£ç :
{router_code}

è¯·æ£€æŸ¥:
1. æ¨¡å‹ç±»æ˜¯å¦åœ¨æœåŠ¡å’Œè·¯ç”±ä¸­æ­£ç¡®ä½¿ç”¨
2. æœåŠ¡æ–¹æ³•æ˜¯å¦åœ¨è·¯ç”±ä¸­æ­£ç¡®è°ƒç”¨
3. ç±»å‹æ³¨è§£æ˜¯å¦ä¸€è‡´
4. æ˜¯å¦æœ‰æœªå®šä¹‰çš„å¼•ç”¨
5. ID å‚æ•°ç±»å‹æ˜¯å¦ç»Ÿä¸€ä¸º int

è¯·ä»¥ JSON æ ¼å¼è¿”å›éªŒè¯ç»“æœ:
{{
    "is_valid": true/false,
    "issues": [
        {{"severity": "error/warning", "location": "ä½ç½®", "description": "é—®é¢˜æè¿°"}}
    ],
    "suggestions": ["æ”¹è¿›å»ºè®®1", "æ”¹è¿›å»ºè®®2"],
    "summary": "éªŒè¯æ€»ç»“"
}}"""

    text = await _llm_call(prompt, "validate_project")

    json_match = re.search(r"\{.*\}", text, re.DOTALL)
    if json_match:
        result = json.loads(json_match.group())
        status = "âœ… é€šè¿‡" if result.get("is_valid") else "âš ï¸ æœ‰é—®é¢˜"
        print(f"   {status}")
        return {"success": True, **result}

    return {"success": True, "is_valid": True, "issues": []}


# å·¥å…·æ˜ å°„
TOOL_HANDLERS = {
    "init_project": tool_init_project,
    "analyze_requirements": tool_analyze_requirements,
    "design_api": tool_design_api,
    "generate_models": tool_generate_models,
    "generate_service": tool_generate_service,
    "generate_router": tool_generate_router,
    "generate_tests": tool_generate_tests,
    "write_code": tool_write_code,
    "validate_project": tool_validate_project,
}


# ==================== Agent ä¸»å¾ªç¯ (æ¨¡æ‹Ÿ LangChain ReAct) ====================

SYSTEM_PROMPT = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å…¨æ ˆé¡¹ç›®ç”Ÿæˆæ™ºèƒ½ä½“ï¼Œèƒ½å¤Ÿè‡ªä¸»è§„åˆ’å’Œç”Ÿæˆå®Œæ•´çš„ REST API é¡¹ç›®ã€‚

## ä½ çš„èƒ½åŠ›
ä½ å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å·¥å…·å®Œæˆé¡¹ç›®ç”Ÿæˆä»»åŠ¡ï¼š
1. init_project - åˆå§‹åŒ–é¡¹ç›®ç›®å½•
2. analyze_requirements - åˆ†æéœ€æ±‚ï¼Œæå–å®ä½“å’Œå…³ç³»
3. design_api - è®¾è®¡ REST API ç«¯ç‚¹
4. generate_models - ç”Ÿæˆ Pydantic æ¨¡å‹ä»£ç 
5. generate_service - ç”ŸæˆæœåŠ¡å±‚ä»£ç 
6. generate_router - ç”Ÿæˆ FastAPI è·¯ç”±ä»£ç 
7. generate_tests - ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹
8. write_code - å°†ä»£ç å†™å…¥æ–‡ä»¶
9. validate_project - éªŒè¯é¡¹ç›®ä¸€è‡´æ€§

## å·¥ä½œæµç¨‹
è¯·ä¸¥æ ¼æŒ‰ä»¥ä¸‹é¡ºåºæ‰§è¡Œï¼š
1. init_project - åˆå§‹åŒ–é¡¹ç›®ç›®å½•
2. analyze_requirements - åˆ†æéœ€æ±‚
3. design_api - è®¾è®¡ API
4. generate_models â†’ write_code(filename="models.py", code_type="models")
5. generate_service â†’ write_code(filename="service.py", code_type="service")
6. generate_router â†’ write_code(filename="router.py", code_type="router")
7. generate_tests â†’ write_code(filename="test_api.py", code_type="tests")
8. validate_project - éªŒè¯ä¸€è‡´æ€§

## é‡è¦è§„åˆ™
- æ¯æ¬¡ç”Ÿæˆä»£ç åï¼Œå¿…é¡»ç«‹å³è°ƒç”¨ write_code å†™å…¥æ–‡ä»¶
- å„å±‚ä»£ç ä½¿ç”¨ä¸€è‡´çš„ç±»åå’Œæ–¹æ³•å
- æ‰€æœ‰ ID å‚æ•°ä½¿ç”¨ int ç±»å‹
- ç¡®ä¿æŒ‰é¡ºåºæ‰§è¡Œï¼Œå› ä¸ºåç»­æ­¥éª¤ä¾èµ–å‰é¢çš„ç»“æœ"""


async def run_agent_loop(query: str) -> Dict[str, Any]:
    """è¿è¡Œ Agent å¾ªç¯ (æ¨¡æ‹Ÿ LangChain ReAct æ¨¡å¼)"""

    messages = [
        {"role": "system", "content": SYSTEM_PROMPT},
        {"role": "user", "content": query},
    ]

    max_iterations = 25
    iteration = 0
    tool_calls_count = 0

    while iteration < max_iterations:
        iteration += 1
        print(f"\n--- è¿­ä»£ {iteration} ---")

        # è°ƒç”¨ LLM
        response = await _g.client.chat.completions.create(
            model=_g.model,
            messages=messages,
            tools=TOOLS_SCHEMA,
            tool_choice="auto",
            temperature=0.3,
        )

        # è®°å½• token
        if response.usage and _g.tracker:
            _g.tracker.add(response.usage.total_tokens, f"agent_iter_{iteration}")

        message = response.choices[0].message

        # æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨
        if message.tool_calls:
            messages.append(message)

            for tool_call in message.tool_calls:
                func_name = tool_call.function.name
                func_args = json.loads(tool_call.function.arguments)

                print(f"   ğŸ”§ è°ƒç”¨å·¥å…·: {func_name}")
                tool_calls_count += 1

                # æ‰§è¡Œå·¥å…·
                handler = TOOL_HANDLERS.get(func_name)
                if handler:
                    try:
                        result = await handler(func_args)
                    except Exception as e:
                        result = {"success": False, "error": str(e)}
                else:
                    result = {"success": False, "error": f"æœªçŸ¥å·¥å…·: {func_name}"}

                # æ·»åŠ å·¥å…·ç»“æœ
                messages.append(
                    {
                        "role": "tool",
                        "tool_call_id": tool_call.id,
                        "content": json.dumps(result, ensure_ascii=False)[:3000],
                    }
                )
        else:
            # æ²¡æœ‰å·¥å…·è°ƒç”¨ï¼ŒAgent å®Œæˆ
            final_output = message.content or ""
            print(f"\nâœ… Agent å®Œæˆæ¨ç†")

            return {
                "success": True,
                "output": final_output,
                "iterations": iteration,
                "tool_calls": tool_calls_count,
            }

    return {
        "success": False,
        "error": "è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°",
        "iterations": iteration,
        "tool_calls": tool_calls_count,
    }


async def run_langchain_fullstack(
    requirements: str,
    project_name: str,
    output_dir: Path,
) -> Dict[str, Any]:
    """è¿è¡Œå…¨æ ˆé¡¹ç›®ç”Ÿæˆ"""

    print("=" * 70)
    print("ğŸ—ï¸  LangChain é£æ ¼å…¨æ ˆé¡¹ç›®ç”Ÿæˆå™¨ (OpenAI åŸç”Ÿå®¢æˆ·ç«¯)")
    print("=" * 70)

    # åˆå§‹åŒ–
    api_key = os.getenv("OPENAI_API_KEY") or os.getenv("DEEPSEEK_API_KEY")
    base_url = os.getenv("OPENAI_BASE_URL", "https://api.deepseek.com/v1")
    model = os.getenv("OPENAI_MODEL", "deepseek-chat")

    _g.client = AsyncOpenAI(api_key=api_key, base_url=base_url)
    _g.model = model
    _g.output_dir = output_dir
    _g.tracker = TokenTracker()
    _g.reset()

    print(f"\nâœ… å®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ (model: {model})")
    print(f"ğŸ“ è¾“å‡ºç›®å½•: {output_dir}")
    print(f"ğŸ“‹ é¡¹ç›®åç§°: {project_name}")

    # æ„å»ºæŸ¥è¯¢
    query = f"""
è¯·å¸®æˆ‘ç”Ÿæˆä¸€ä¸ªå®Œæ•´çš„ REST API é¡¹ç›®ã€‚

é¡¹ç›®åç§°: {project_name}

éœ€æ±‚æè¿°:
{requirements}

è¯·æŒ‰ä»¥ä¸‹æ­¥éª¤æ‰§è¡Œ:
1. åˆå§‹åŒ–é¡¹ç›®ç›®å½• (init_project)
2. åˆ†æéœ€æ±‚ï¼Œæå–å®ä½“å’Œå…³ç³» (analyze_requirements)
3. è®¾è®¡ REST API ç«¯ç‚¹ (design_api)
4. ç”Ÿæˆ Pydantic æ•°æ®æ¨¡å‹ (generate_models)ï¼Œç„¶åç”¨ write_code å†™å…¥ models.py
5. ç”ŸæˆæœåŠ¡å±‚ä»£ç  (generate_service)ï¼Œç„¶åç”¨ write_code å†™å…¥ service.py
6. ç”Ÿæˆ FastAPI è·¯ç”±ä»£ç  (generate_router)ï¼Œç„¶åç”¨ write_code å†™å…¥ router.py
7. ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹ (generate_tests)ï¼Œç„¶åç”¨ write_code å†™å…¥ test_api.py
8. éªŒè¯é¡¹ç›®ä¸€è‡´æ€§ (validate_project)

é‡è¦è§„åˆ™:
- æ¯æ¬¡ç”Ÿæˆä»£ç åï¼Œå¿…é¡»ç«‹å³è°ƒç”¨ write_code å·¥å…·å°†ä»£ç å†™å…¥æ–‡ä»¶
- å„å±‚ä»£ç ä½¿ç”¨ä¸€è‡´çš„ç±»åå’Œæ–¹æ³•å
- æ‰€æœ‰ ID å‚æ•°ä½¿ç”¨ int ç±»å‹
- ä»£ç ç¬¦åˆ Python æœ€ä½³å®è·µ
"""

    print("\n" + "=" * 70)
    print("ğŸš€ å¼€å§‹æ‰§è¡Œ...")
    print("=" * 70)

    start_time = time.time()

    try:
        result = await run_agent_loop(query)

        end_time = time.time()
        duration_ms = (end_time - start_time) * 1000

        print("\n" + "=" * 70)
        print("âœ… æ‰§è¡Œå®Œæˆ!")
        print("=" * 70)

        # ç»Ÿè®¡
        print(f"\nğŸ“Š æ‰§è¡Œç»Ÿè®¡:")
        print(f"   - è¿­ä»£æ¬¡æ•°: {result.get('iterations', 0)}")
        print(f"   - å·¥å…·è°ƒç”¨: {result.get('tool_calls', 0)} æ¬¡")
        print(f"   - LLM è°ƒç”¨: {_g.tracker.llm_call_count} æ¬¡")
        print(f"   - Token æ¶ˆè€—: {_g.tracker.cumulative_tokens:,}")
        print(f"   - è€—æ—¶: {duration_ms:.1f}ms ({duration_ms / 1000:.1f}s)")

        # Token æ˜ç»†
        print(f"\nğŸ“Š Token æ¶ˆè€—æ˜ç»†:")
        for step in _g.tracker.steps:
            print(
                f"      {step['step']}: +{step['tokens']:,} (ç´¯è®¡: {step['cumulative']:,})"
            )

        # ç”Ÿæˆçš„æ–‡ä»¶
        generated_files = list(_g.generated_code.keys())
        print(f"\nğŸ“ ç”Ÿæˆä»£ç : {', '.join(generated_files)}")

        return {
            "success": result.get("success", False),
            "output": result.get("output", ""),
            "project_name": project_name,
            "output_dir": str(output_dir / project_name)
            if _g.project_dir
            else str(output_dir),
            "generated_files": generated_files,
            "iterations": result.get("iterations", 0),
            "tool_calls": result.get("tool_calls", 0),
            "llm_calls": _g.tracker.llm_call_count,
            "total_tokens": _g.tracker.cumulative_tokens,
            "token_steps": _g.tracker.steps,
            "duration_ms": duration_ms,
        }

    except Exception as e:
        end_time = time.time()
        print(f"\nâŒ æ‰§è¡Œå¤±è´¥: {e}")
        import traceback

        traceback.print_exc()

        return {
            "success": False,
            "error": str(e),
            "duration_ms": (end_time - start_time) * 1000,
            "total_tokens": _g.tracker.cumulative_tokens if _g.tracker else 0,
        }


# ==================== ç¤ºä¾‹éœ€æ±‚ ====================

SAMPLE_REQUIREMENTS = {
    "task": """
ä¸€ä¸ªä»»åŠ¡ç®¡ç†ç³»ç»Ÿ APIï¼ŒåŒ…å«ä»¥ä¸‹åŠŸèƒ½ï¼š

1. é¡¹ç›®ç®¡ç†
   - åˆ›å»ºã€ç¼–è¾‘ã€åˆ é™¤é¡¹ç›®
   - é¡¹ç›®æˆå‘˜ç®¡ç†
   - é¡¹ç›®çŠ¶æ€ï¼ˆè¿›è¡Œä¸­ã€å·²å®Œæˆã€å·²å½’æ¡£ï¼‰

2. ä»»åŠ¡ç®¡ç†
   - åˆ›å»ºã€ç¼–è¾‘ã€åˆ é™¤ä»»åŠ¡
   - ä»»åŠ¡å±æ€§ï¼ˆæ ‡é¢˜ã€æè¿°ã€ä¼˜å…ˆçº§ã€æˆªæ­¢æ—¥æœŸï¼‰
   - ä»»åŠ¡çŠ¶æ€ï¼ˆå¾…åŠã€è¿›è¡Œä¸­ã€å·²å®Œæˆï¼‰
   - ä»»åŠ¡åˆ†é…ç»™æˆå‘˜
   - å­ä»»åŠ¡æ”¯æŒ

3. æ ‡ç­¾ç³»ç»Ÿ
   - åˆ›å»ºã€ç¼–è¾‘ã€åˆ é™¤æ ‡ç­¾
   - ä»»åŠ¡å¯ä»¥æœ‰å¤šä¸ªæ ‡ç­¾

4. è¯„è®ºå’Œé™„ä»¶
   - ä»»åŠ¡è¯„è®º
   - ä»»åŠ¡é™„ä»¶ä¸Šä¼ 

5. ä¸šåŠ¡è§„åˆ™
   - åªæœ‰é¡¹ç›®æˆå‘˜å¯ä»¥æŸ¥çœ‹/ç¼–è¾‘é¡¹ç›®å†…çš„ä»»åŠ¡
   - å®Œæˆæ‰€æœ‰å­ä»»åŠ¡åçˆ¶ä»»åŠ¡è‡ªåŠ¨å®Œæˆ
   - åˆ é™¤é¡¹ç›®æ—¶åˆ é™¤æ‰€æœ‰ç›¸å…³ä»»åŠ¡
""",
}


async def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¯åŠ¨ LangChain é£æ ¼å…¨æ ˆé¡¹ç›®ç”Ÿæˆå™¨...")

    # æ£€æŸ¥ API Key
    api_key = os.getenv("OPENAI_API_KEY") or os.getenv("DEEPSEEK_API_KEY")
    if not api_key:
        print("âŒ æœªè®¾ç½® API Key")
        return

    # è¾“å‡ºç›®å½•
    output_dir = Path(__file__).parent.parent / "output"
    output_dir.mkdir(exist_ok=True)

    # é¡¹ç›®é…ç½®
    project_name = "task_api_langchain"
    requirements = SAMPLE_REQUIREMENTS["task"]

    result = await run_langchain_fullstack(requirements, project_name, output_dir)

    # ä¿å­˜æŠ¥å‘Š
    if result.get("success"):
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        report_file = output_dir / f"langchain_fullstack_report_{timestamp}.md"

        # Token æ˜ç»†
        token_detail = (
            "\n### Token æ¶ˆè€—æ˜ç»†\n\n| æ­¥éª¤ | Token | ç´¯è®¡ |\n|------|-------|------|\n"
        )
        for step in result.get("token_steps", []):
            token_detail += (
                f"| {step['step']} | {step['tokens']:,} | {step['cumulative']:,} |\n"
            )

        report_file.write_text(
            f"""# LangChain é£æ ¼å…¨æ ˆé¡¹ç›®ç”ŸæˆæŠ¥å‘Š

> ç”Ÿæˆæ—¶é—´: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}
> æ¡†æ¶: OpenAI Function Calling (LangChain ReAct é£æ ¼)

## é¡¹ç›®ä¿¡æ¯

- é¡¹ç›®åç§°: {result["project_name"]}
- è¾“å‡ºç›®å½•: {result["output_dir"]}
- ç”Ÿæˆæ–‡ä»¶: {", ".join(result.get("generated_files", []))}

## æ‰§è¡Œç»Ÿè®¡

- è¿­ä»£æ¬¡æ•°: {result.get("iterations", 0)}
- å·¥å…·è°ƒç”¨æ¬¡æ•°: {result.get("tool_calls", 0)}
- LLM è°ƒç”¨æ¬¡æ•°: {result.get("llm_calls", 0)}
- Token æ¶ˆè€—: {result.get("total_tokens", 0):,}
- æ€»è€—æ—¶: {result["duration_ms"]:.1f}ms ({result["duration_ms"] / 1000:.1f}s)
{token_detail}

## Agent è¾“å‡º

{result.get("output", "")}
""",
            encoding="utf-8",
        )

        print(f"\nğŸ“„ æŠ¥å‘Šå·²ä¿å­˜: {report_file}")


if __name__ == "__main__":
    print("=" * 70)
    print("LangChain é£æ ¼å…¨æ ˆé¡¹ç›®ç”Ÿæˆå™¨")
    print("=" * 70)
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\nâš ï¸ ç”¨æˆ·ä¸­æ–­")
