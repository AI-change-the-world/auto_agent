"""
Deep Research æ™ºèƒ½ä½“ç¤ºä¾‹ - è‡ªä¸»è§„åˆ’ç‰ˆæœ¬

æ¼”ç¤ºç”¨æˆ·ç”¨è‡ªç„¶è¯­è¨€æè¿°éœ€æ±‚ï¼Œç”±æ™ºèƒ½ä½“è‡ªä¸»è§„åˆ’æ‰§è¡Œè·¯å¾„å¹¶å¾—åˆ°ç»“æœã€‚

æ ¸å¿ƒç‰¹ç‚¹ï¼š
- LLM æ ¹æ®ç”¨æˆ·éœ€æ±‚åŠ¨æ€è§„åˆ’æ‰§è¡Œæ­¥éª¤
- æ‰€æœ‰å·¥å…·éƒ½ä½¿ç”¨ LLM é©±åŠ¨ï¼Œä¸ä½¿ç”¨ç¡¬ç¼–ç é€»è¾‘
- åŒ…å«åæ€å·¥å…·å’Œè¯­è¨€æ¶¦è‰²å·¥å…·
- æ”¯æŒå¤±è´¥é‡è¯•å’Œé‡è§„åˆ’

ä½¿ç”¨æ–¹æ³•:
1. è®¾ç½®ç¯å¢ƒå˜é‡:
   export OPENAI_API_KEY=your-api-key  # æˆ– DEEPSEEK_API_KEY
   export OPENAI_BASE_URL=https://api.deepseek.com/v1  # å¯é€‰
   export OPENAI_MODEL=deepseek-chat  # å¯é€‰

2. å‡†å¤‡ç´ æï¼ˆå¯é€‰ï¼Œä¼šè‡ªåŠ¨åˆ›å»ºç¤ºä¾‹ï¼‰:
   åœ¨ examples/research_materials/ ç›®å½•ä¸‹æ”¾ç½® .txt æˆ– .md æ–‡ä»¶

3. è¿è¡Œ:
   python examples/deep_research_demo.py
"""

import asyncio
import json
import os
import re
from pathlib import Path
from typing import Any, Dict, List, Optional

from auto_agent import (
    AutoAgent,
    BaseTool,
    OpenAIClient,
    ToolDefinition,
    ToolParameter,
    ToolRegistry,
)


# ==================== LLM å®¢æˆ·ç«¯é…ç½® ====================


def get_llm_client() -> Optional[OpenAIClient]:
    """è·å– LLM å®¢æˆ·ç«¯ï¼ˆé€šè¿‡ç¯å¢ƒå˜é‡é…ç½®ï¼‰"""
    api_key = os.getenv("OPENAI_API_KEY") or os.getenv("DEEPSEEK_API_KEY")
    if not api_key:
        return None

    base_url = os.getenv("OPENAI_BASE_URL", "https://api.deepseek.com/v1")
    model = os.getenv("OPENAI_MODEL", "deepseek-chat")

    return OpenAIClient(
        api_key=api_key,
        base_url=base_url,
        model=model,
        timeout=120.0,
    )


# ==================== å·¥å…·å®šä¹‰ï¼ˆå…¨éƒ¨ä½¿ç”¨ LLM é©±åŠ¨ï¼‰ ====================


class ReadMaterialsTool(BaseTool):
    """
    è¯»å–ç ”ç©¶ç´ æå·¥å…·

    è¯»å–æŒ‡å®šç›®å½•ä¸‹çš„ç´ ææ–‡ä»¶ï¼Œå¹¶ä½¿ç”¨ LLM ç”Ÿæˆæ¯ä¸ªæ–‡ä»¶çš„æ‘˜è¦
    """

    def __init__(self, llm_client: OpenAIClient, materials_dir: str):
        self.llm_client = llm_client
        self.materials_dir = materials_dir

    @property
    def definition(self) -> ToolDefinition:
        return ToolDefinition(
            name="read_materials",
            description="è¯»å–ç ”ç©¶ç´ æç›®å½•ä¸‹çš„æ‰€æœ‰æ–‡ä»¶ï¼Œè¿”å›æ–‡ä»¶å†…å®¹å’Œ LLM ç”Ÿæˆçš„æ‘˜è¦ã€‚è¿™æ˜¯ç ”ç©¶çš„ç¬¬ä¸€æ­¥ï¼Œç”¨äºè·å–åŸå§‹æ•°æ®ã€‚",
            parameters=[
                ToolParameter(
                    name="file_types",
                    type="string",
                    description="è¦è¯»å–çš„æ–‡ä»¶ç±»å‹ï¼Œç”¨é€—å·åˆ†éš”ï¼ˆå¦‚ .txt,.mdï¼‰",
                    required=False,
                ),
            ],
            category="file_operation",
            output_schema={
                "materials": {"type": "array", "description": "ç´ æåˆ—è¡¨"},
                "total_files": {"type": "integer", "description": "æ–‡ä»¶æ€»æ•°"},
            },
        )

    async def execute(self, file_types: str = ".txt,.md", **kwargs) -> Dict[str, Any]:
        """è¯»å–ç´ ææ–‡ä»¶"""
        try:
            dir_path = Path(self.materials_dir)
            if not dir_path.exists():
                return {"success": False, "error": f"ç´ æç›®å½•ä¸å­˜åœ¨: {self.materials_dir}"}

            extensions = [ext.strip() for ext in file_types.split(",")]
            materials = []

            for file_path in dir_path.iterdir():
                if file_path.is_file() and file_path.suffix in extensions:
                    try:
                        content = file_path.read_text(encoding="utf-8")

                        # ä½¿ç”¨ LLM ç”Ÿæˆæ–‡ä»¶æ‘˜è¦
                        summary = await self._generate_summary(file_path.name, content)

                        materials.append({
                            "filename": file_path.name,
                            "content": content,
                            "summary": summary,
                            "word_count": len(content),
                        })
                    except Exception as e:
                        materials.append({
                            "filename": file_path.name,
                            "error": str(e),
                        })

            if not materials:
                return {"success": False, "error": f"ç›®å½•ä¸­æ²¡æœ‰æ‰¾åˆ° {file_types} æ ¼å¼çš„æ–‡ä»¶"}

            return {
                "success": True,
                "materials": materials,
                "total_files": len(materials),
                "total_words": sum(m.get("word_count", 0) for m in materials),
            }

        except Exception as e:
            return {"success": False, "error": str(e)}

    async def _generate_summary(self, filename: str, content: str) -> str:
        """ä½¿ç”¨ LLM ç”Ÿæˆæ–‡ä»¶æ‘˜è¦"""
        prompt = f"""è¯·ä¸ºä»¥ä¸‹æ–‡ä»¶å†…å®¹ç”Ÿæˆä¸€ä¸ªç®€æ´çš„æ‘˜è¦ï¼ˆ100å­—ä»¥å†…ï¼‰ã€‚

æ–‡ä»¶å: {filename}

å†…å®¹:
{content[:3000]}
{"..." if len(content) > 3000 else ""}

è¯·ç›´æ¥è¾“å‡ºæ‘˜è¦ï¼Œä¸è¦æœ‰ä»»ä½•å‰ç¼€ã€‚"""

        try:
            response = await self.llm_client.chat(
                [{"role": "user", "content": prompt}],
                temperature=0.3,
                max_tokens=200,
            )
            return response.strip()
        except Exception as e:
            return f"æ‘˜è¦ç”Ÿæˆå¤±è´¥: {str(e)}"


class AnalyzeContentTool(BaseTool):
    """
    å†…å®¹åˆ†æå·¥å…·

    ä½¿ç”¨ LLM åˆ†æç´ æå†…å®¹ï¼Œæå–ä¸»é¢˜ã€è®ºç‚¹ã€å…³é”®æ•°æ®ç­‰
    """

    def __init__(self, llm_client: OpenAIClient):
        self.llm_client = llm_client

    @property
    def definition(self) -> ToolDefinition:
        return ToolDefinition(
            name="analyze_content",
            description="åˆ†æç ”ç©¶ç´ æå†…å®¹ï¼Œä½¿ç”¨ LLM æå–ä¸»é¢˜ã€è®ºç‚¹ã€å…³é”®æ•°æ®å’ŒçŸ¥è¯†ç¼ºå£ã€‚è¿™æ˜¯æ·±åº¦ç ”ç©¶çš„æ ¸å¿ƒåˆ†ææ­¥éª¤ã€‚",
            parameters=[
                ToolParameter(
                    name="materials",
                    type="array",
                    description="ç´ æåˆ—è¡¨ï¼ˆä» read_materials è·å–ï¼‰",
                    required=True,
                ),
                ToolParameter(
                    name="focus",
                    type="string",
                    description="ç ”ç©¶é‡ç‚¹/å…³æ³¨æ–¹å‘",
                    required=False,
                ),
            ],
            category="analysis",
            output_schema={
                "analysis_result": {"type": "object", "description": "å®Œæ•´åˆ†æç»“æœ"},
                "main_themes": {"type": "array", "description": "ä¸»è¦ä¸»é¢˜"},
                "key_arguments": {"type": "array", "description": "æ ¸å¿ƒè®ºç‚¹"},
                "overall_insight": {"type": "string", "description": "æ•´ä½“æ´å¯Ÿ"},
            },
            # å‚æ•°åˆ«åï¼šä» state çš„å“ªä¸ªå­—æ®µè·å–å‚æ•°
            param_aliases={
                "materials": "materials",
            },
        )

    async def execute(
        self,
        materials: List[Dict[str, Any]],
        focus: str = "",
        **kwargs,
    ) -> Dict[str, Any]:
        """ä½¿ç”¨ LLM åˆ†æç´ æå†…å®¹"""
        try:
            if not materials:
                return {"success": False, "error": "æ²¡æœ‰å¯åˆ†æçš„ç´ æ"}

            # æ„å»ºç´ æå†…å®¹
            materials_text = ""
            for m in materials:
                if "content" in m:
                    materials_text += f"\n\n=== {m['filename']} ===\n"
                    materials_text += m["content"][:2500]
                    if len(m["content"]) > 2500:
                        materials_text += "\n[...å†…å®¹å·²æˆªæ–­...]"

            focus_instruction = f"\nç‰¹åˆ«å…³æ³¨: {focus}" if focus else ""

            prompt = f"""è¯·æ·±å…¥åˆ†æä»¥ä¸‹ç ”ç©¶ç´ æï¼Œæå–å…³é”®ä¿¡æ¯ã€‚{focus_instruction}

ç´ æå†…å®¹:
{materials_text}

è¯·ä»¥ JSON æ ¼å¼è¿”å›åˆ†æç»“æœï¼ŒåŒ…å«ä»¥ä¸‹å­—æ®µ:
{{
    "main_themes": ["ä¸»é¢˜1", "ä¸»é¢˜2", ...],
    "key_arguments": [
        {{"argument": "è®ºç‚¹å†…å®¹", "source": "æ¥æºæ–‡ä»¶", "evidence": "æ”¯æ’‘è¯æ®"}}
    ],
    "key_data": [
        {{"data": "æ•°æ®å†…å®¹", "context": "ä¸Šä¸‹æ–‡", "source": "æ¥æº"}}
    ],
    "knowledge_gaps": ["çŸ¥è¯†ç¼ºå£1", ...],
    "cross_references": ["æ–‡ä»¶é—´çš„å…³è”1", ...],
    "overall_insight": "æ•´ä½“æ´å¯Ÿï¼ˆ200å­—ä»¥å†…ï¼‰"
}}"""

            response = await self.llm_client.chat(
                [{"role": "user", "content": prompt}],
                temperature=0.4,
                max_tokens=2000,
            )

            # è§£æ JSON
            json_match = re.search(r'\{.*\}', response, re.DOTALL)
            if json_match:
                analysis = json.loads(json_match.group())
                analysis["success"] = True
                # ä¿å­˜å®Œæ•´åˆ†æç»“æœä¾›åç»­å·¥å…·ä½¿ç”¨
                analysis["analysis_result"] = {
                    "main_themes": analysis.get("main_themes", []),
                    "key_arguments": analysis.get("key_arguments", []),
                    "key_data": analysis.get("key_data", []),
                    "knowledge_gaps": analysis.get("knowledge_gaps", []),
                    "overall_insight": analysis.get("overall_insight", ""),
                }
                return analysis
            else:
                fallback = {
                    "success": True,
                    "raw_analysis": response,
                    "main_themes": [],
                    "overall_insight": response[:500],
                }
                fallback["analysis_result"] = fallback.copy()
                return fallback

        except json.JSONDecodeError:
            return {"success": True, "raw_analysis": response, "parse_error": "JSONè§£æå¤±è´¥"}
        except Exception as e:
            return {"success": False, "error": str(e)}


class ReflectTool(BaseTool):
    """
    åæ€å·¥å…·

    ä½¿ç”¨ LLM å¯¹åˆ†æç»“æœè¿›è¡Œæ‰¹åˆ¤æ€§åæ€ï¼Œå‘ç°é—®é¢˜å’Œæ”¹è¿›æ–¹å‘
    """

    def __init__(self, llm_client: OpenAIClient):
        self.llm_client = llm_client

    @property
    def definition(self) -> ToolDefinition:
        return ToolDefinition(
            name="reflect",
            description="å¯¹åˆ†æç»“æœè¿›è¡Œæ‰¹åˆ¤æ€§åæ€ï¼Œä½¿ç”¨ LLM å‘ç°é€»è¾‘é—®é¢˜ã€æ½œåœ¨åè§å’Œç¼ºå¤±è§†è§’ã€‚è¿™æ˜¯ç¡®ä¿ç ”ç©¶è´¨é‡çš„å…³é”®æ­¥éª¤ã€‚",
            parameters=[
                ToolParameter(
                    name="analysis",
                    type="object",
                    description="åˆ†æç»“æœï¼ˆä» analyze_content è·å–ï¼‰",
                    required=True,
                ),
                ToolParameter(
                    name="depth",
                    type="string",
                    description="åæ€æ·±åº¦: shallow(æµ…å±‚), medium(ä¸­ç­‰), deep(æ·±å…¥)",
                    required=False,
                ),
            ],
            category="reasoning",
            output_schema={
                "reflection_result": {"type": "object", "description": "å®Œæ•´åæ€ç»“æœ"},
                "reflection_summary": {"type": "string", "description": "åæ€æ€»ç»“"},
                "logical_issues": {"type": "array", "description": "é€»è¾‘é—®é¢˜"},
                "confidence_assessment": {"type": "object", "description": "å¯ä¿¡åº¦è¯„ä¼°"},
            },
            # å‚æ•°åˆ«åï¼šä» state["analysis_result"] è·å– analysis å‚æ•°
            param_aliases={
                "analysis": "analysis_result",
            },
        )

    async def execute(
        self,
        analysis: Dict[str, Any],
        depth: str = "medium",
        **kwargs,
    ) -> Dict[str, Any]:
        """ä½¿ç”¨ LLM è¿›è¡Œæ‰¹åˆ¤æ€§åæ€"""
        try:
            depth_instructions = {
                "shallow": "è¿›è¡Œå¿«é€Ÿçš„é€»è¾‘æ£€æŸ¥å’Œè¡¨é¢é—®é¢˜å‘ç°",
                "medium": "è¿›è¡Œä¸­ç­‰æ·±åº¦çš„æ‰¹åˆ¤æ€§åˆ†æï¼Œæ£€æŸ¥è®ºè¯é€»è¾‘å’Œæ½œåœ¨åè§",
                "deep": "è¿›è¡Œæ·±å…¥çš„æ‰¹åˆ¤æ€§åæ€ï¼ŒåŒ…æ‹¬å“²å­¦å±‚é¢çš„è´¨ç–‘å’Œå¤šè§’åº¦å®¡è§†",
            }

            depth_instruction = depth_instructions.get(
                depth, depth_instructions["medium"])
            analysis_text = json.dumps(analysis, ensure_ascii=False, indent=2)

            prompt = f"""è¯·å¯¹ä»¥ä¸‹ç ”ç©¶åˆ†æç»“æœè¿›è¡Œæ‰¹åˆ¤æ€§åæ€ã€‚

åæ€æ·±åº¦è¦æ±‚: {depth_instruction}

åˆ†æç»“æœ:
{analysis_text[:4000]}

è¯·ä»ä»¥ä¸‹è§’åº¦è¿›è¡Œåæ€ï¼Œå¹¶ä»¥ JSON æ ¼å¼è¿”å›:
{{
    "logical_issues": [
        {{"issue": "é—®é¢˜æè¿°", "location": "å‡ºç°ä½ç½®", "suggestion": "æ”¹è¿›å»ºè®®"}}
    ],
    "potential_biases": [
        {{"bias": "åè§æè¿°", "impact": "å¯èƒ½å½±å“", "mitigation": "ç¼“è§£æ–¹æ³•"}}
    ],
    "missing_perspectives": [
        {{"perspective": "è§†è§’æè¿°", "importance": "é‡è¦æ€§è¯´æ˜"}}
    ],
    "strengthening_suggestions": [
        {{"current": "å½“å‰çŠ¶æ€", "suggestion": "æ”¹è¿›å»ºè®®"}}
    ],
    "confidence_assessment": {{
        "overall_score": 0.0-1.0,
        "reasoning": "è¯„ä¼°ç†ç”±"
    }},
    "reflection_summary": "åæ€æ€»ç»“ï¼ˆ200å­—ä»¥å†…ï¼‰"
}}"""

            response = await self.llm_client.chat(
                [{"role": "user", "content": prompt}],
                temperature=0.5,
                max_tokens=2500,
            )

            json_match = re.search(r'\{.*\}', response, re.DOTALL)
            if json_match:
                reflection = json.loads(json_match.group())
                reflection["success"] = True
                # ä¿å­˜å®Œæ•´åæ€ç»“æœä¾›åç»­å·¥å…·ä½¿ç”¨
                reflection["reflection_result"] = {
                    "logical_issues": reflection.get("logical_issues", []),
                    "potential_biases": reflection.get("potential_biases", []),
                    "missing_perspectives": reflection.get("missing_perspectives", []),
                    "confidence_assessment": reflection.get("confidence_assessment", {}),
                    "reflection_summary": reflection.get("reflection_summary", ""),
                }
                return reflection
            else:
                fallback = {"success": True, "raw_reflection": response}
                fallback["reflection_result"] = fallback.copy()
                return fallback

        except json.JSONDecodeError:
            fallback = {"success": True, "raw_reflection": response}
            fallback["reflection_result"] = fallback.copy()
            return fallback
        except Exception as e:
            return {"success": False, "error": str(e)}


class PolishTextTool(BaseTool):
    """
    è¯­è¨€æ¶¦è‰²å·¥å…·

    ä½¿ç”¨ LLM å¯¹æ–‡æœ¬è¿›è¡Œè¯­è¨€æ¶¦è‰²ï¼Œæå‡è¡¨è¾¾è´¨é‡
    """

    def __init__(self, llm_client: OpenAIClient):
        self.llm_client = llm_client

    @property
    def definition(self) -> ToolDefinition:
        return ToolDefinition(
            name="polish_text",
            description="å¯¹æ–‡æœ¬è¿›è¡Œè¯­è¨€æ¶¦è‰²ï¼Œä½¿ç”¨ LLM æå‡è¡¨è¾¾çš„ä¸“ä¸šæ€§ã€æ¸…æ™°åº¦å’Œå¯è¯»æ€§ã€‚é€šå¸¸ç”¨äºæ¶¦è‰²æœ€ç»ˆæŠ¥å‘Šã€‚",
            parameters=[
                ToolParameter(
                    name="text",
                    type="string",
                    description="å¾…æ¶¦è‰²çš„æ–‡æœ¬",
                    required=True,
                ),
                ToolParameter(
                    name="style",
                    type="string",
                    description="ç›®æ ‡é£æ ¼: academic(å­¦æœ¯), professional(ä¸“ä¸š), casual(é€šä¿—)",
                    required=False,
                ),
            ],
            category="writing",
            output_schema={
                "polished_text": {"type": "string", "description": "æ¶¦è‰²åçš„æ–‡æœ¬"},
            },
        )

    async def execute(
        self,
        text: str,
        style: str = "professional",
        **kwargs,
    ) -> Dict[str, Any]:
        """ä½¿ç”¨ LLM è¿›è¡Œè¯­è¨€æ¶¦è‰²"""
        try:
            if not text:
                return {"success": False, "error": "æ²¡æœ‰å¾…æ¶¦è‰²çš„æ–‡æœ¬"}

            style_instructions = {
                "academic": "ä½¿ç”¨å­¦æœ¯è®ºæ–‡çš„ä¸¥è°¨é£æ ¼ï¼Œå‡†ç¡®ä½¿ç”¨ä¸“ä¸šæœ¯è¯­",
                "professional": "ä½¿ç”¨ä¸“ä¸šæŠ¥å‘Šçš„é£æ ¼ï¼Œæ¸…æ™°å‡†ç¡®ï¼Œå…¼é¡¾å¯è¯»æ€§",
                "casual": "ä½¿ç”¨é€šä¿—æ˜“æ‡‚çš„é£æ ¼ï¼Œé¿å…è¿‡å¤šæœ¯è¯­",
            }

            style_instruction = style_instructions.get(
                style, style_instructions["professional"])

            prompt = f"""è¯·å¯¹ä»¥ä¸‹æ–‡æœ¬è¿›è¡Œè¯­è¨€æ¶¦è‰²ã€‚

é£æ ¼è¦æ±‚: {style_instruction}

åŸæ–‡:
{text}

è¯·ç›´æ¥è¾“å‡ºæ¶¦è‰²åçš„å®Œæ•´æ–‡æœ¬ï¼Œä¿æŒåŸæœ‰ç»“æ„ï¼Œæå‡è¡¨è¾¾è´¨é‡ã€‚"""

            response = await self.llm_client.chat(
                [{"role": "user", "content": prompt}],
                temperature=0.6,
                max_tokens=4000,
            )

            return {
                "success": True,
                "polished_text": response.strip(),
                "original_length": len(text),
                "polished_length": len(response),
            }

        except Exception as e:
            return {"success": False, "error": str(e)}


class GenerateReportTool(BaseTool):
    """
    æŠ¥å‘Šç”Ÿæˆå·¥å…·

    ä½¿ç”¨ LLM åŸºäºåˆ†æå’Œåæ€ç»“æœç”Ÿæˆç ”ç©¶æŠ¥å‘Š
    """

    def __init__(self, llm_client: OpenAIClient):
        self.llm_client = llm_client

    @property
    def definition(self) -> ToolDefinition:
        return ToolDefinition(
            name="generate_report",
            description="åŸºäºåˆ†æç»“æœå’Œåæ€æ„è§ï¼Œä½¿ç”¨ LLM ç”Ÿæˆç»“æ„åŒ–çš„ç ”ç©¶æŠ¥å‘Šã€‚è¿™æ˜¯ç ”ç©¶æµç¨‹çš„æœ€ç»ˆè¾“å‡ºæ­¥éª¤ã€‚",
            parameters=[
                ToolParameter(
                    name="analysis",
                    type="object",
                    description="å†…å®¹åˆ†æç»“æœ",
                    required=True,
                ),
                ToolParameter(
                    name="reflection",
                    type="object",
                    description="åæ€ç»“æœ",
                    required=False,
                ),
                ToolParameter(
                    name="topic",
                    type="string",
                    description="ç ”ç©¶ä¸»é¢˜",
                    required=True,
                ),
                ToolParameter(
                    name="format",
                    type="string",
                    description="æŠ¥å‘Šæ ¼å¼: brief(ç®€æŠ¥), standard(æ ‡å‡†), detailed(è¯¦ç»†)",
                    required=False,
                ),
            ],
            category="document",
            output_schema={
                "report": {"type": "string", "description": "ç”Ÿæˆçš„æŠ¥å‘Š"},
                "word_count": {"type": "integer", "description": "å­—æ•°"},
            },
            # å‚æ•°åˆ«åï¼šä» state è·å–å‚æ•°
            param_aliases={
                "analysis": "analysis_result",
                "reflection": "reflection_result",
            },
        )

    async def execute(
        self,
        analysis: Dict[str, Any],
        topic: str,
        reflection: Dict[str, Any] = None,
        format: str = "standard",
        **kwargs,
    ) -> Dict[str, Any]:
        """ä½¿ç”¨ LLM ç”Ÿæˆç ”ç©¶æŠ¥å‘Š"""
        try:
            format_instructions = {
                "brief": "ç”Ÿæˆç®€æ˜æ‰¼è¦çš„ç ”ç©¶ç®€æŠ¥ï¼ˆ500-800å­—ï¼‰",
                "standard": "ç”Ÿæˆæ ‡å‡†ç ”ç©¶æŠ¥å‘Šï¼ˆ1000-1500å­—ï¼‰",
                "detailed": "ç”Ÿæˆè¯¦ç»†ç ”ç©¶æŠ¥å‘Šï¼ˆ2000å­—ä»¥ä¸Šï¼‰",
            }

            format_instruction = format_instructions.get(
                format, format_instructions["standard"])

            analysis_text = json.dumps(analysis, ensure_ascii=False, indent=2)
            reflection_text = json.dumps(
                reflection, ensure_ascii=False, indent=2) if reflection else "æ— "

            prompt = f"""è¯·åŸºäºä»¥ä¸‹åˆ†æç»“æœå’Œåæ€æ„è§ï¼Œç”Ÿæˆä¸€ä»½ä¸“ä¸šçš„ç ”ç©¶æŠ¥å‘Šã€‚

ç ”ç©¶ä¸»é¢˜: {topic}
æ ¼å¼è¦æ±‚: {format_instruction}

=== å†…å®¹åˆ†æç»“æœ ===
{analysis_text[:3000]}

=== æ‰¹åˆ¤æ€§åæ€ ===
{reflection_text[:2000]}

è¯·ç”Ÿæˆä¸€ä»½ Markdown æ ¼å¼çš„ç ”ç©¶æŠ¥å‘Šï¼ŒåŒ…å«ä»¥ä¸‹éƒ¨åˆ†:
1. æ ‡é¢˜å’Œæ‘˜è¦
2. ç ”ç©¶èƒŒæ™¯ä¸é—®é¢˜
3. æ ¸å¿ƒå‘ç°
4. è®¨è®ºä¸åæ€
5. å±€é™æ€§ä¸æœªæ¥æ–¹å‘
6. ç»“è®º

è¯·ç›´æ¥è¾“å‡º Markdown æ ¼å¼çš„æŠ¥å‘Šå†…å®¹ã€‚"""

            response = await self.llm_client.chat(
                [{"role": "user", "content": prompt}],
                temperature=0.7,
                max_tokens=4000,
            )

            return {
                "success": True,
                "report": response,
                "word_count": len(response),
                "format": format,
                "topic": topic,
            }

        except Exception as e:
            return {"success": False, "error": str(e)}


# ==================== ç¤ºä¾‹ç´ æåˆ›å»º ====================


def create_sample_materials(materials_dir: Path):
    """åˆ›å»ºç¤ºä¾‹ç ”ç©¶ç´ æ"""
    materials_dir.mkdir(parents=True, exist_ok=True)

    sample1 = materials_dir / "ai_medical_applications.md"
    sample1.write_text("""# äººå·¥æ™ºèƒ½åœ¨åŒ»ç–—é¢†åŸŸçš„åº”ç”¨

## æ¦‚è¿°
äººå·¥æ™ºèƒ½ï¼ˆAIï¼‰æ­£åœ¨æ·±åˆ»æ”¹å˜åŒ»ç–—è¡Œä¸šã€‚ä»ç–¾ç—…è¯Šæ–­åˆ°è¯ç‰©ç ”å‘ï¼ŒAIæŠ€æœ¯å±•ç°å‡ºå·¨å¤§æ½œåŠ›ã€‚

## ä¸»è¦åº”ç”¨é¢†åŸŸ

### 1. åŒ»å­¦å½±åƒåˆ†æ
æ·±åº¦å­¦ä¹ åœ¨åŒ»å­¦å½±åƒåˆ†ææ–¹é¢å–å¾—äº†çªç ´æ€§è¿›å±•ã€‚ç ”ç©¶è¡¨æ˜ï¼ŒAIåœ¨æŸäº›å½±åƒè¯Šæ–­ä»»åŠ¡ä¸­çš„å‡†ç¡®ç‡å·²ç»æ¥è¿‘ç”šè‡³è¶…è¿‡ä¸“ä¸šåŒ»ç”Ÿã€‚

### 2. è¯ç‰©ç ”å‘
AIå¯ä»¥åŠ é€Ÿè¯ç‰©å‘ç°è¿‡ç¨‹ï¼Œé€šè¿‡åˆ†æå¤§é‡åŒ–åˆç‰©æ•°æ®é¢„æµ‹æ½œåœ¨çš„è¯ç‰©å€™é€‰åˆ†å­ã€‚è¿™å°†ç ”å‘å‘¨æœŸä»ä¼ ç»Ÿçš„10-15å¹´ç¼©çŸ­åˆ°å‡ å¹´ã€‚

### 3. ä¸ªæ€§åŒ–åŒ»ç–—
åŸºäºæ‚£è€…çš„åŸºå› ä¿¡æ¯ã€ç—…å²å’Œç”Ÿæ´»æ–¹å¼æ•°æ®ï¼ŒAIå¯ä»¥å¸®åŠ©åŒ»ç”Ÿåˆ¶å®šä¸ªæ€§åŒ–çš„æ²»ç–—æ–¹æ¡ˆã€‚

## æŒ‘æˆ˜ä¸é£é™©
- æ•°æ®éšç§å’Œå®‰å…¨é—®é¢˜
- AIå†³ç­–çš„å¯è§£é‡Šæ€§
- åŒ»ç–—è´£ä»»å½’å±é—®é¢˜
- æŠ€æœ¯åº”ç”¨çš„ä¼¦ç†è¾¹ç•Œ

## ç»“è®º
AIåœ¨åŒ»ç–—é¢†åŸŸçš„åº”ç”¨å‰æ™¯å¹¿é˜”ï¼Œä½†éœ€è¦åœ¨æŠ€æœ¯å‘å±•å’Œä¼¦ç†è§„èŒƒä¹‹é—´æ‰¾åˆ°å¹³è¡¡ã€‚
""", encoding="utf-8")

    sample2 = materials_dir / "ai_ethics_challenges.md"
    sample2.write_text("""# AI åŒ»ç–—è¯Šæ–­çš„ä¼¦ç†æŒ‘æˆ˜

## å¼•è¨€
éšç€äººå·¥æ™ºèƒ½åœ¨åŒ»ç–—è¯Šæ–­ä¸­çš„åº”ç”¨æ—¥ç›Šæ™®åŠï¼Œç›¸å…³çš„ä¼¦ç†é—®é¢˜ä¹Ÿå˜å¾—æ›´åŠ çªå‡ºã€‚

## æ ¸å¿ƒä¼¦ç†é—®é¢˜

### 1. ç®—æ³•åè§
å¦‚æœè®­ç»ƒæ•°æ®å­˜åœ¨åè§ï¼ŒAIç³»ç»Ÿå¯èƒ½å¯¹æŸäº›ç¾¤ä½“äº§ç”Ÿä¸å…¬å¹³çš„è¯Šæ–­ç»“æœã€‚

### 2. é€æ˜åº¦é—®é¢˜
è®¸å¤šAIæ¨¡å‹æ˜¯"é»‘ç®±"ç³»ç»Ÿï¼ŒåŒ»ç”Ÿå’Œæ‚£è€…éš¾ä»¥ç†è§£å…¶å†³ç­–è¿‡ç¨‹ã€‚

### 3. è´£ä»»åˆ’åˆ†
å½“AIå‚ä¸è¯Šæ–­å‡ºç°é”™è¯¯æ—¶ï¼Œè´£ä»»åº”è¯¥ç”±è°æ‰¿æ‹…ï¼Ÿæ˜¯AIå¼€å‘è€…ã€åŒ»é™¢è¿˜æ˜¯ä½¿ç”¨AIçš„åŒ»ç”Ÿï¼Ÿ

## å»ºè®®çš„è§£å†³æ–¹æ¡ˆ
1. å»ºç«‹AIåŒ»ç–—åº”ç”¨çš„ä¼¦ç†å®¡æŸ¥æœºåˆ¶
2. æ¨åŠ¨å¯è§£é‡ŠAIæŠ€æœ¯çš„å‘å±•
3. åˆ¶å®šæ˜ç¡®çš„è´£ä»»æ¡†æ¶å’Œä¿é™©æœºåˆ¶
4. åŠ å¼ºæ‚£è€…çŸ¥æƒ…åŒæ„ç¨‹åº

## æ€»ç»“
æŠ€æœ¯è¿›æ­¥ä¸èƒ½ä»¥ç‰ºç‰²ä¼¦ç†ä¸ºä»£ä»·ï¼ŒAIåŒ»ç–—åº”ç”¨éœ€è¦åœ¨åˆ›æ–°ä¸ä¼¦ç†ä¹‹é—´å¯»æ‰¾å¹³è¡¡ç‚¹ã€‚
""", encoding="utf-8")

    sample3 = materials_dir / "market_data.txt"
    sample3.write_text("""AIåŒ»ç–—å¸‚åœºæ•°æ®æŠ¥å‘Šï¼ˆ2024ï¼‰

å¸‚åœºè§„æ¨¡ä¸å¢é•¿:
- 2024å¹´å…¨çƒAIåŒ»ç–—å¸‚åœºè§„æ¨¡: çº¦150äº¿ç¾å…ƒ
- é¢„è®¡2030å¹´å¸‚åœºè§„æ¨¡: 450äº¿ç¾å…ƒ
- å¹´å‡å¤åˆå¢é•¿ç‡(CAGR): çº¦20%

åº”ç”¨é¢†åŸŸåˆ†å¸ƒ:
1. åŒ»å­¦å½±åƒ: 35%
2. è¯ç‰©å‘ç°: 25%
3. ä¸´åºŠå†³ç­–æ”¯æŒ: 20%
4. æ‚£è€…ç®¡ç†: 15%
5. å…¶ä»–: 5%

ä¸»è¦å‚ä¸è€…:
- ç§‘æŠ€å·¨å¤´: Google Health, IBM Watson Health, Microsoft Healthcare
- ä¸“ä¸šåŒ»ç–—AIå…¬å¸: Tempus, PathAI, Butterfly Network
- ä¼ ç»ŸåŒ»ç–—è®¾å¤‡å…¬å¸: GE Healthcare, Siemens Healthineers

æŠ•èµ„è¶‹åŠ¿:
- 2023å¹´AIåŒ»ç–—é¢†åŸŸæŠ•èµ„æ€»é¢: 85äº¿ç¾å…ƒ
- åŒæ¯”å¢é•¿: 15%
- ä¸»è¦æŠ•èµ„æ–¹å‘: è¯Šæ–­AI, è¯ç‰©ç ”å‘, æ‰‹æœ¯æœºå™¨äºº

åœ°åŒºåˆ†å¸ƒ:
- åŒ—ç¾: 45%
- æ¬§æ´²: 25%
- äºšå¤ª: 25%
- å…¶ä»–: 5%
""", encoding="utf-8")

    print(f"âœ… å·²åˆ›å»ºç¤ºä¾‹ç´ æåˆ° {materials_dir}")


# ==================== ç»“æœå¯¼å‡º ====================


async def export_results(
    report: str,
    execution_log: list,
    plan: "ExecutionPlan",
    results: list,
    state: dict,
    output_dir: Path,
    topic: str,
) -> None:
    """
    å¯¼å‡ºç ”ç©¶ç»“æœåˆ° Markdown å’Œ HTML æ–‡ä»¶

    ä½¿ç”¨é¡¹ç›®å†…ç½®çš„ ExecutionReportGenerator
    """
    from datetime import datetime
    from auto_agent import ExecutionReportGenerator

    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir.mkdir(parents=True, exist_ok=True)

    # ç”Ÿæˆæ—¶é—´æˆ³
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

    # 1. ä½¿ç”¨ ExecutionReportGenerator ç”ŸæˆæŠ¥å‘Šæ•°æ®
    report_data = ExecutionReportGenerator.generate_report_data(
        agent_name="Deep Research Agent",
        query=topic,
        plan=plan,
        results=results,
        state=state,
    )

    # 2. å¯¼å‡º Markdown æŠ¥å‘Šï¼ˆåŒ…å«æ‰§è¡Œè¿‡ç¨‹ + æœ€ç»ˆç ”ç©¶æŠ¥å‘Šï¼‰
    md_filename = output_dir / f"research_report_{timestamp}.md"

    # ç”Ÿæˆæ‰§è¡Œè¿‡ç¨‹æŠ¥å‘Š
    execution_report = ExecutionReportGenerator.generate_markdown_report(
        report_data)

    # ç»„åˆå®Œæ•´æŠ¥å‘Š
    md_content = f"""# ç ”ç©¶æŠ¥å‘Š: {topic}

> ç”Ÿæˆæ—¶é—´: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}

---

{report}

---

# æ‰§è¡Œè¿‡ç¨‹æŠ¥å‘Š

{execution_report}
"""

    md_filename.write_text(md_content, encoding="utf-8")
    print(f"\nğŸ“„ Markdown æŠ¥å‘Šå·²ä¿å­˜: {md_filename}")

    # 3. å¯¼å‡º HTML æŠ¥å‘Š
    html_filename = output_dir / f"research_report_{timestamp}.html"

    html_content = generate_html_report(
        topic=topic,
        research_report=report,
        report_data=report_data,
    )

    html_filename.write_text(html_content, encoding="utf-8")
    print(f"ğŸŒ HTML æŠ¥å‘Šå·²ä¿å­˜: {html_filename}")

    # 4. æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
    stats = report_data.get("statistics", {})
    print(f"\nğŸ“Š æ‰§è¡Œç»Ÿè®¡:")
    print(f"   - æ€»æ­¥éª¤: {stats.get('total_steps', 0)}")
    print(f"   - æˆåŠŸ: {stats.get('successful_steps', 0)}")
    print(f"   - å¤±è´¥: {stats.get('failed_steps', 0)}")
    print(f"   - æˆåŠŸç‡: {stats.get('success_rate', 0)}%")

    # 5. æ˜¾ç¤º Mermaid æµç¨‹å›¾
    print(f"\nğŸ“ˆ æ‰§è¡Œæµç¨‹å›¾:")
    print(report_data.get("mermaid_diagram", ""))


def generate_html_report(topic: str, research_report: str, report_data: dict) -> str:
    """ç”Ÿæˆ HTML æ ¼å¼æŠ¥å‘Š"""
    from datetime import datetime
    import re

    # ç®€å•çš„ Markdown è½¬ HTML
    def md_to_html(md_text: str) -> str:
        html = md_text
        # æ ‡é¢˜
        html = re.sub(r'^### (.+)$', r'<h3>\1</h3>', html, flags=re.MULTILINE)
        html = re.sub(r'^## (.+)$', r'<h2>\1</h2>', html, flags=re.MULTILINE)
        html = re.sub(r'^# (.+)$', r'<h1>\1</h1>', html, flags=re.MULTILINE)
        # åŠ ç²—
        html = re.sub(r'\*\*(.+?)\*\*', r'<strong>\1</strong>', html)
        # åˆ—è¡¨é¡¹
        html = re.sub(r'^- (.+)$', r'<li>\1</li>', html, flags=re.MULTILINE)
        # æ®µè½
        lines = html.split('\n')
        result = []
        for line in lines:
            line = line.strip()
            if line and not line.startswith('<'):
                result.append(f'<p>{line}</p>')
            else:
                result.append(line)
        return '\n'.join(result)

    html_report = md_to_html(research_report)
    stats = report_data.get("statistics", {})
    steps = report_data.get("steps", [])

    # ç”Ÿæˆæ­¥éª¤è¯¦æƒ… HTML
    steps_html = ""
    for step in steps:
        status_class = "success" if step['status'] == 'success' else "error" if step['status'] == 'failed' else "pending"
        status_icon = "âœ…" if step['status'] == 'success' else "âŒ" if step['status'] == 'failed' else "â³"
        error_html = f'<p class="error"><strong>é”™è¯¯:</strong> {step["error"]}</p>' if step.get(
            'error') else ''

        steps_html += f"""
        <div class="step {status_class}">
            <h4>{status_icon} Step {step['step']}: {step['name']}</h4>
            <p><strong>æè¿°:</strong> {step['description']}</p>
            {f"<p><strong>æœŸæœ›:</strong> {step['expectations']}</p>" if step.get('expectations') else ''}
            {error_html}
        </div>
        """

    return f"""<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ç ”ç©¶æŠ¥å‘Š: {topic}</title>
    <style>
        * {{ box-sizing: border-box; }}
        body {{
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            line-height: 1.8;
            max-width: 1000px;
            margin: 0 auto;
            padding: 40px 20px;
            background: #f5f7fa;
            color: #333;
        }}
        .container {{ background: white; padding: 40px; border-radius: 12px; box-shadow: 0 4px 20px rgba(0,0,0,0.08); }}
        h1 {{ color: #1a202c; border-bottom: 3px solid #4299e1; padding-bottom: 15px; }}
        h2 {{ color: #2d3748; margin-top: 40px; border-left: 4px solid #4299e1; padding-left: 15px; }}
        h3 {{ color: #4a5568; }}
        .meta {{ background: #edf2f7; padding: 20px; border-radius: 8px; margin-bottom: 30px; }}
        .stats {{ display: grid; grid-template-columns: repeat(4, 1fr); gap: 15px; margin: 20px 0; }}
        .stat {{ background: #f7fafc; padding: 20px; border-radius: 8px; text-align: center; }}
        .stat-value {{ font-size: 2em; font-weight: bold; color: #4299e1; }}
        .stat-label {{ color: #718096; font-size: 0.9em; }}
        .step {{ padding: 20px; margin: 15px 0; border-radius: 8px; border-left: 4px solid #e2e8f0; background: #f7fafc; }}
        .step.success {{ border-left-color: #48bb78; background: #f0fff4; }}
        .step.error {{ border-left-color: #fc8181; background: #fff5f5; }}
        .step.pending {{ border-left-color: #ecc94b; background: #fffff0; }}
        .step h4 {{ margin: 0 0 10px 0; color: #2d3748; }}
        .error {{ color: #c53030; }}
        .success {{ color: #276749; }}
        blockquote {{ border-left: 4px solid #cbd5e0; margin: 20px 0; padding: 15px 20px; background: #f7fafc; }}
        ul, ol {{ padding-left: 25px; }}
        li {{ margin: 8px 0; }}
        hr {{ border: none; border-top: 1px solid #e2e8f0; margin: 30px 0; }}
        .report-content {{ background: #fafafa; padding: 30px; border-radius: 8px; margin: 20px 0; }}
    </style>
</head>
<body>
    <div class="container">
        <h1>ğŸ”¬ ç ”ç©¶æŠ¥å‘Š: {topic}</h1>
        
        <div class="meta">
            <strong>ç”Ÿæˆæ—¶é—´:</strong> {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}<br>
            <strong>æ™ºèƒ½ä½“:</strong> {report_data.get('agent_name', 'Deep Research Agent')}<br>
            <strong>æ„å›¾:</strong> {report_data.get('intent', 'N/A')}
        </div>
        
        <h2>ğŸ“Š æ‰§è¡Œç»Ÿè®¡</h2>
        <div class="stats">
            <div class="stat">
                <div class="stat-value">{stats.get('total_steps', 0)}</div>
                <div class="stat-label">æ€»æ­¥éª¤</div>
            </div>
            <div class="stat">
                <div class="stat-value" style="color: #48bb78;">{stats.get('successful_steps', 0)}</div>
                <div class="stat-label">æˆåŠŸ</div>
            </div>
            <div class="stat">
                <div class="stat-value" style="color: #fc8181;">{stats.get('failed_steps', 0)}</div>
                <div class="stat-label">å¤±è´¥</div>
            </div>
            <div class="stat">
                <div class="stat-value">{stats.get('success_rate', 0)}%</div>
                <div class="stat-label">æˆåŠŸç‡</div>
            </div>
        </div>
        
        <h2>ğŸ“– ç ”ç©¶å†…å®¹</h2>
        <div class="report-content">
            {html_report}
        </div>
        
        <h2>ğŸ”§ æ‰§è¡Œæ­¥éª¤è¯¦æƒ…</h2>
        {steps_html}
        
    </div>
</body>
</html>
"""


# ==================== ä¸»ç¨‹åº ====================


async def main():
    """ä¸»å‡½æ•° - ä½¿ç”¨è‡ªä¸»è§„åˆ’æ‰§è¡Œæ·±åº¦ç ”ç©¶"""
    print("=" * 70)
    print("ğŸ”¬ Deep Research Agent - è‡ªä¸»è§„åˆ’ç‰ˆæœ¬")
    print("=" * 70)

    # 1. è·å– LLM å®¢æˆ·ç«¯
    llm_client = get_llm_client()
    if not llm_client:
        print("\nâŒ æœªè®¾ç½® API Keyï¼Œè¯·è®¾ç½®ç¯å¢ƒå˜é‡:")
        print("   export OPENAI_API_KEY=your-api-key")
        print("   # æˆ–")
        print("   export DEEPSEEK_API_KEY=your-api-key")
        return

    print("\nâœ… LLM å®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")

    # 2. å‡†å¤‡ç´ æç›®å½•
    script_dir = Path(__file__).parent
    materials_dir = script_dir / "research_materials"

    if not materials_dir.exists() or not any(materials_dir.iterdir()):
        print(f"\nğŸ“ ç´ æç›®å½•ä¸ºç©ºï¼Œåˆ›å»ºç¤ºä¾‹ç´ æ...")
        create_sample_materials(materials_dir)
    else:
        print(f"\nğŸ“ ç´ æç›®å½•: {materials_dir}")

    # 3. æ³¨å†Œå·¥å…·åˆ° ToolRegistry
    print("\nğŸ”§ æ³¨å†Œç ”ç©¶å·¥å…·...")
    registry = ToolRegistry()

    registry.register(ReadMaterialsTool(llm_client, str(materials_dir)))
    registry.register(AnalyzeContentTool(llm_client))
    registry.register(ReflectTool(llm_client))
    registry.register(PolishTextTool(llm_client))
    registry.register(GenerateReportTool(llm_client))

    print(f"   å·²æ³¨å†Œ {len(registry.get_all_tools())} ä¸ªå·¥å…·:")
    for tool in registry.get_all_tools():
        print(
            f"   - {tool.definition.name}: {tool.definition.description[:50]}...")

    # 4. åˆ›å»ºæ™ºèƒ½ä½“ï¼ˆå¸¦ç›®æ ‡å’Œçº¦æŸï¼‰
    print("\nğŸ¤– åˆ›å»ºæ™ºèƒ½ä½“...")
    agent = AutoAgent(
        llm_client=llm_client,
        tool_registry=registry,
        agent_name="Deep Research Agent",
        agent_description="ä¸€ä¸ªèƒ½å¤Ÿè‡ªä¸»è§„åˆ’å’Œæ‰§è¡Œæ·±åº¦ç ”ç©¶ä»»åŠ¡çš„æ™ºèƒ½ä½“",
        agent_goals=[
            "é˜…è¯»å¹¶ç†è§£ç ”ç©¶ç´ æ",
            "è¿›è¡Œæ·±åº¦åˆ†æï¼Œæå–å…³é”®ä¿¡æ¯",
            "æ‰¹åˆ¤æ€§åæ€åˆ†æç»“æœ",
            "ç”Ÿæˆé«˜è´¨é‡çš„ç ”ç©¶æŠ¥å‘Š",
        ],
        agent_constraints=[
            "æ‰€æœ‰åˆ†æå¿…é¡»åŸºäºæä¾›çš„ç´ æ",
            "å¿…é¡»è¿›è¡Œæ‰¹åˆ¤æ€§åæ€",
            "æŠ¥å‘Šå¿…é¡»ç»è¿‡è¯­è¨€æ¶¦è‰²",
        ],
    )

    # 5. ç”¨æˆ·è‡ªç„¶è¯­è¨€æè¿°éœ€æ±‚
    user_query = """
    è¯·å¸®æˆ‘åšä¸€ä¸ªå…³äº"äººå·¥æ™ºèƒ½åœ¨åŒ»ç–—é¢†åŸŸçš„åº”ç”¨ä¸ä¼¦ç†æŒ‘æˆ˜"çš„æ·±åº¦ç ”ç©¶ã€‚

    å…·ä½“è¦æ±‚ï¼š
    1. é¦–å…ˆè¯»å–ç ”ç©¶ç´ æ
    2. åˆ†æç´ æå†…å®¹ï¼Œæå–å…³é”®ä¿¡æ¯å’Œè®ºç‚¹
    3. å¯¹åˆ†æç»“æœè¿›è¡Œæ‰¹åˆ¤æ€§åæ€ï¼Œå‘ç°å¯èƒ½çš„é—®é¢˜
    4. ç”Ÿæˆä¸€ä»½ç ”ç©¶æŠ¥å‘Š
    5. æœ€åå¯¹æŠ¥å‘Šè¿›è¡Œè¯­è¨€æ¶¦è‰²
    
    è¯·è‡ªè¡Œè§„åˆ’æ‰§è¡Œæ­¥éª¤ï¼Œæœ€ç»ˆç»™æˆ‘ä¸€ä»½é«˜è´¨é‡çš„ç ”ç©¶æŠ¥å‘Šã€‚
    """

    print("\n" + "=" * 70)
    print("ğŸ“‹ ç”¨æˆ·éœ€æ±‚:")
    print("=" * 70)
    print(user_query.strip())
    print("\n" + "=" * 70)
    print("ğŸš€ æ™ºèƒ½ä½“å¼€å§‹è‡ªä¸»è§„åˆ’å’Œæ‰§è¡Œ...")
    print("=" * 70)

    # ç”¨äºæ”¶é›†æ‰§è¡Œè¿‡ç¨‹å’Œæœ€ç»ˆç»“æœ
    execution_log = []  # æ‰§è¡Œæ—¥å¿—
    final_report = ""   # æœ€ç»ˆæŠ¥å‘Š
    execution_success = False
    collected_plan = None  # æ‰§è¡Œè®¡åˆ’
    collected_results = []  # æ‰§è¡Œç»“æœ
    collected_state = {}  # æœ€ç»ˆçŠ¶æ€

    # 6. æµå¼æ‰§è¡Œï¼ˆè§‚å¯Ÿè§„åˆ’å’Œæ‰§è¡Œè¿‡ç¨‹ï¼‰
    try:
        async for event in agent.run_stream(
            query=user_query,
            user_id="researcher",
        ):
            event_type = event.get("event")
            data = event.get("data", {})

            if event_type == "planning":
                print(f"\nğŸ“ {data.get('message', 'è§„åˆ’ä¸­...')}")
                execution_log.append(
                    {"event": "planning", "message": data.get('message', '')})

            elif event_type == "execution_plan":
                print("\n" + "-" * 50)
                print("ğŸ“‹ LLM è§„åˆ’çš„æ‰§è¡Œæ­¥éª¤:")
                print("-" * 50)
                steps_info = []
                for step in data.get("steps", []):
                    pinned = "ğŸ“Œ" if step.get("is_pinned") else "  "
                    print(
                        f"   {pinned} Step {step['step']}: [{step['name']}] {step['description']}")
                    steps_info.append(step)
                print("-" * 50)
                execution_log.append(
                    {"event": "execution_plan", "steps": steps_info})

                # ä¿å­˜è§„åˆ’ä¿¡æ¯ç”¨äºç”ŸæˆæŠ¥å‘Š
                from auto_agent import ExecutionPlan, PlanStep
                collected_plan = ExecutionPlan(
                    intent=data.get("description", "æ·±åº¦ç ”ç©¶"),
                    subtasks=[
                        PlanStep(
                            id=str(s.get("step", i+1)),
                            tool=s.get("name"),
                            description=s.get("description", ""),
                            expectations=s.get("expectations"),
                        )
                        for i, s in enumerate(steps_info)
                    ]
                )

            elif event_type == "stage_start":
                step = data.get("step", "?")
                name = data.get("name", "unknown")
                desc = data.get("description", "")
                print(f"\nâ–¶ï¸  Step {step}: {name}")
                print(f"   ğŸ“ æè¿°: {desc}")

            elif event_type == "stage_complete":
                step = data.get("step", "?")
                name = data.get("name", "unknown")
                success = data.get("success", False)
                result = data.get("result", {}) or {}
                error = data.get("error")  # è·å–é”™è¯¯ä¿¡æ¯
                status = "âœ… æˆåŠŸ" if success else "âŒ å¤±è´¥"

                print(f"\n   {status}")
                print(f"   " + "-" * 40)

                # æ˜¾ç¤ºé”™è¯¯åŸå› ï¼ˆå¦‚æœå¤±è´¥ï¼‰
                if not success:
                    # å°è¯•ä»å¤šä¸ªåœ°æ–¹è·å–é”™è¯¯ä¿¡æ¯
                    error_msg = error
                    if not error_msg and isinstance(result, dict):
                        error_msg = result.get("error")
                    if not error_msg:
                        error_msg = str(result) if result else "æœªçŸ¥é”™è¯¯ - æ— è¿”å›ç»“æœ"
                    print(f"   â— å¤±è´¥åŸå› : {error_msg}")
                    print(f"   " + "-" * 40)
                    continue

                # è¯¦ç»†å±•ç¤ºè¾“å‡º
                if isinstance(result, dict):
                    print(f"   ğŸ“¤ è¾“å‡º:")

                    # æ ¹æ®ä¸åŒå·¥å…·æ˜¾ç¤ºä¸åŒçš„è¾“å‡ºå†…å®¹
                    if "total_files" in result:
                        print(f"      - æ–‡ä»¶æ•°é‡: {result['total_files']}")
                        print(
                            f"      - æ€»å­—æ•°: {result.get('total_words', 'N/A')}")
                        materials = result.get('materials', [])
                        for m in materials[:5]:
                            print(
                                f"      - ğŸ“„ {m.get('filename', 'unknown')}: {m.get('summary', 'N/A')[:80]}...")

                    if "main_themes" in result:
                        themes = result.get("main_themes", [])
                        print(f"      - ä¸»é¢˜: {themes}")
                        args = result.get("key_arguments", [])
                        if args:
                            print(f"      - æ ¸å¿ƒè®ºç‚¹æ•°: {len(args)}")
                            for arg in args[:3]:
                                if isinstance(arg, dict):
                                    print(
                                        f"        â€¢ {arg.get('argument', 'N/A')[:60]}...")
                        insight = result.get("overall_insight", "")
                        if insight:
                            print(f"      - æ•´ä½“æ´å¯Ÿ: {insight[:150]}...")

                    if "reflection_summary" in result:
                        summary = result.get("reflection_summary", "")
                        print(f"      - åæ€æ€»ç»“: {summary[:200]}...")
                        issues = result.get("logical_issues", [])
                        if issues:
                            print(f"      - å‘ç°é—®é¢˜æ•°: {len(issues)}")
                        conf = result.get("confidence_assessment", {})
                        if conf:
                            print(
                                f"      - å¯ä¿¡åº¦è¯„åˆ†: {conf.get('overall_score', 'N/A')}")

                    if "report" in result:
                        report = result.get("report", "")
                        print(
                            f"      - æŠ¥å‘Šå­—æ•°: {result.get('word_count', len(report))}")
                        print(f"      - æŠ¥å‘Šé¢„è§ˆ: {report[:200]}...")
                        # ä¿å­˜æŠ¥å‘Šå†…å®¹
                        if success and report:
                            final_report = report

                    if "polished_text" in result:
                        polished = result.get("polished_text", "")
                        print(
                            f"      - æ¶¦è‰²åå­—æ•°: {result.get('polished_length', len(polished))}")
                        print(f"      - æ¶¦è‰²é¢„è§ˆ: {polished[:200]}...")
                        # æ›´æ–°ä¸ºæ¶¦è‰²åçš„æŠ¥å‘Š
                        if success and polished:
                            final_report = polished

                print(f"   " + "-" * 40)

                # è®°å½•åˆ°æ‰§è¡Œæ—¥å¿—
                execution_log.append({
                    "event": "step_complete",
                    "step": step,
                    "name": name,
                    "success": success,
                    "result": result,
                })

                # æ”¶é›†æ‰§è¡Œç»“æœç”¨äºæŠ¥å‘Šç”Ÿæˆ
                from auto_agent import SubTaskResult
                collected_results.append(SubTaskResult(
                    step_id=str(step),
                    success=success,
                    output=result,
                    error=result.get("error") if isinstance(
                        result, dict) else None,
                ))

            elif event_type == "stage_retry":
                reason = data.get('message', 'é‡è¯•ä¸­...')
                print(f"\n   ğŸ”„ é‡è¯•: {reason}")
                execution_log.append(
                    {"event": "retry", "step": data.get('step'), "reason": reason})

            elif event_type == "stage_replan":
                reason = data.get('reason', '')
                print(f"\nâš ï¸  è§¦å‘é‡è§„åˆ’")
                print(f"   åŸå› : {reason}")
                execution_log.append({"event": "replan", "reason": reason})

            elif event_type == "answer":
                print("\n" + "=" * 70)
                print("ğŸ“„ æœ€ç»ˆç ”ç©¶æŠ¥å‘Š:")
                print("=" * 70)
                answer = data.get("answer", "")
                if answer:
                    final_report = answer
                print(answer)

            elif event_type == "done":
                print("\n" + "=" * 70)
                execution_success = data.get("success", False)
                iterations = data.get("iterations", 0)
                if execution_success:
                    print(f"âœ… ç ”ç©¶å®Œæˆ! (æ‰§è¡Œäº† {iterations} æ­¥)")
                else:
                    print(f"âŒ æ‰§è¡Œå¤±è´¥: {data.get('message', '')}")
                print("=" * 70)

            elif event_type == "error":
                print(f"\nâŒ é”™è¯¯: {data.get('message', '')}")
                if data.get("errors"):
                    for err in data["errors"]:
                        print(f"   - {err}")
                execution_log.append({"event": "error", "message": data.get(
                    'message', ''), "errors": data.get('errors', [])})

        # 7. å¯¼å‡ºç»“æœ
        if final_report and collected_plan:
            await export_results(
                report=final_report,
                execution_log=execution_log,
                plan=collected_plan,
                results=collected_results,
                state={
                    "final_report": final_report[:500] + "..." if len(final_report) > 500 else final_report},
                output_dir=script_dir / "output",
                topic="äººå·¥æ™ºèƒ½åœ¨åŒ»ç–—é¢†åŸŸçš„åº”ç”¨ä¸ä¼¦ç†æŒ‘æˆ˜",
            )

    except Exception as e:
        print(f"\nâŒ æ‰§è¡Œå¼‚å¸¸: {e}")
        import traceback
        traceback.print_exc()

    finally:
        await llm_client.close()


if __name__ == "__main__":
    asyncio.run(main())
