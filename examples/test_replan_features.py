"""
æµ‹è¯•æ–°å¢çš„ Replan ä¼˜åŒ–åŠŸèƒ½

æµ‹è¯•å†…å®¹ï¼š
1. ä»»åŠ¡å¤æ‚åº¦åˆ†çº§ (TaskComplexity, TaskProfile)
2. æ‰§è¡Œç­–ç•¥é€‰æ‹© (ExecutionStrategy)
3. å·¥ä½œè®°å¿† (CrossStepWorkingMemory)
4. å·¥å…·çº§ Replan ç­–ç•¥ (ToolReplanPolicy)

ä½¿ç”¨æ–¹æ³•:
    python examples/test_replan_features.py
"""

import asyncio
import os
import sys

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° path
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))


def test_task_complexity():
    """æµ‹è¯•ä»»åŠ¡å¤æ‚åº¦æšä¸¾å’Œ TaskProfile"""
    print("\n" + "=" * 60)
    print("æµ‹è¯• 1: ä»»åŠ¡å¤æ‚åº¦åˆ†çº§")
    print("=" * 60)

    from auto_agent.models import TaskComplexity, TaskProfile

    # æµ‹è¯•æšä¸¾
    print("\nâœ… TaskComplexity æšä¸¾:")
    for c in TaskComplexity:
        print(f"   - {c.name}: {c.value}")

    # æµ‹è¯• TaskProfile
    profile = TaskProfile(
        complexity=TaskComplexity.COMPLEX,
        estimated_steps=10,
        has_code_generation=True,
        has_cross_dependencies=True,
        requires_consistency=True,
        is_reversible=False,
        reasoning="è¿™æ˜¯ä¸€ä¸ªå¤æ‚çš„ä»£ç ç”Ÿæˆä»»åŠ¡",
    )

    print("\nâœ… TaskProfile åˆ›å»ºæˆåŠŸ:")
    print(f"   å¤æ‚åº¦: {profile.complexity.value}")
    print(f"   é¢„ä¼°æ­¥éª¤: {profile.estimated_steps}")
    print(f"   æ¶‰åŠä»£ç ç”Ÿæˆ: {profile.has_code_generation}")
    print(f"   éœ€è¦ä¸€è‡´æ€§: {profile.requires_consistency}")

    return True


def test_execution_strategy():
    """æµ‹è¯•æ‰§è¡Œç­–ç•¥"""
    print("\n" + "=" * 60)
    print("æµ‹è¯• 2: æ‰§è¡Œç­–ç•¥é€‰æ‹©")
    print("=" * 60)

    from auto_agent.models import ExecutionStrategy, TaskComplexity, TaskProfile

    # æ¨¡æ‹Ÿ planner çš„ç­–ç•¥é€‰æ‹©é€»è¾‘
    def get_strategy(complexity: TaskComplexity) -> ExecutionStrategy:
        if complexity == TaskComplexity.SIMPLE:
            return ExecutionStrategy(
                enable_replan=False,
                replan_trigger="on_failure",
            )
        elif complexity == TaskComplexity.MODERATE:
            return ExecutionStrategy(
                enable_replan=True,
                replan_trigger="on_failure",
            )
        elif complexity == TaskComplexity.COMPLEX:
            return ExecutionStrategy(
                enable_replan=True,
                replan_trigger="periodic",
                replan_interval=3,
                enable_consistency_check=True,
            )
        else:  # PROJECT
            return ExecutionStrategy(
                enable_replan=True,
                replan_trigger="proactive",
                replan_interval=3,
                enable_consistency_check=True,
                enable_lookahead=True,
                require_phase_review=True,
            )

    print("\nâœ… ä¸åŒå¤æ‚åº¦å¯¹åº”çš„ç­–ç•¥:")
    for complexity in TaskComplexity:
        strategy = get_strategy(complexity)
        print(f"\n   [{complexity.value}]")
        print(f"      enable_replan: {strategy.enable_replan}")
        print(f"      replan_trigger: {strategy.replan_trigger}")
        print(f"      replan_interval: {strategy.replan_interval}")

    return True


def test_working_memory():
    """æµ‹è¯•å·¥ä½œè®°å¿†"""
    print("\n" + "=" * 60)
    print("æµ‹è¯• 3: è·¨æ­¥éª¤å·¥ä½œè®°å¿†")
    print("=" * 60)

    from auto_agent.core.context import CrossStepWorkingMemory

    wm = CrossStepWorkingMemory()

    # æ·»åŠ è®¾è®¡å†³ç­–
    wm.add_decision(
        decision="ä½¿ç”¨ REST API è€Œé GraphQL",
        reason="å›¢é˜Ÿæ›´ç†Ÿæ‚‰ RESTï¼Œä¸”éœ€æ±‚ç®€å•",
        step_id="step_1",
        tags=["architecture", "api"],
    )

    # æ·»åŠ çº¦æŸ
    wm.add_constraint(
        constraint="æ‰€æœ‰å‡½æ•°å¿…é¡»æœ‰ç±»å‹æ³¨è§£",
        source="step_2",
        priority="high",
    )
    wm.add_constraint(
        constraint="API å“åº”å¿…é¡»åœ¨ 200ms å†…",
        source="step_1",
        priority="critical",
    )

    # æ·»åŠ å¾…åŠ
    wm.add_todo(
        todo="æ›´æ–° README æ–‡æ¡£",
        created_by="step_3",
        priority="normal",
    )

    # æ·»åŠ æ¥å£å®šä¹‰
    wm.add_interface(
        name="get_user",
        definition={
            "method": "GET",
            "path": "/api/users/{id}",
            "params": ["id: int"],
            "returns": "User",
        },
        defined_by="step_2",
        interface_type="api",
    )

    print("\nâœ… å·¥ä½œè®°å¿†å†…å®¹:")
    print(f"   è®¾è®¡å†³ç­–: {len(wm.design_decisions)} æ¡")
    print(f"   çº¦æŸæ¡ä»¶: {len(wm.constraints)} æ¡")
    print(f"   å¾…åŠäº‹é¡¹: {len(wm.todos)} æ¡")
    print(f"   æ¥å£å®šä¹‰: {len(wm.interfaces)} ä¸ª")

    # æµ‹è¯•ä¸Šä¸‹æ–‡ç”Ÿæˆ
    context = wm.get_relevant_context("å½“å‰æ­¥éª¤")
    print("\nâœ… ç”Ÿæˆçš„ä¸Šä¸‹æ–‡:")
    print(context)

    # æµ‹è¯•æŒä¹…åŒ–
    data = wm.to_dict()
    wm2 = CrossStepWorkingMemory.from_dict(data)
    print(f"\nâœ… æŒä¹…åŒ–æµ‹è¯•: æ¢å¤äº† {len(wm2.design_decisions)} æ¡å†³ç­–")

    return True


def test_tool_replan_policy():
    """æµ‹è¯•å·¥å…·çº§ Replan ç­–ç•¥"""
    print("\n" + "=" * 60)
    print("æµ‹è¯• 4: å·¥å…·çº§ Replan ç­–ç•¥")
    print("=" * 60)

    from auto_agent.models import ToolDefinition, ToolParameter, ToolReplanPolicy

    # ç®€å•å·¥å…· - ä¸éœ€è¦ replan
    simple_tool = ToolDefinition(
        name="get_weather",
        description="æŸ¥è¯¢å¤©æ°”",
        parameters=[
            ToolParameter(name="city", type="string", description="åŸå¸‚", required=True)
        ],
        replan_policy=ToolReplanPolicy(
            force_replan_check=False,
            high_impact=False,
        ),
    )

    # é«˜å½±å“åŠ›å·¥å…· - éœ€è¦ replan
    code_gen_tool = ToolDefinition(
        name="generate_code",
        description="ç”Ÿæˆä»£ç ",
        parameters=[
            ToolParameter(
                name="requirement", type="string", description="éœ€æ±‚", required=True
            )
        ],
        replan_policy=ToolReplanPolicy(
            force_replan_check=True,
            high_impact=True,
            requires_consistency_check=True,
            replan_condition="å¦‚æœç”Ÿæˆçš„ä»£ç è¶…è¿‡ 100 è¡Œæˆ–æ¶‰åŠå¤šä¸ªæ–‡ä»¶",
            consistency_check_against=["interface_definition"],
        ),
    )

    print("\nâœ… ç®€å•å·¥å…·ç­–ç•¥:")
    print(f"   name: {simple_tool.name}")
    print(f"   force_replan_check: {simple_tool.replan_policy.force_replan_check}")
    print(f"   high_impact: {simple_tool.replan_policy.high_impact}")

    print("\nâœ… ä»£ç ç”Ÿæˆå·¥å…·ç­–ç•¥:")
    print(f"   name: {code_gen_tool.name}")
    print(f"   force_replan_check: {code_gen_tool.replan_policy.force_replan_check}")
    print(f"   high_impact: {code_gen_tool.replan_policy.high_impact}")
    print(f"   replan_condition: {code_gen_tool.replan_policy.replan_condition}")

    return True


async def test_task_classification():
    """æµ‹è¯•ä»»åŠ¡åˆ†ç±»ï¼ˆéœ€è¦ LLMï¼‰"""
    print("\n" + "=" * 60)
    print("æµ‹è¯• 5: ä»»åŠ¡å¤æ‚åº¦åˆ†ç±»ï¼ˆéœ€è¦ LLMï¼‰")
    print("=" * 60)

    api_key = os.getenv("OPENAI_API_KEY") or os.getenv("DEEPSEEK_API_KEY")
    if not api_key:
        print("\nâš ï¸  è·³è¿‡: æœªè®¾ç½® API Key")
        return True

    from auto_agent import OpenAIClient, TaskPlanner, ToolRegistry

    # åˆå§‹åŒ–
    llm = OpenAIClient(
        api_key=api_key,
        base_url=os.getenv("OPENAI_BASE_URL", "https://api.deepseek.com/v1"),
        model=os.getenv("OPENAI_MODEL", "deepseek-chat"),
    )

    planner = TaskPlanner(
        llm_client=llm,
        tool_registry=ToolRegistry(),
    )

    # æµ‹è¯•ä¸åŒå¤æ‚åº¦çš„æŸ¥è¯¢
    test_queries = [
        ("ä»Šå¤©åŒ—äº¬å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ", "SIMPLE"),
        ("æœç´¢å…³äº Python çš„æ–‡ç« å¹¶æ€»ç»“", "MODERATE"),
        ("å¸®æˆ‘å†™ä¸€ä»½å…³äº AI çš„ç ”ç©¶æŠ¥å‘Š", "COMPLEX"),
        ("å¸®æˆ‘åˆ›å»ºä¸€ä¸ªå®Œæ•´çš„ TODO åº”ç”¨é¡¹ç›®", "PROJECT"),
    ]

    print("\nâœ… ä»»åŠ¡åˆ†ç±»ç»“æœ:")
    for query, expected in test_queries:
        try:
            profile = await planner.classify_task_complexity(query)
            match = "âœ“" if profile.complexity.value == expected.lower() else "âœ—"
            print(f"\n   {match} æŸ¥è¯¢: {query[:30]}...")
            print(f"      é¢„æœŸ: {expected}, å®é™…: {profile.complexity.value}")
            print(f"      ç†ç”±: {profile.reasoning[:50]}...")
        except Exception as e:
            print(f"\n   âœ— æŸ¥è¯¢: {query[:30]}... å¤±è´¥: {e}")

    await llm.close()
    return True


async def test_execution_context_integration():
    """æµ‹è¯• ExecutionContext é›†æˆå·¥ä½œè®°å¿†"""
    print("\n" + "=" * 60)
    print("æµ‹è¯• 6: ExecutionContext é›†æˆ")
    print("=" * 60)

    from auto_agent.core.context import ExecutionContext

    ctx = ExecutionContext(
        query="å¸®æˆ‘å†™ä¸€ä¸ª TODO åº”ç”¨",
        user_id="test_user",
        plan_summary="1. è®¾è®¡æ¶æ„\n2. å®ç°åŠŸèƒ½\n3. æµ‹è¯•",
    )

    # æ·»åŠ å·¥ä½œè®°å¿†
    ctx.working_memory.add_decision(
        decision="ä½¿ç”¨ SQLite ä½œä¸ºæ•°æ®åº“",
        reason="è½»é‡çº§ï¼Œé€‚åˆå°å‹åº”ç”¨",
        step_id="step_1",
    )

    ctx.working_memory.add_constraint(
        constraint="å¿…é¡»æ”¯æŒä»»åŠ¡ä¼˜å…ˆçº§",
        source="user",
        priority="high",
    )

    # è®°å½•æ­¥éª¤
    ctx.record_step(
        step_id="1",
        step_num=1,
        tool_name="design_architecture",
        description="è®¾è®¡ç³»ç»Ÿæ¶æ„",
        arguments={"requirement": "TODO åº”ç”¨"},
        output={"architecture": "MVC æ¨¡å¼"},
        success=True,
    )

    # ç”Ÿæˆ LLM ä¸Šä¸‹æ–‡
    llm_context = ctx.to_llm_context(include_memories=False)

    print("\nâœ… ExecutionContext åˆ›å»ºæˆåŠŸ")
    print(f"   æŸ¥è¯¢: {ctx.query}")
    print(f"   å·¥ä½œè®°å¿†å†³ç­–æ•°: {len(ctx.working_memory.design_decisions)}")
    print(f"   æ‰§è¡Œå†å²æ­¥éª¤æ•°: {len(ctx.history)}")

    print("\nâœ… ç”Ÿæˆçš„ LLM ä¸Šä¸‹æ–‡åŒ…å«å·¥ä½œè®°å¿†:")
    if "è®¾è®¡å†³ç­–" in llm_context:
        print("   âœ“ åŒ…å«è®¾è®¡å†³ç­–")
    if "çº¦æŸ" in llm_context:
        print("   âœ“ åŒ…å«çº¦æŸæ¡ä»¶")

    return True


def test_consistency_checker():
    """æµ‹è¯•å…¨å±€ä¸€è‡´æ€§æ£€æŸ¥å™¨"""
    print("\n" + "=" * 60)
    print("æµ‹è¯• 7: å…¨å±€ä¸€è‡´æ€§æ£€æŸ¥å™¨")
    print("=" * 60)

    from auto_agent.core.context import (
        ConsistencyCheckpoint,
        ConsistencyViolation,
        GlobalConsistencyChecker,
    )

    checker = GlobalConsistencyChecker()

    # æ³¨å†Œæ£€æŸ¥ç‚¹
    cp1 = checker.register_checkpoint(
        step_id="step_1",
        artifact_type="interface",
        key_elements={
            "names": ["get_user", "create_user"],
            "signatures": {
                "get_user": "(user_id: int) -> User",
                "create_user": "(name: str, email: str) -> User",
            },
        },
        constraints_for_future=[
            "æ‰€æœ‰ç”¨æˆ·ç›¸å…³å‡½æ•°å¿…é¡»ä½¿ç”¨ User ç±»å‹",
            "user_id å¿…é¡»æ˜¯æ•´æ•°ç±»å‹",
        ],
        description="ç”¨æˆ·æœåŠ¡æ¥å£å®šä¹‰",
    )

    cp2 = checker.register_checkpoint(
        step_id="step_2",
        artifact_type="schema",
        key_elements={
            "User": {
                "id": "int",
                "name": "str",
                "email": "str",
            }
        },
        constraints_for_future=["User å¿…é¡»åŒ…å« id, name, email å­—æ®µ"],
        description="ç”¨æˆ·æ•°æ®ç»“æ„å®šä¹‰",
    )

    print("\nâœ… æ£€æŸ¥ç‚¹æ³¨å†ŒæˆåŠŸ:")
    print(f"   æ£€æŸ¥ç‚¹æ•°é‡: {len(checker.checkpoints)}")
    for step_id, cp in checker.checkpoints.items():
        print(f"   - [{cp.artifact_type}] {cp.description}")

    # æ·»åŠ è¿è§„
    v1 = checker.add_violation(
        checkpoint_id="step_1",
        current_step_id="step_3",
        violation_type="interface_mismatch",
        severity="warning",
        description="get_user å‡½æ•°å‚æ•°ç±»å‹ä¸ä¸€è‡´ï¼Œä½¿ç”¨äº† str è€Œé int",
        suggestion="å°† user_id å‚æ•°ç±»å‹æ”¹ä¸º int",
    )

    v2 = checker.add_violation(
        checkpoint_id="step_2",
        current_step_id="step_3",
        violation_type="constraint_violation",
        severity="critical",
        description="User ç±»ç¼ºå°‘ email å­—æ®µ",
        suggestion="æ·»åŠ  email: str å­—æ®µåˆ° User ç±»",
    )

    print("\nâœ… è¿è§„è®°å½•:")
    print(f"   è¿è§„æ•°é‡: {len(checker.violations)}")
    print(f"   ä¸¥é‡è¿è§„: {checker.has_critical_violations()}")
    for v in checker.violations:
        print(f"   - [{v.severity}] {v.description}")

    # æµ‹è¯•è·å–ç›¸å…³æ£€æŸ¥ç‚¹
    interface_cps = checker.get_relevant_checkpoints(artifact_types=["interface"])
    print(f"\nâœ… æ¥å£ç±»å‹æ£€æŸ¥ç‚¹: {len(interface_cps)} ä¸ª")

    # æµ‹è¯•è·å–æ‰€æœ‰çº¦æŸ
    all_constraints = checker.get_all_constraints()
    print(f"âœ… æ‰€æœ‰çº¦æŸ: {len(all_constraints)} æ¡")

    # æµ‹è¯• LLM ä¸Šä¸‹æ–‡ç”Ÿæˆ
    llm_context = checker.get_context_for_llm()
    print("\nâœ… ç”Ÿæˆçš„ LLM ä¸Šä¸‹æ–‡:")
    print(llm_context[:300] + "..." if len(llm_context) > 300 else llm_context)

    # æµ‹è¯•æŒä¹…åŒ–
    data = checker.to_dict()
    checker2 = GlobalConsistencyChecker.from_dict(data)
    print(f"\nâœ… æŒä¹…åŒ–æµ‹è¯•: æ¢å¤äº† {len(checker2.checkpoints)} ä¸ªæ£€æŸ¥ç‚¹, {len(checker2.violations)} ä¸ªè¿è§„")

    return True


def test_consistency_in_context():
    """æµ‹è¯• ExecutionContext ä¸­çš„ä¸€è‡´æ€§æ£€æŸ¥å™¨é›†æˆ"""
    print("\n" + "=" * 60)
    print("æµ‹è¯• 8: ExecutionContext ä¸€è‡´æ€§æ£€æŸ¥å™¨é›†æˆ")
    print("=" * 60)

    from auto_agent.core.context import ExecutionContext

    ctx = ExecutionContext(
        query="å¸®æˆ‘å†™ä¸€ä¸ªç”¨æˆ·ç®¡ç†ç³»ç»Ÿ",
        user_id="test_user",
        plan_summary="1. å®šä¹‰æ¥å£\n2. å®ç°åŠŸèƒ½\n3. æµ‹è¯•",
    )

    # æ³¨å†Œæ£€æŸ¥ç‚¹
    ctx.consistency_checker.register_checkpoint(
        step_id="step_1",
        artifact_type="interface",
        key_elements={"functions": ["get_user", "create_user"]},
        constraints_for_future=["å¿…é¡»ä½¿ç”¨ User ç±»å‹"],
        description="ç”¨æˆ·æ¥å£å®šä¹‰",
    )

    # ç”Ÿæˆ LLM ä¸Šä¸‹æ–‡
    llm_context = ctx.to_llm_context(include_memories=False)

    print("\nâœ… ExecutionContext ä¸€è‡´æ€§æ£€æŸ¥å™¨é›†æˆæˆåŠŸ")
    print(f"   æ£€æŸ¥ç‚¹æ•°é‡: {len(ctx.consistency_checker.checkpoints)}")

    if "ä¸€è‡´æ€§æ£€æŸ¥ç‚¹" in llm_context:
        print("   âœ“ LLM ä¸Šä¸‹æ–‡åŒ…å«ä¸€è‡´æ€§æ£€æŸ¥ç‚¹")
    else:
        print("   âœ— LLM ä¸Šä¸‹æ–‡æœªåŒ…å«ä¸€è‡´æ€§æ£€æŸ¥ç‚¹")

    return True


def test_tool_post_policy():
    """æµ‹è¯•ç»Ÿä¸€åå¤„ç†ç­–ç•¥"""
    print("\n" + "=" * 60)
    print("æµ‹è¯• 9: ç»Ÿä¸€åå¤„ç†ç­–ç•¥ (ToolPostPolicy)")
    print("=" * 60)

    from auto_agent.models import (
        PostSuccessConfig,
        ResultHandlingConfig,
        ToolDefinition,
        ToolParameter,
        ToolPostPolicy,
        ToolReplanPolicy,
        ValidationConfig,
    )

    # æµ‹è¯• 1: ç›´æ¥ä½¿ç”¨ ToolPostPolicy
    post_policy = ToolPostPolicy(
        validation=ValidationConfig(
            on_fail="retry",
            max_retries=3,
            use_llm_validation=True,
        ),
        post_success=PostSuccessConfig(
            high_impact=True,
            requires_consistency_check=True,
            extract_working_memory=True,
            replan_condition="å¦‚æœç”Ÿæˆçš„ä»£ç è¶…è¿‡ 100 è¡Œ",
        ),
        result_handling=ResultHandlingConfig(
            cache_policy="session",
            register_as_checkpoint=True,
            checkpoint_type="code",
            state_mapping={"generated_code": "code_output"},
        ),
    )

    print("\nâœ… ToolPostPolicy åˆ›å»ºæˆåŠŸ:")
    print(f"   validation.on_fail: {post_policy.validation.on_fail}")
    print(f"   post_success.high_impact: {post_policy.post_success.high_impact}")
    print(f"   result_handling.checkpoint_type: {post_policy.result_handling.checkpoint_type}")

    # æµ‹è¯•è¾…åŠ©æ–¹æ³•
    print("\nâœ… è¾…åŠ©æ–¹æ³•æµ‹è¯•:")
    print(f"   is_high_impact(): {post_policy.is_high_impact()}")
    print(f"   should_check_consistency(): {post_policy.should_check_consistency()}")
    print(f"   should_register_checkpoint(): {post_policy.should_register_checkpoint()}")
    print(f"   should_extract_working_memory(): {post_policy.should_extract_working_memory()}")

    # æµ‹è¯• 2: ä»æ—§å­—æ®µæ„é€ ï¼ˆå…¼å®¹æ€§ï¼‰
    old_replan_policy = ToolReplanPolicy(
        high_impact=True,
        requires_consistency_check=True,
        replan_condition="å¦‚æœæ¶‰åŠå¤šä¸ªæ–‡ä»¶",
    )

    legacy_post_policy = ToolPostPolicy.from_legacy(
        validate_function=lambda r, e, s, m: (True, "OK"),
        compress_function=lambda r, s: {"summary": "compressed"},
        replan_policy=old_replan_policy,
        state_mapping={"output": "result"},
    )

    print("\nâœ… ä»æ—§å­—æ®µæ„é€  ToolPostPolicy:")
    print(f"   has validation: {legacy_post_policy.validation is not None}")
    print(f"   has post_success: {legacy_post_policy.post_success is not None}")
    print(f"   has result_handling: {legacy_post_policy.result_handling is not None}")
    print(f"   is_high_impact(): {legacy_post_policy.is_high_impact()}")

    # æµ‹è¯• 3: ToolDefinition.get_effective_post_policy()
    # ä½¿ç”¨æ–°å­—æ®µ
    tool_with_new = ToolDefinition(
        name="new_tool",
        description="ä½¿ç”¨æ–° post_policy çš„å·¥å…·",
        parameters=[],
        post_policy=post_policy,
    )

    # ä½¿ç”¨æ—§å­—æ®µ
    tool_with_old = ToolDefinition(
        name="old_tool",
        description="ä½¿ç”¨æ—§å­—æ®µçš„å·¥å…·",
        parameters=[],
        replan_policy=old_replan_policy,
        compress_function=lambda r, s: r,
    )

    print("\nâœ… ToolDefinition.get_effective_post_policy():")
    
    new_effective = tool_with_new.get_effective_post_policy()
    print(f"   æ–°å·¥å…· - is_high_impact: {new_effective.is_high_impact()}")
    
    old_effective = tool_with_old.get_effective_post_policy()
    print(f"   æ—§å·¥å…· - is_high_impact: {old_effective.is_high_impact()}")

    # æµ‹è¯•åºåˆ—åŒ–
    policy_dict = post_policy.to_dict()
    print("\nâœ… åºåˆ—åŒ–æµ‹è¯•:")
    print(f"   to_dict() keys: {list(policy_dict.keys())}")

    return True


def test_incremental_replan_structure():
    """æµ‹è¯•å¢é‡é‡è§„åˆ’çš„æ•°æ®ç»“æ„"""
    print("\n" + "=" * 60)
    print("æµ‹è¯• 10: å¢é‡é‡è§„åˆ’æ•°æ®ç»“æ„")
    print("=" * 60)

    from auto_agent.models import ExecutionPlan, ExecutionStrategy, PlanStep, SubTaskResult

    # åˆ›å»ºä¸€ä¸ªæ¨¡æ‹Ÿçš„æ‰§è¡Œè®¡åˆ’
    plan = ExecutionPlan(
        intent="åˆ›å»ºç”¨æˆ·ç®¡ç†ç³»ç»Ÿ",
        subtasks=[
            PlanStep(
                id="step_1",
                description="è®¾è®¡æ•°æ®åº“ç»“æ„",
                tool="design_schema",
                parameters={},
                read_fields=[],
                write_fields=["schema"],
            ),
            PlanStep(
                id="step_2",
                description="å®ç°ç”¨æˆ·æ¨¡å‹",
                tool="generate_code",
                parameters={},
                read_fields=["schema"],
                write_fields=["user_model"],
            ),
            PlanStep(
                id="step_3",
                description="å®ç° API æ¥å£",
                tool="generate_code",
                parameters={},
                read_fields=["user_model"],
                write_fields=["api_code"],
            ),
        ],
        expected_outcome="å®Œæ•´çš„ç”¨æˆ·ç®¡ç†ç³»ç»Ÿ",
    )

    # æ¨¡æ‹Ÿæ‰§è¡Œå†å²ï¼ˆå‰ä¸¤æ­¥æˆåŠŸï¼‰
    execution_history = [
        SubTaskResult(
            step_id="step_1",
            success=True,
            output={"schema": {"users": {"id": "int", "name": "str"}}},
        ),
        SubTaskResult(
            step_id="step_2",
            success=True,
            output={"user_model": "class User: ..."},
        ),
    ]

    print("\nâœ… æ‰§è¡Œè®¡åˆ’åˆ›å»ºæˆåŠŸ:")
    print(f"   æ€»æ­¥éª¤æ•°: {len(plan.subtasks)}")
    print(f"   å·²å®Œæˆæ­¥éª¤: {len(execution_history)}")

    # æ¨¡æ‹Ÿå¢é‡é‡è§„åˆ’åœºæ™¯
    current_step_index = 2  # ç¬¬ä¸‰æ­¥
    completed_steps = plan.subtasks[:current_step_index]
    remaining_steps = plan.subtasks[current_step_index:]

    print(f"\nâœ… å¢é‡é‡è§„åˆ’åœºæ™¯:")
    print(f"   å½“å‰æ­¥éª¤ç´¢å¼•: {current_step_index}")
    print(f"   å·²å®Œæˆæ­¥éª¤: {[s.id for s in completed_steps]}")
    print(f"   å¾…æ‰§è¡Œæ­¥éª¤: {[s.id for s in remaining_steps]}")

    # éªŒè¯å·²å®Œæˆæ­¥éª¤çš„äº§å‡ºå¯ä»¥è¢«åç»­æ­¥éª¤ä½¿ç”¨
    completed_outputs = set()
    for result in execution_history:
        if result.output:
            completed_outputs.update(result.output.keys())

    print(f"\nâœ… å·²å®Œæˆæ­¥éª¤çš„äº§å‡º: {completed_outputs}")

    # æ£€æŸ¥å¾…æ‰§è¡Œæ­¥éª¤çš„ä¾èµ–
    for step in remaining_steps:
        missing_deps = [f for f in step.read_fields if f not in completed_outputs]
        if missing_deps:
            print(f"   âš ï¸ æ­¥éª¤ {step.id} ç¼ºå°‘ä¾èµ–: {missing_deps}")
        else:
            print(f"   âœ“ æ­¥éª¤ {step.id} ä¾èµ–æ»¡è¶³")

    return True


async def main():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("\n" + "=" * 60)
    print("ğŸ§ª Replan ä¼˜åŒ–åŠŸèƒ½æµ‹è¯•")
    print("=" * 60)

    results = []

    # é˜¶æ®µä¸€æµ‹è¯•ï¼šä»»åŠ¡å¤æ‚åº¦åˆ†çº§
    results.append(("ä»»åŠ¡å¤æ‚åº¦åˆ†çº§", test_task_complexity()))
    results.append(("æ‰§è¡Œç­–ç•¥é€‰æ‹©", test_execution_strategy()))
    results.append(("å·¥å…·çº§ Replan ç­–ç•¥", test_tool_replan_policy()))

    # é˜¶æ®µäºŒæµ‹è¯•ï¼šå·¥ä½œè®°å¿†
    results.append(("è·¨æ­¥éª¤å·¥ä½œè®°å¿†", test_working_memory()))
    results.append(("ExecutionContext é›†æˆ", await test_execution_context_integration()))

    # é˜¶æ®µä¸‰æµ‹è¯•ï¼šä¸€è‡´æ€§æ£€æŸ¥å™¨
    results.append(("å…¨å±€ä¸€è‡´æ€§æ£€æŸ¥å™¨", test_consistency_checker()))
    results.append(("ExecutionContext ä¸€è‡´æ€§é›†æˆ", test_consistency_in_context()))

    # é˜¶æ®µå››æµ‹è¯•ï¼šå¢é‡é‡è§„åˆ’
    results.append(("å¢é‡é‡è§„åˆ’æ•°æ®ç»“æ„", test_incremental_replan_structure()))

    # ç»Ÿä¸€åå¤„ç†æœºåˆ¶æµ‹è¯•
    results.append(("ç»Ÿä¸€åå¤„ç†ç­–ç•¥", test_tool_post_policy()))

    # LLM æµ‹è¯•ï¼ˆå¯é€‰ï¼‰
    results.append(("ä»»åŠ¡åˆ†ç±»ï¼ˆLLMï¼‰", await test_task_classification()))

    # æ±‡æ€»ç»“æœ
    print("\n" + "=" * 60)
    print("ğŸ“Š æµ‹è¯•ç»“æœæ±‡æ€»")
    print("=" * 60)

    passed = sum(1 for _, r in results if r)
    total = len(results)

    for name, result in results:
        status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
        print(f"   {status} - {name}")

    print(f"\n   æ€»è®¡: {passed}/{total} é€šè¿‡")
    print("=" * 60)


if __name__ == "__main__":
    asyncio.run(main())
